Loading data...
{'sympathy_and_emotional_support': 0, 'not_related_or_irrelevant': 1, 'infrastructure_and_utilities_damage': 2, 'other_useful_information': 3, 'injured_or_dead_people': 4, 'caution_and_advice': 5, 'displaced_people_and_evacuations': 6, 'donation_needs_or_offers_or_volunteering_services': 7, 'missing_trapped_or_found_people': 8}
Max Document length: 2407
Vocabulary Size: 24319
Train/Dev split: 9226/1025
Writing to /home/ubuntu/Project/runs/1550599466

2019-02-19T18:04:28.697950: step 1, loss 13.5969, accuracy 0.125, precision [nan, 0.0, 0.0, 0.0, 0.5, 0.5, nan, 0.0, nan], recall [nan, nan, 0.0, nan, 0.5, 0.1111111111111111, nan, 0.0, nan]
2019-02-19T18:04:28.883408: step 2, loss 14.6674, accuracy 0.125, precision [nan, 0.0, 0.5, 0.2, 0.0, nan, nan, nan, 0.0], recall [0.0, nan, 0.3333333333333333, 0.2, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:29.043998: step 3, loss 6.50111, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.3333333333333333, nan, nan, nan], recall [nan, 0.0, 0.0, 0.75, 0.0, 0.3333333333333333, 0.0, nan, nan]
2019-02-19T18:04:29.194083: step 4, loss 11.3053, accuracy 0.1875, precision [nan, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:29.351712: step 5, loss 14.2426, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.75, 1.0, 0.0, nan, 0.0, 0.0], recall [nan, 0.0, 0.0, 0.3333333333333333, 0.5, nan, nan, nan, nan]
2019-02-19T18:04:29.506652: step 6, loss 17.1275, accuracy 0.1875, precision [0.0, nan, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, nan], recall [nan, nan, 0.0, 0.2, nan, nan, nan, 0.5, nan]
2019-02-19T18:04:29.659110: step 7, loss 9.18166, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.625, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.7142857142857143, 0.5, nan, nan, nan, nan]
2019-02-19T18:04:29.809010: step 8, loss 13.1683, accuracy 0.3125, precision [0.0, 0.5, nan, 0.5, 0.25, 0.0, 0.0, nan, nan], recall [nan, 1.0, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:04:29.962579: step 9, loss 9.9061, accuracy 0.0625, precision [nan, 0.0, 0.0, 0.14285714285714285, nan, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.25, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:30.119728: step 10, loss 9.17036, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.4, 0.5, nan, nan, 0.5, nan], recall [0.0, nan, 0.0, 0.3333333333333333, 0.25, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:04:30.275701: step 11, loss 12.7818, accuracy 0.25, precision [0.0, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, nan, 1.0, nan], recall [nan, nan, 0.5, 0.25, 0.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:04:30.430487: step 12, loss 11.7192, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.5, 0.5, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:04:30.585981: step 13, loss 11.7679, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, nan, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.4, nan, 0.0, 0.0, nan]
2019-02-19T18:04:30.744035: step 14, loss 10.935, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 0.0, nan, 0.6666666666666666, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:04:30.898404: step 15, loss 10.2224, accuracy 0.3125, precision [1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.5, nan, 0.0, 0.0, nan], recall [0.25, 0.0, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:04:31.054066: step 16, loss 9.72357, accuracy 0.25, precision [nan, 0.0, 0.0, 0.25, 0.4, nan, 0.0, 0.5, nan], recall [0.0, 0.0, nan, 0.25, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:04:31.206617: step 17, loss 17.3552, accuracy 0.125, precision [0.25, 1.0, 0.0, 0.0, nan, 0.0, 0.0, 0.0, nan], recall [0.3333333333333333, 0.16666666666666666, nan, 0.0, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:04:31.360180: step 18, loss 16.1836, accuracy 0.3125, precision [0.0, nan, 0.5, 0.5714285714285714, 0.0, nan, 0.0, 0.0, nan], recall [nan, 0.0, 0.5, 0.5714285714285714, nan, nan, nan, nan, nan]
2019-02-19T18:04:31.511123: step 19, loss 11.3642, accuracy 0.3125, precision [0.0, nan, 0.0, 0.5, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.5714285714285714, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T18:04:31.663134: step 20, loss 7.34603, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.5555555555555556, 0.0, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.7142857142857143, nan, 0.0, nan, 0.0, 0.0]
2019-02-19T18:04:31.819146: step 21, loss 9.12985, accuracy 0.25, precision [0.0, 0.0, nan, 0.5714285714285714, 0.0, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.36363636363636365, nan, nan, nan, nan, 0.0]
2019-02-19T18:04:31.974696: step 22, loss 8.87899, accuracy 0.25, precision [0.0, 0.6666666666666666, 0.0, 0.5, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.2, 0.5, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:32.132109: step 23, loss 13.3789, accuracy 0.1875, precision [0.0, 0.0, nan, 0.6666666666666666, 0.25, 0.0, 0.0, 0.0, 0.0], recall [0.0, nan, 0.0, 0.2222222222222222, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:04:32.291489: step 24, loss 7.66588, accuracy 0.4375, precision [nan, 0.25, nan, 0.8, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:04:32.447355: step 25, loss 10.6038, accuracy 0.25, precision [0.0, 0.5, 0.0, 0.4, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.5, 0.0, 0.3333333333333333, 0.0, nan, 0.0, nan, 0.0]
2019-02-19T18:04:32.603995: step 26, loss 9.26233, accuracy 0.0625, precision [0.0, 0.0, 0.0, 0.1111111111111111, 0.0, nan, 0.0, nan, nan], recall [0.0, 0.0, 0.0, 0.5, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:04:32.757047: step 27, loss 9.57285, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.25, 0.5, 0.0, nan, nan, nan], recall [nan, 1.0, nan, 0.5, 0.16666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T18:04:32.916910: step 28, loss 10.4986, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.0, 0.25, 0.75, 0.0, nan, nan, nan], recall [nan, 0.3333333333333333, 0.0, 0.25, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:33.070179: step 29, loss 10.524, accuracy 0.3125, precision [0.5, 0.0, 0.25, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.3333333333333333, nan, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, nan, 0.0, 0.0, 0.0]
2019-02-19T18:04:33.225716: step 30, loss 17.2191, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0], recall [0.0, nan, 0.0, 0.2, 0.0, nan, 0.6666666666666666, nan, nan]
2019-02-19T18:04:33.378764: step 31, loss 13.216, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.7142857142857143, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, nan, 0.5, 0.0, nan, nan, nan, nan]
2019-02-19T18:04:33.537996: step 32, loss 12.244, accuracy 0.1875, precision [0.0, 0.0, 1.0, 0.5, 0.0, 0.0, nan, 0.0, nan], recall [0.0, nan, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:33.695866: step 33, loss 5.48074, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.16666666666666666, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.5, 1.0, 0.3333333333333333, 0.2857142857142857, nan, 0.0, nan, nan]
2019-02-19T18:04:33.854145: step 34, loss 7.7179, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, nan, nan], recall [0.5, 0.0, nan, 0.375, 0.3333333333333333, nan, nan, 0.0, 0.0]
2019-02-19T18:04:34.004192: step 35, loss 8.95472, accuracy 0.375, precision [1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, nan, 0.0, 0.0, 0.0], recall [0.75, 0.5, 1.0, 0.16666666666666666, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:34.157053: step 36, loss 15.465, accuracy 0.0625, precision [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.0, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:04:34.316249: step 37, loss 9.38621, accuracy 0.125, precision [nan, 0.0, 0.3333333333333333, 0.2, 0.0, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:04:34.476311: step 38, loss 12.0244, accuracy 0.25, precision [0.5, 0.5, 0.0, 0.2, 0.0, 1.0, 0.0, 0.0, nan], recall [0.5, 0.25, 0.0, 0.3333333333333333, 0.0, 0.5, nan, 0.0, nan]
2019-02-19T18:04:34.636250: step 39, loss 7.93213, accuracy 0.125, precision [0.0, 0.0, nan, 0.16666666666666666, 0.0, 0.0, nan, 1.0, nan], recall [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:04:34.792413: step 40, loss 8.07665, accuracy 0.125, precision [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.2, 0.0, 0.25, 0.0, 0.0, 0.0, nan, nan]
2019-02-19T18:04:34.949668: step 41, loss 12.4547, accuracy 0.4375, precision [nan, nan, 1.0, 0.5, 0.0, 1.0, nan, 0.0, 0.0], recall [nan, 0.0, 0.5, 0.75, nan, 0.5, nan, nan, nan]
2019-02-19T18:04:35.109924: step 42, loss 13.4297, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.5, 0.2, nan, 0.0, 1.0, nan], recall [nan, 0.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:04:35.268398: step 43, loss 11.6093, accuracy 0.1875, precision [0.0, 0.0, nan, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0], recall [0.0, 0.0, 0.0, 0.6666666666666666, nan, 0.0, nan, 0.16666666666666666, nan]
2019-02-19T18:04:35.424779: step 44, loss 7.90626, accuracy 0.25, precision [1.0, 1.0, 0.0, 0.25, 0.0, nan, 0.0, 0.25, nan], recall [0.5, 1.0, 0.0, 0.25, 0.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:04:35.575450: step 45, loss 9.16019, accuracy 0.1875, precision [0.0, 0.5, 0.3333333333333333, 0.0, 1.0, nan, 0.0, nan, nan], recall [nan, 0.25, 0.5, 0.0, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:04:35.729354: step 46, loss 9.94304, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.5, 0.0, 0.0, nan, 0.5, nan], recall [0.0, 0.5, 0.0, 0.2222222222222222, nan, nan, nan, 1.0, nan]
2019-02-19T18:04:35.883628: step 47, loss 12.6895, accuracy 0.125, precision [0.0, 0.0, nan, 0.6666666666666666, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, nan, nan, 0.0]
2019-02-19T18:04:36.038156: step 48, loss 13.7592, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.5, 0.4, nan, 0.0, 0.0, nan], recall [0.0, nan, 0.0, 0.2, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:04:36.190598: step 49, loss 8.1596, accuracy 0.5, precision [nan, nan, 0.4, 0.7142857142857143, 1.0, 0.0, 0.0, nan, nan], recall [nan, 0.0, 0.6666666666666666, 0.625, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:04:36.350517: step 50, loss 8.45243, accuracy 0.4375, precision [1.0, 0.5, nan, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [0.5, 1.0, 0.0, 1.0, 0.4, 0.0, nan, 0.0, nan]
2019-02-19T18:04:36.507038: step 51, loss 7.50311, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.5, 0.5, nan, 1.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.2, nan, 1.0, 0.0, nan]
2019-02-19T18:04:36.660521: step 52, loss 9.98752, accuracy 0.1875, precision [0.0, 0.0, nan, 0.2857142857142857, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.0, nan, 0.5, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T18:04:36.819403: step 53, loss 13.6492, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.5, 0.3333333333333333, nan, nan, 0.0, 1.0, nan], recall [0.0, 0.25, 1.0, 0.5, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:04:36.973800: step 54, loss 10.7413, accuracy 0.3125, precision [0.0, nan, 0.0, 0.3333333333333333, 0.75, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:37.127822: step 55, loss 9.5162, accuracy 0.125, precision [0.3333333333333333, 0.0, nan, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0], recall [0.25, 0.0, nan, 0.0, 0.2, nan, 0.0, 0.0, nan]
2019-02-19T18:04:37.284959: step 56, loss 5.48475, accuracy 0.3125, precision [1.0, 0.25, 0.3333333333333333, 0.3333333333333333, 0.25, nan, 0.0, nan, nan], recall [0.25, 0.5, 1.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:04:37.446271: step 57, loss 6.65443, accuracy 0.25, precision [0.5, 1.0, 1.0, 0.0, 0.25, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 0.5, 0.25, 0.0, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T18:04:37.604284: step 58, loss 9.89417, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.8, 0.5, 0.0, nan, nan, nan], recall [nan, nan, nan, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:37.755892: step 59, loss 7.64958, accuracy 0.3125, precision [0.5, 0.0, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.25, 0.0, 0.0, 0.5, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:04:37.910092: step 60, loss 6.81117, accuracy 0.25, precision [0.5, 0.5, 0.0, 0.2, 0.0, 0.0, nan, 1.0, nan], recall [1.0, 0.25, 0.0, 0.2, 0.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:04:38.065467: step 61, loss 12.4249, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.3333333333333333, 0.5, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:04:38.218118: step 62, loss 5.54433, accuracy 0.375, precision [0.0, 0.0, 0.3333333333333333, 0.8, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [nan, nan, 0.3333333333333333, 0.4444444444444444, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:04:38.371296: step 63, loss 9.63939, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.6, 0.25, nan, 0.0, 0.0, nan], recall [nan, 0.0, nan, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:04:38.531068: step 64, loss 6.14844, accuracy 0.25, precision [0.0, 0.0, nan, 0.6666666666666666, 0.0, nan, 0.0, 0.0, nan], recall [nan, 0.0, 0.0, 0.4444444444444444, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:04:38.691743: step 65, loss 6.02848, accuracy 0.375, precision [0.0, 0.5, 0.5, 0.3333333333333333, 1.0, 0.5, nan, 0.0, 0.0], recall [0.0, 0.5, 1.0, 0.2, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:04:38.849349: step 66, loss 7.14453, accuracy 0.1875, precision [0.5, nan, 0.0, 0.2, 0.0, 0.0, nan, 0.0, 0.0], recall [0.5, 0.0, nan, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:04:39.000390: step 67, loss 8.91666, accuracy 0.3125, precision [0.0, 0.6666666666666666, nan, 0.3, nan, nan, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.6, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:04:39.161950: step 68, loss 9.03739, accuracy 0.25, precision [0.0, nan, 0.5, 0.375, 0.0, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.25, 0.6, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:39.318234: step 69, loss 8.29441, accuracy 0.25, precision [0.5, 0.2, 0.0, 0.6666666666666666, 0.0, nan, 0.0, 0.0, nan], recall [1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:39.470144: step 70, loss 8.91129, accuracy 0.25, precision [0.0, 0.5, 0.0, nan, 0.3333333333333333, 0.0, nan, 0.0, 1.0], recall [0.0, 1.0, nan, 0.0, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:04:39.621894: step 71, loss 7.79302, accuracy 0.25, precision [nan, 0.5, 0.0, 0.16666666666666666, 0.2, nan, nan, 0.5, nan], recall [0.0, 1.0, nan, 0.3333333333333333, 0.3333333333333333, 0.0, nan, 0.5, nan]
2019-02-19T18:04:39.776288: step 72, loss 6.82041, accuracy 0.4375, precision [0.6666666666666666, 1.0, 0.5, 0.3333333333333333, 0.5, 0.0, 0.0, 0.3333333333333333, nan], recall [0.6666666666666666, 0.5, 0.5, 0.25, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:04:39.930726: step 73, loss 9.97395, accuracy 0.25, precision [0.0, 1.0, 0.0, 0.5, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.2, 0.4, nan, nan, nan, nan]
2019-02-19T18:04:40.086274: step 74, loss 7.98717, accuracy 0.25, precision [1.0, 0.0, 0.0, 0.4, 0.0, nan, 0.0, 0.0, 0.5], recall [0.25, 0.0, nan, 0.6666666666666666, 0.0, 0.0, nan, 0.0, 0.5]
2019-02-19T18:04:40.239657: step 75, loss 7.17259, accuracy 0.375, precision [0.3333333333333333, 0.5, 1.0, 0.2857142857142857, 1.0, nan, 0.0, nan, 0.0], recall [0.25, 0.5, 0.5, 0.6666666666666666, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:40.396802: step 76, loss 5.29737, accuracy 0.25, precision [0.0, nan, 0.0, 0.5, 0.3333333333333333, nan, nan, 0.0, nan], recall [0.0, 0.0, nan, 1.0, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T18:04:40.553754: step 77, loss 4.99326, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.5, 0.4, nan, 0.0, nan, 1.0], recall [0.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.5]
2019-02-19T18:04:40.707082: step 78, loss 2.55804, accuracy 0.5, precision [0.0, 0.5, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan], recall [nan, 0.5, 1.0, 1.0, 0.4, 0.0, nan, 0.5, nan]
2019-02-19T18:04:40.862016: step 79, loss 5.65673, accuracy 0.5, precision [nan, 0.0, 1.0, 0.5555555555555556, nan, 0.0, nan, 0.3333333333333333, nan], recall [nan, 0.0, 0.5, 1.0, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T18:04:41.017374: step 80, loss 6.13828, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.25, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [0.0, 1.0, 1.0, 0.2, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:41.174031: step 81, loss 8.77323, accuracy 0.375, precision [0.0, 0.0, nan, 0.6, 0.5, 0.0, 1.0, 0.0, 0.0], recall [0.0, nan, 0.0, 0.5, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:04:41.329533: step 82, loss 8.77106, accuracy 0.25, precision [0.0, 0.5, 0.5, 0.16666666666666666, nan, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 1.0, 0.25, 0.2, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:04:41.487393: step 83, loss 7.4706, accuracy 0.3125, precision [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:41.637317: step 84, loss 9.20928, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.625, 0.0, 0.0, nan, 0.0, nan], recall [0.0, nan, 0.2, 0.7142857142857143, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:41.789503: step 85, loss 9.25871, accuracy 0.375, precision [nan, 0.0, 0.5, 0.75, 0.5, 0.0, 1.0, 0.0, 0.0], recall [nan, nan, 0.3333333333333333, 0.6, 0.3333333333333333, nan, 0.5, 0.0, nan]
2019-02-19T18:04:41.947482: step 86, loss 9.54041, accuracy 0.4375, precision [0.3333333333333333, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, nan, nan], recall [0.5, 1.0, nan, 0.2857142857142857, 0.6, nan, 0.0, nan, nan]
2019-02-19T18:04:42.099124: step 87, loss 5.51798, accuracy 0.4375, precision [0.5, 0.3333333333333333, nan, 0.7142857142857143, 0.0, nan, nan, 0.0, nan], recall [1.0, 0.3333333333333333, 0.0, 0.625, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:04:42.254655: step 88, loss 10.0925, accuracy 0.375, precision [1.0, 0.3333333333333333, 0.0, 0.6, 0.5, 0.0, nan, 0.0, nan], recall [0.5, 1.0, nan, 0.42857142857142855, 0.25, nan, 0.0, 0.0, nan]
2019-02-19T18:04:42.409793: step 89, loss 8.06756, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 1.0, nan], recall [0.0, 0.0, nan, 0.3333333333333333, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:04:42.566801: step 90, loss 13.8638, accuracy 0.125, precision [0.0, 0.0, nan, 0.25, 0.16666666666666666, 0.0, nan, 0.0, 0.0], recall [nan, 0.0, nan, 0.14285714285714285, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:04:42.724937: step 91, loss 10.9134, accuracy 0.0625, precision [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, nan], recall [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, nan]
2019-02-19T18:04:42.873047: step 92, loss 5.4377, accuracy 0.5, precision [nan, 0.5, 0.5, 0.5555555555555556, 0.0, nan, nan, 0.5, nan], recall [0.0, 0.5, 1.0, 0.8333333333333334, 0.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:04:43.024633: step 93, loss 5.32297, accuracy 0.3125, precision [1.0, nan, 0.0, 0.3333333333333333, 0.0, 0.0, nan, 1.0, nan], recall [0.2, 0.0, 0.0, 0.75, 0.0, nan, nan, 1.0, nan]
2019-02-19T18:04:43.173687: step 94, loss 8.63794, accuracy 0.1875, precision [nan, 0.0, 0.0, 0.3333333333333333, 0.25, 0.0, 0.0, nan, 0.0], recall [0.0, 0.0, nan, 0.3333333333333333, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:04:43.326550: step 95, loss 9.08005, accuracy 0.25, precision [0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, nan, nan, nan], recall [1.0, 0.25, nan, 0.5, nan, 0.0, nan, 0.0, nan]
2019-02-19T18:04:43.483547: step 96, loss 5.62755, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.0, 0.25, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0]
2019-02-19T18:04:43.638230: step 97, loss 6.61212, accuracy 0.25, precision [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.25, nan, 0.4, 0.5, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:04:43.789252: step 98, loss 6.60553, accuracy 0.375, precision [0.0, 0.0, 0.3333333333333333, 1.0, 0.5, nan, 0.0, nan, nan], recall [0.0, 0.0, 1.0, 0.75, 0.4, nan, nan, 0.0, nan]
2019-02-19T18:04:43.947528: step 99, loss 7.04714, accuracy 0.1875, precision [nan, 0.0, nan, 0.14285714285714285, 0.25, 0.0, nan, 1.0, nan], recall [0.0, 0.0, 0.0, 0.3333333333333333, 0.2, 0.0, nan, 1.0, nan]
2019-02-19T18:04:44.100509: step 100, loss 11.0379, accuracy 0.1875, precision [0.0, nan, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, nan, 0.2, 0.5, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:04:44.256259: step 101, loss 7.51344, accuracy 0.25, precision [0.0, nan, 0.4, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.25, 0.0, nan, nan, 0.0]
2019-02-19T18:04:44.409553: step 102, loss 6.8723, accuracy 0.375, precision [1.0, nan, nan, 0.5, 0.5, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.6, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:04:44.567842: step 103, loss 7.51111, accuracy 0.3125, precision [nan, 0.0, nan, 0.8, 1.0, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.4444444444444444, 0.5, 0.0, 0.0, nan, 0.0]
2019-02-19T18:04:44.720191: step 104, loss 5.65716, accuracy 0.5625, precision [0.0, 0.5, nan, 1.0, 0.5, 1.0, nan, 0.0, nan], recall [nan, 0.5, 0.0, 0.7142857142857143, 0.6666666666666666, 1.0, nan, 0.0, 0.0]
2019-02-19T18:04:44.869366: step 105, loss 5.25795, accuracy 0.5, precision [1.0, 0.3333333333333333, 1.0, 0.5, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 0.75, 0.3333333333333333, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:04:45.018714: step 106, loss 5.57465, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.0, 0.8333333333333334, 0.3333333333333333, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.5555555555555556, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:04:45.173565: step 107, loss 8.75644, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.2, 0.75, nan, nan, nan, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.3333333333333333, 0.75, nan, nan, 0.0, 0.0]
2019-02-19T18:04:45.328283: step 108, loss 2.83837, accuracy 0.625, precision [nan, 0.5, 1.0, 0.5714285714285714, 0.6, nan, nan, 1.0, nan], recall [nan, 1.0, 0.5, 0.5714285714285714, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:04:45.485340: step 109, loss 8.53663, accuracy 0.25, precision [1.0, 0.3333333333333333, 0.5, 0.0, 0.0, nan, nan, 0.0, nan], recall [0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:04:45.636962: step 110, loss 5.44968, accuracy 0.4375, precision [0.5, 0.25, nan, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0], recall [1.0, 0.5, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, nan]
2019-02-19T18:04:45.795488: step 111, loss 8.77843, accuracy 0.25, precision [0.0, 0.0, nan, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, nan], recall [nan, 0.0, nan, 0.25, 0.3333333333333333, 0.0, nan, 1.0, nan]
2019-02-19T18:04:45.950843: step 112, loss 9.30516, accuracy 0.1875, precision [1.0, 0.0, 0.5, 0.0, 0.0, nan, 0.0, 0.3333333333333333, nan], recall [0.25, 0.0, 0.5, 0.0, 0.0, 0.0, nan, 0.5, nan]
2019-02-19T18:04:46.098954: step 113, loss 4.18093, accuracy 0.4375, precision [0.0, 0.3333333333333333, 1.0, 0.5, 0.25, nan, nan, 0.6666666666666666, nan], recall [nan, 0.5, 0.5, 0.3333333333333333, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:04:46.255153: step 114, loss 6.03184, accuracy 0.375, precision [nan, 0.3333333333333333, 1.0, 0.16666666666666666, nan, 0.0, 0.5, nan, nan], recall [nan, 0.2, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:04:46.405786: step 115, loss 8.42259, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.5, 0.3333333333333333, nan, nan, 0.3333333333333333, 0.0], recall [0.0, 0.3333333333333333, nan, 0.5, 0.5, 0.0, 0.0, 0.5, nan]
2019-02-19T18:04:46.558839: step 116, loss 8.62441, accuracy 0.3125, precision [0.5, 0.25, nan, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 0.0, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:04:46.717087: step 117, loss 6.60446, accuracy 0.4375, precision [0.0, 0.0, 0.3333333333333333, 0.5, 1.0, nan, nan, 0.75, nan], recall [0.0, 0.0, 1.0, 0.2, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:04:46.870978: step 118, loss 4.92082, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.75, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.3333333333333333, nan, 0.6, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:04:47.020171: step 119, loss 9.09657, accuracy 0.3125, precision [0.0, 1.0, 0.5, 0.4, 0.0, nan, nan, nan, 0.0], recall [0.0, 0.2857142857142857, 1.0, 0.3333333333333333, 0.0, nan, nan, nan, nan]
2019-02-19T18:04:47.174459: step 120, loss 6.67678, accuracy 0.25, precision [0.0, 0.5, nan, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.0, 0.3333333333333333, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:04:47.329665: step 121, loss 2.90089, accuracy 0.625, precision [nan, 1.0, nan, 0.625, 0.75, 0.0, nan, 0.0, 1.0], recall [0.0, 0.25, 0.0, 0.8333333333333334, 1.0, nan, nan, nan, 1.0]
2019-02-19T18:04:47.488673: step 122, loss 9.68138, accuracy 0.3125, precision [0.0, 0.6666666666666666, 0.0, 0.4, 0.5, 0.0, nan, 0.0, nan], recall [nan, 0.4, 0.0, 0.4, 0.25, 0.0, nan, nan, nan]
2019-02-19T18:04:47.643792: step 123, loss 6.41142, accuracy 0.4375, precision [1.0, 0.5, 0.6666666666666666, 0.5, 0.0, 0.0, nan, 0.0, nan], recall [1.0, 0.3333333333333333, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:47.795244: step 124, loss 7.05252, accuracy 0.3125, precision [0.5, 0.3333333333333333, 0.3333333333333333, 0.2, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.25, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:47.949631: step 125, loss 8.24355, accuracy 0.25, precision [0.3333333333333333, nan, 0.0, 0.2857142857142857, nan, 1.0, nan, 0.0, nan], recall [0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, nan, nan]
2019-02-19T18:04:48.099559: step 126, loss 4.82292, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, nan, 0.6666666666666666, 0.5, 0.25, 0.0, 0.0, 0.5, nan]
2019-02-19T18:04:48.255520: step 127, loss 5.62027, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.75, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:04:48.407497: step 128, loss 6.9466, accuracy 0.375, precision [0.0, 0.4, nan, 0.6666666666666666, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T18:04:48.563921: step 129, loss 8.44942, accuracy 0.1875, precision [nan, 0.0, 0.0, 0.5, 0.0, 0.0, nan, 0.5, nan], recall [0.0, 0.0, nan, 0.4, 0.0, nan, 0.0, 0.5, 0.0]
2019-02-19T18:04:48.719200: step 130, loss 7.32576, accuracy 0.25, precision [0.0, 0.0, 0.5, 0.6, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.5, 0.3333333333333333, nan, 0.0, nan, 0.0, nan]
2019-02-19T18:04:48.874983: step 131, loss 4.44616, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.3333333333333333, 0.42857142857142855, nan, nan, 0.5, nan], recall [1.0, 0.5, 0.0, 0.25, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:04:49.026439: step 132, loss 9.6346, accuracy 0.1875, precision [0.0, 0.0, 0.25, 0.3333333333333333, 0.0, 1.0, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.16666666666666666, 0.0, 0.5, nan, 0.0, nan]
2019-02-19T18:04:49.179956: step 133, loss 5.01564, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.0, 0.25, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.0, 0.25, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T18:04:49.332519: step 134, loss 8.7802, accuracy 0.25, precision [nan, 0.5, 0.0, 0.25, 0.5, 0.0, 0.0, 0.25, nan], recall [0.0, 0.5, 0.0, 0.2, 0.25, nan, nan, 0.5, nan]
2019-02-19T18:04:49.487829: step 135, loss 6.31652, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.5, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.2, 0.5, 0.6, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:04:49.638232: step 136, loss 11.0876, accuracy 0.3125, precision [nan, 0.5, 0.5, 0.25, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0], recall [0.0, 0.25, 0.25, 0.3333333333333333, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:04:49.788641: step 137, loss 6.67278, accuracy 0.3125, precision [nan, 0.0, nan, 0.6666666666666666, 0.5, nan, nan, 0.25, 0.0], recall [0.0, 0.0, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:04:49.938406: step 138, loss 8.36499, accuracy 0.25, precision [nan, 0.3333333333333333, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, nan, nan], recall [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:04:50.095615: step 139, loss 6.64026, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.5, 0.25, 1.0, nan, 1.0, nan], recall [1.0, 0.0, nan, 0.3333333333333333, 0.3333333333333333, 0.5, 0.0, 0.4, nan]
2019-02-19T18:04:50.248172: step 140, loss 6.6478, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.5, 0.25, nan, nan, 1.0, 0.0], recall [0.0, 0.0, 1.0, 0.5, 0.5, nan, 0.0, 0.25, nan]
2019-02-19T18:04:50.403173: step 141, loss 8.08518, accuracy 0.1875, precision [nan, 0.2, 0.0, 0.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.0, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:50.554079: step 142, loss 7.74218, accuracy 0.25, precision [0.0, 0.0, 0.5, 0.0, 1.0, nan, nan, 0.25, nan], recall [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, nan, 0.2, nan]
2019-02-19T18:04:50.710462: step 143, loss 5.9079, accuracy 0.5, precision [1.0, 0.5, 0.5, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0], recall [1.0, 0.5, 0.5, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:04:50.863118: step 144, loss 6.62286, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.6, 0.0, 0.0, nan, 1.0, nan], recall [0.0, nan, 0.0, 0.6, 0.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:04:51.021303: step 145, loss 5.42085, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.5, 0.0, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.0, 0.3333333333333333, 0.5, nan, 0.0, nan, 0.25, 0.0]
2019-02-19T18:04:51.179608: step 146, loss 8.62193, accuracy 0.125, precision [0.0, 0.5, 0.0, 0.0, 0.3333333333333333, 0.0, nan, nan, nan], recall [0.0, 0.5, 0.0, 0.0, 0.5, nan, 0.0, 0.0, 0.0]
2019-02-19T18:04:51.332269: step 147, loss 9.79456, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.0, 1.0, nan, nan, 0.25, nan], recall [nan, 0.0, 0.0, 0.0, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T18:04:51.483506: step 148, loss 5.95109, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.25, 0.5, 1.0, nan, 0.0, 0.0], recall [nan, 0.25, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, nan, nan]
2019-02-19T18:04:51.634463: step 149, loss 6.89091, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.16666666666666666, 0.5, 0.0, nan, 0.5, nan], recall [0.0, 0.0, 0.4, 0.5, 0.5, nan, nan, 0.5, 0.0]
2019-02-19T18:04:51.789654: step 150, loss 4.9765, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.3333333333333333, 0.5, 0.5, nan, nan, 1.0, 0.0], recall [0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:04:51.941905: step 151, loss 4.73546, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.2, nan, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, 0.8, 0.3333333333333333, 0.0, nan, nan, 0.6666666666666666, 0.0]
2019-02-19T18:04:52.097976: step 152, loss 4.76969, accuracy 0.25, precision [nan, 0.5, nan, 0.25, 0.3333333333333333, nan, 0.0, 0.0, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, nan, nan, nan, 0.0]
2019-02-19T18:04:52.252982: step 153, loss 7.53442, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.6, 0.5, 0.0, nan, 0.0, nan], recall [1.0, nan, 0.0, 0.42857142857142855, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:04:52.406633: step 154, loss 9.33735, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, nan, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:04:52.559845: step 155, loss 5.90314, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.6, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.6, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:52.724730: step 156, loss 4.95159, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.3333333333333333, 0.4, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:04:52.883916: step 157, loss 4.36751, accuracy 0.375, precision [nan, 0.0, nan, 0.5, 0.8, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.4, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:53.033827: step 158, loss 5.87806, accuracy 0.375, precision [0.0, 1.0, 0.3333333333333333, 0.2857142857142857, 0.5, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.5, 0.5, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T18:04:53.191391: step 159, loss 3.49179, accuracy 0.375, precision [1.0, 0.25, 0.0, 0.6, 0.5, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 0.5, nan, 0.5, 0.3333333333333333, nan, 0.0, 0.0, nan]
2019-02-19T18:04:53.345669: step 160, loss 4.12648, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.0, 0.4, 0.8, 0.0, nan, nan, nan], recall [nan, 0.5, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:04:53.497776: step 161, loss 5.91987, accuracy 0.375, precision [nan, 0.5, nan, 0.5, 0.75, 0.0, 0.0, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.5, 0.6, 0.0, nan, 0.0, nan]
2019-02-19T18:04:53.649162: step 162, loss 4.80616, accuracy 0.25, precision [0.5, 0.0, 0.25, 0.0, 1.0, nan, nan, 0.0, 0.0], recall [1.0, 0.0, 0.5, 0.0, 0.4, 0.0, nan, 0.0, nan]
2019-02-19T18:04:53.804673: step 163, loss 4.55735, accuracy 0.4375, precision [0.0, 0.0, nan, 0.8333333333333334, 0.5, nan, nan, 0.3333333333333333, nan], recall [nan, 0.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, 0.25, 0.0]
2019-02-19T18:04:53.965214: step 164, loss 5.46054, accuracy 0.375, precision [0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, nan, 0.5555555555555556, 0.25, 0.0, nan, nan, nan]
2019-02-19T18:04:54.118240: step 165, loss 7.89983, accuracy 0.375, precision [0.0, 0.5, nan, 0.5714285714285714, 0.0, 0.0, nan, nan, nan], recall [0.0, 0.3333333333333333, 0.0, 0.8, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:04:54.272495: step 166, loss 5.2315, accuracy 0.25, precision [0.0, 0.5, 0.0, 0.3333333333333333, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.25, nan, 0.2857142857142857, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:04:54.425776: step 167, loss 9.02538, accuracy 0.3125, precision [0.3333333333333333, nan, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], recall [1.0, 0.0, 0.0, 0.0, 0.5714285714285714, 0.0, nan, 0.0, nan]
2019-02-19T18:04:54.582595: step 168, loss 7.03001, accuracy 0.25, precision [0.0, 0.0, 0.5, 0.3333333333333333, 0.0, nan, 0.0, 0.5, nan], recall [0.0, 0.0, 1.0, 0.16666666666666666, nan, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:04:54.736540: step 169, loss 4.50908, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [nan, 0.3333333333333333, 0.0, 0.2, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:04:54.889083: step 170, loss 8.46399, accuracy 0.3125, precision [0.0, 1.0, 0.3333333333333333, 0.0, 0.5, 0.0, 1.0, 0.0, nan], recall [0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 1.0, nan, nan]
2019-02-19T18:04:55.046708: step 171, loss 9.23573, accuracy 0.3125, precision [0.25, 0.25, nan, 0.6, 0.0, nan, nan, 0.0, nan], recall [0.5, 0.3333333333333333, 0.0, 0.5, 0.0, 0.0, 0.0, nan, nan]
2019-02-19T18:04:55.199351: step 172, loss 7.54821, accuracy 0.3125, precision [nan, 1.0, 0.0, 0.14285714285714285, 0.0, 0.0, 1.0, 1.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.2, nan, nan, 0.5, 1.0, 0.0]
2019-02-19T18:04:55.355596: step 173, loss 7.85056, accuracy 0.3125, precision [0.5, 0.3333333333333333, 0.0, 0.5, nan, 0.0, 0.0, 0.3333333333333333, nan], recall [0.3333333333333333, 0.3333333333333333, 0.0, 0.4, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:04:55.509251: step 174, loss 8.09878, accuracy 0.375, precision [1.0, 0.3333333333333333, 0.3333333333333333, 0.6, 0.0, 0.0, nan, nan, nan], recall [0.5, 1.0, 0.5, 0.375, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:55.662209: step 175, loss 5.74225, accuracy 0.4375, precision [0.0, 0.0, 0.6666666666666666, 0.5555555555555556, 0.0, 0.0, nan, nan, nan], recall [0.0, 0.0, 0.6666666666666666, 0.7142857142857143, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:55.813283: step 176, loss 5.28858, accuracy 0.4375, precision [0.5, 0.0, 0.0, 0.75, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [1.0, 0.0, 0.0, 0.6, 0.6666666666666666, nan, 0.0, 0.5, nan]
2019-02-19T18:04:55.970468: step 177, loss 3.91256, accuracy 0.375, precision [0.3333333333333333, 0.0, nan, 0.5714285714285714, 0.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:04:56.118016: step 178, loss 7.8687, accuracy 0.375, precision [0.75, 0.3333333333333333, 0.0, 0.16666666666666666, 0.5, nan, nan, nan, nan], recall [0.42857142857142855, 0.3333333333333333, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:04:56.272454: step 179, loss 6.26625, accuracy 0.4375, precision [1.0, 1.0, 0.6666666666666666, 0.4, 0.3333333333333333, 0.0, 0.0, nan, nan], recall [0.5, 1.0, 1.0, 0.4, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:56.425792: step 180, loss 4.2983, accuracy 0.5, precision [0.3333333333333333, 0.6666666666666666, 0.2, 0.8, nan, nan, nan, nan, nan], recall [1.0, 1.0, 0.5, 0.4, nan, nan, nan, 0.0, nan]
2019-02-19T18:04:56.581448: step 181, loss 5.50882, accuracy 0.125, precision [0.3333333333333333, 0.0, nan, 0.0, 0.3333333333333333, 0.0, nan, 0.0, 0.0], recall [0.2, nan, nan, 0.0, 0.25, nan, nan, 0.0, nan]
2019-02-19T18:04:56.736140: step 182, loss 6.69149, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.25, 0.75, nan, nan, 0.0, 0.0, nan]
2019-02-19T18:04:56.890623: step 183, loss 5.78754, accuracy 0.5, precision [nan, nan, 1.0, 0.5, 0.4, nan, nan, 0.0, nan], recall [nan, 0.0, 0.4, 0.6666666666666666, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:04:57.040382: step 184, loss 4.48571, accuracy 0.4375, precision [0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, nan, 1.0, 0.3333333333333333, nan], recall [nan, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0]
2019-02-19T18:04:57.195234: step 185, loss 7.01237, accuracy 0.375, precision [0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, 0.0], recall [0.6666666666666666, 0.4, 0.0, 0.3333333333333333, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:04:57.350865: step 186, loss 4.85529, accuracy 0.4375, precision [0.5, nan, 0.5, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, nan], recall [1.0, 0.0, 0.5, 0.5714285714285714, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:04:57.503330: step 187, loss 5.7452, accuracy 0.3125, precision [nan, 0.5, 0.0, 0.2, 0.0, 1.0, 0.0, 0.4, nan], recall [0.0, 0.5, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, nan, 0.6666666666666666, nan]
2019-02-19T18:04:57.658785: step 188, loss 5.57362, accuracy 0.375, precision [0.0, nan, 0.3333333333333333, 0.5, 0.5, nan, 0.0, nan, nan], recall [nan, 0.0, 0.3333333333333333, 0.6, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:04:57.813832: step 189, loss 5.32853, accuracy 0.375, precision [0.5, 0.3333333333333333, 0.0, 0.25, 1.0, nan, nan, 0.0, nan], recall [0.5, 1.0, 0.0, 0.5, 0.375, nan, nan, nan, 0.0]
2019-02-19T18:04:57.969571: step 190, loss 7.4921, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.16666666666666666, 0.75, 0.0, nan, nan, nan], recall [0.0, nan, 0.0, 0.2, 0.42857142857142855, nan, nan, nan, nan]
2019-02-19T18:04:58.123965: step 191, loss 6.08746, accuracy 0.3125, precision [nan, 0.0, 1.0, 0.2, 0.5, 0.0, 0.0, nan, nan], recall [0.0, nan, 0.5, 0.5, 0.4, 0.0, nan, 0.0, nan]
2019-02-19T18:04:58.278511: step 192, loss 6.55213, accuracy 0.5, precision [0.3333333333333333, 0.25, 1.0, 1.0, 0.0, nan, nan, 0.6666666666666666, 0.0], recall [0.5, 0.5, 0.25, 1.0, 0.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:04:58.436163: step 193, loss 7.24169, accuracy 0.25, precision [0.3333333333333333, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.5, nan], recall [0.5, nan, 0.3333333333333333, 0.2, 0.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:04:58.591035: step 194, loss 5.81358, accuracy 0.1875, precision [nan, 0.0, nan, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.0, nan, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:58.738980: step 195, loss 5.47023, accuracy 0.4375, precision [0.0, 0.0, nan, 0.8333333333333334, 0.3333333333333333, nan, 0.0, nan, nan], recall [nan, nan, nan, 0.45454545454545453, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:04:58.894131: step 196, loss 3.72962, accuracy 0.375, precision [nan, 0.0, nan, 0.625, 0.3333333333333333, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, nan, 0.625, 0.3333333333333333, nan, 0.0, nan, nan]
2019-02-19T18:04:59.042855: step 197, loss 5.1481, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.5, 0.5, 0.3333333333333333, nan, nan, 1.0, nan], recall [nan, 0.5, 0.5, 0.6, 0.25, nan, 0.0, 0.5, nan]
2019-02-19T18:04:59.197011: step 198, loss 5.20649, accuracy 0.25, precision [0.0, 0.4, nan, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.0, 0.16666666666666666, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T18:04:59.351028: step 199, loss 7.44535, accuracy 0.125, precision [0.0, 0.0, 0.5, 0.14285714285714285, nan, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:04:59.509381: step 200, loss 5.876, accuracy 0.375, precision [0.0, 1.0, nan, 0.25, 0.3333333333333333, 1.0, nan, 0.25, 0.0], recall [0.0, 0.3333333333333333, nan, 0.2, 0.5, 1.0, 0.0, 1.0, nan]
2019-02-19T18:04:59.771427: step 201, loss 3.04423, accuracy 0.5, precision [0.0, 0.75, 0.5, 0.4, 1.0, nan, 0.0, nan, nan], recall [nan, 0.6, 1.0, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:04:59.983245: step 202, loss 9.23402, accuracy 0.1875, precision [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, nan, 0.5, nan], recall [0.0, 0.4, nan, 0.0, nan, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:00.137543: step 203, loss 8.188, accuracy 0.3125, precision [1.0, 1.0, 0.0, 0.3333333333333333, 0.2, nan, nan, nan, 0.0], recall [0.5, 0.3333333333333333, 0.0, 1.0, 0.2, nan, 0.0, 0.0, nan]
2019-02-19T18:05:00.293357: step 204, loss 7.44116, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.5, 0.5, nan, nan, 0.25, 0.0], recall [0.0, 0.0, nan, 0.2, 0.75, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:00.446378: step 205, loss 6.47252, accuracy 0.25, precision [1.0, 0.0, 1.0, 0.4, 0.0, 0.0, nan, 0.0, nan], recall [0.5, 0.0, 1.0, 0.4, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:00.598709: step 206, loss 5.17175, accuracy 0.3125, precision [0.0, 0.25, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 1.0, 0.0], recall [nan, 0.5, nan, 0.2, 0.25, nan, nan, 0.4, nan]
2019-02-19T18:05:00.751384: step 207, loss 5.34594, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.75, nan, 0.0, 0.0, nan], recall [0.5, nan, nan, 0.3333333333333333, 0.6, 0.0, 0.0, nan, 0.0]
2019-02-19T18:05:00.906199: step 208, loss 3.81395, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.4444444444444444, 1.0, nan, nan, nan, 0.0], recall [nan, 0.5, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:05:01.059979: step 209, loss 2.66146, accuracy 0.4375, precision [nan, nan, 0.0, 0.375, 0.8, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.75, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:01.214416: step 210, loss 5.89163, accuracy 0.375, precision [nan, 0.3333333333333333, 1.0, 0.6666666666666666, 0.5, nan, 0.0, 0.0, 0.5], recall [nan, 0.5, 0.5, 0.4, 0.5, 0.0, nan, 0.0, 1.0]
2019-02-19T18:05:01.370403: step 211, loss 4.43933, accuracy 0.3125, precision [0.2, 0.0, nan, 0.4, 0.3333333333333333, nan, nan, 0.5, nan], recall [1.0, 0.0, nan, 0.2857142857142857, 0.2, nan, nan, 1.0, 0.0]
2019-02-19T18:05:01.526137: step 212, loss 4.23807, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.625, 0.5, 0.0, nan, 0.0, nan], recall [nan, 1.0, 0.0, 0.7142857142857143, 0.25, nan, nan, 0.0, 0.0]
2019-02-19T18:05:01.683862: step 213, loss 3.78293, accuracy 0.5625, precision [0.0, 0.3333333333333333, nan, 0.625, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, 0.0, 0.7142857142857143, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:01.833982: step 214, loss 4.50391, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.5, 0.6, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 0.5, 1.0, 0.75, 0.3333333333333333, nan, nan, nan, 0.0]
2019-02-19T18:05:01.984857: step 215, loss 3.96452, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T18:05:02.135088: step 216, loss 4.64059, accuracy 0.5, precision [0.5, 0.3333333333333333, 0.8, 0.3333333333333333, 0.5, 0.0, nan, nan, nan], recall [0.25, 0.25, 1.0, 0.5, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:05:02.285644: step 217, loss 5.53318, accuracy 0.3125, precision [nan, 0.2, 0.0, 0.6666666666666666, 0.0, nan, 0.0, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.4444444444444444, 0.0, nan, nan, nan, nan]
2019-02-19T18:05:02.440162: step 218, loss 4.50947, accuracy 0.5, precision [0.6666666666666666, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.5, 0.5, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T18:05:02.597414: step 219, loss 9.99551, accuracy 0.25, precision [1.0, 0.0, 0.5, 0.3333333333333333, nan, 0.0, 0.0, nan, 0.0], recall [0.25, 0.0, 0.3333333333333333, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:05:02.750355: step 220, loss 7.18444, accuracy 0.1875, precision [nan, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, 0.25, nan, 0.0, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:02.906223: step 221, loss 5.78528, accuracy 0.4375, precision [0.0, 0.5, nan, 0.5714285714285714, 0.25, nan, nan, 1.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.5714285714285714, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:05:03.064123: step 222, loss 3.56819, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.5, 0.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, nan, 0.0]
2019-02-19T18:05:03.219249: step 223, loss 7.42521, accuracy 0.3125, precision [nan, 0.2, 0.3333333333333333, 0.6666666666666666, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 1.0, 0.4, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:05:03.376281: step 224, loss 6.70256, accuracy 0.25, precision [1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.3333333333333333, 0.0, 0.14285714285714285, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:03.527479: step 225, loss 3.38716, accuracy 0.5, precision [nan, 0.6666666666666666, nan, 0.6, 0.0, nan, nan, nan, nan], recall [0.0, 0.5, 0.0, 0.75, nan, nan, nan, 0.0, nan]
2019-02-19T18:05:03.683949: step 226, loss 4.58943, accuracy 0.4375, precision [1.0, 0.0, nan, 0.4, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 0.0, 0.0, 0.4, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:05:03.836651: step 227, loss 5.26292, accuracy 0.375, precision [0.0, 1.0, 0.0, 0.8, 0.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.25, 0.0, 0.5, nan, nan, nan, 0.5, nan]
2019-02-19T18:05:03.987470: step 228, loss 6.41476, accuracy 0.3125, precision [nan, 0.0, 0.5, 0.6666666666666666, 0.0, nan, nan, 0.0, nan], recall [nan, nan, 0.25, 0.5, nan, 0.0, nan, 0.0, nan]
2019-02-19T18:05:04.141590: step 229, loss 2.84101, accuracy 0.5, precision [0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.5, nan], recall [1.0, 1.0, 0.5, 0.25, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:05:04.292598: step 230, loss 3.61406, accuracy 0.375, precision [0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.0, nan, nan], recall [0.25, 0.0, 0.3333333333333333, 0.75, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:05:04.443374: step 231, loss 3.10005, accuracy 0.5625, precision [1.0, 0.6666666666666666, 1.0, 0.5714285714285714, 0.0, nan, nan, 0.0, 0.0], recall [1.0, 0.6666666666666666, 0.6666666666666666, 0.8, nan, nan, nan, 0.0, nan]
2019-02-19T18:05:04.596720: step 232, loss 8.57393, accuracy 0.25, precision [nan, 0.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 0.3333333333333333, nan], recall [0.0, nan, nan, 0.2857142857142857, 1.0, 0.0, 0.0, 0.25, nan]
2019-02-19T18:05:04.745923: step 233, loss 5.34408, accuracy 0.5, precision [0.5, 0.4, nan, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 0.6, 0.2, nan, 0.0, 1.0, nan]
2019-02-19T18:05:04.901237: step 234, loss 5.74493, accuracy 0.4375, precision [0.0, 1.0, nan, 0.3333333333333333, 0.75, 0.0, nan, 0.2, nan], recall [nan, 0.6666666666666666, nan, 0.25, 0.75, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:05:05.051873: step 235, loss 2.82459, accuracy 0.5, precision [0.5, 0.6666666666666666, 0.3333333333333333, 0.5, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:05:05.212244: step 236, loss 5.22946, accuracy 0.375, precision [0.5, 0.25, 0.5, 0.4, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 1.0, 0.6666666666666666, 0.25, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:05.367401: step 237, loss 4.51436, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.5, 1.0, 0.0, nan, nan, 1.0], recall [nan, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.0, 1.0]
2019-02-19T18:05:05.516489: step 238, loss 7.72378, accuracy 0.125, precision [0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:05.670830: step 239, loss 5.04657, accuracy 0.4375, precision [0.0, 0.0, 0.5, 1.0, 0.6666666666666666, nan, 0.0, 0.5, nan], recall [0.0, 0.0, 0.5, 0.4, 0.6666666666666666, 0.0, 0.0, 1.0, nan]
2019-02-19T18:05:05.823975: step 240, loss 4.26634, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 1.0, 1.0, 0.5, 0.4, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:05:05.980105: step 241, loss 4.85201, accuracy 0.1875, precision [0.0, 0.0, 0.5, 0.2857142857142857, nan, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:06.136894: step 242, loss 5.51981, accuracy 0.375, precision [0.0, 0.5, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 0.3333333333333333, nan, 0.6, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:05:06.294099: step 243, loss 5.2912, accuracy 0.3125, precision [nan, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 0.0, 0.0, 0.75, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:06.452174: step 244, loss 7.29925, accuracy 0.375, precision [nan, 0.75, 0.25, 0.0, 0.5, nan, nan, 0.0, 0.0], recall [0.0, 0.6, 1.0, 0.0, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:05:06.607577: step 245, loss 5.55115, accuracy 0.25, precision [1.0, 0.0, 0.0, 0.25, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [1.0, 0.0, nan, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:05:06.760467: step 246, loss 5.16953, accuracy 0.4375, precision [nan, 0.5, nan, 0.375, 0.5, nan, nan, nan, nan], recall [nan, 0.5, 0.0, 0.5, 0.6, 0.0, 0.0, nan, nan]
2019-02-19T18:05:06.918277: step 247, loss 5.23407, accuracy 0.375, precision [0.0, 1.0, 1.0, 0.25, 1.0, 0.0, nan, 0.25, nan], recall [0.0, 0.3333333333333333, 0.5, 0.25, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:05:07.075851: step 248, loss 3.93212, accuracy 0.4375, precision [0.0, 1.0, nan, 0.6666666666666666, 0.4, nan, 0.0, 0.5, nan], recall [nan, 0.25, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, nan]
2019-02-19T18:05:07.228444: step 249, loss 4.96244, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.8333333333333334, nan, nan, 0.0, 0.3333333333333333, 0.0], recall [0.0, 0.3333333333333333, 0.5, 0.7142857142857143, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T18:05:07.384300: step 250, loss 4.23834, accuracy 0.5, precision [0.5, 0.5, 1.0, 0.42857142857142855, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.25, 1.0, 0.75, 0.3333333333333333, nan, nan, nan, 0.0]

Evaluation:
[[ 33  11   1  29   1   1   1   5   0]
 [ 10  57   3  79   3   0   0   4   0]
 [  0   2  43  45   1   0   1   2   0]
 [  1  11  14 263   1   3   1   6   0]
 [  4   2   3  59 102   1   0   2   0]
 [  3   5   1  43   1   4   2   1   0]
 [  2   0   0  18   2   0   8   0   0]
 [  1   9   0  56   2   0   3  34   0]
 [  0   0   2  22   1   0   0   0   0]]
2019-02-19T18:05:13.535630: step 250, loss 2.8354, accuracy 0.530732, precision [0.4024390243902439, 0.36538461538461536, 0.4574468085106383, 0.8766666666666667, 0.5895953757225434, 0.06666666666666667, 0.26666666666666666, 0.3238095238095238, 0.0], recall [0.6111111111111112, 0.5876288659793815, 0.6417910447761194, 0.42833876221498374, 0.8947368421052632, 0.4444444444444444, 0.5, 0.6296296296296297, nan]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-250

2019-02-19T18:05:13.839518: step 251, loss 5.46247, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.8, 0.0, 0.0, nan, nan, 0.0], recall [0.0, 1.0, nan, 0.4, nan, nan, 0.0, 0.0, nan]
2019-02-19T18:05:13.990028: step 252, loss 6.57745, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.5, 0.5, 0.5, nan, 0.5, 0.0], recall [0.0, 0.0, nan, 0.75, 1.0, 0.3333333333333333, nan, 0.3333333333333333, 0.0]
2019-02-19T18:05:14.142345: step 253, loss 3.81761, accuracy 0.5, precision [0.0, 0.0, 0.25, 0.75, 1.0, nan, 1.0, nan, nan], recall [0.0, 0.0, 0.3333333333333333, 0.75, 0.75, nan, 1.0, 0.0, nan]
2019-02-19T18:05:14.294288: step 254, loss 6.70566, accuracy 0.3125, precision [0.0, 0.0, nan, 0.5714285714285714, 0.0, nan, 0.0, 1.0, nan], recall [0.0, 0.0, 0.0, 0.5714285714285714, nan, nan, nan, 0.25, nan]
2019-02-19T18:05:14.452441: step 255, loss 7.93948, accuracy 0.4375, precision [1.0, 0.25, nan, 0.5, 0.0, nan, 1.0, 0.5, 0.0], recall [1.0, 0.5, 0.0, 0.3333333333333333, nan, 0.0, 0.5, 0.5, nan]
2019-02-19T18:05:14.605692: step 256, loss 3.15423, accuracy 0.4375, precision [0.5, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [1.0, 0.5, 0.0, 0.2857142857142857, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:05:14.758780: step 257, loss 3.74231, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.375, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:14.911916: step 258, loss 6.55895, accuracy 0.1875, precision [nan, 0.0, 0.0, 0.3333333333333333, 0.4, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, 0.0, 0.16666666666666666, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:15.066523: step 259, loss 5.05324, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [0.5, nan, 0.5, 0.25, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:15.218311: step 260, loss 3.45935, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.3333333333333333, 0.6, 0.0, 1.0, 0.5, nan], recall [0.6666666666666666, 0.0, 0.5, 1.0, 0.6, 0.0, 0.5, 1.0, nan]
2019-02-19T18:05:15.373793: step 261, loss 4.73752, accuracy 0.4375, precision [0.25, nan, 0.25, 0.75, 0.6666666666666666, nan, nan, 0.0, nan], recall [1.0, 0.0, 0.5, 0.5, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T18:05:15.531270: step 262, loss 4.95022, accuracy 0.375, precision [0.0, 0.25, nan, 1.0, 0.0, nan, 0.0, 0.25, nan], recall [0.0, 0.5, 0.0, 0.4444444444444444, nan, nan, nan, 0.5, 0.0]
2019-02-19T18:05:15.682511: step 263, loss 3.45694, accuracy 0.5625, precision [nan, 0.8, 0.6666666666666666, 0.42857142857142855, nan, nan, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T18:05:15.837275: step 264, loss 3.29652, accuracy 0.4375, precision [0.5, 0.5, 0.5, 0.2, 0.6666666666666666, 0.0, nan, nan, 1.0], recall [0.5, 0.25, 0.5, 0.5, 0.6666666666666666, 0.0, nan, nan, 1.0]
2019-02-19T18:05:15.996117: step 265, loss 3.98186, accuracy 0.5, precision [0.5, 1.0, nan, 0.3333333333333333, 0.5, nan, nan, 0.5, nan], recall [0.3333333333333333, 1.0, 0.0, 1.0, 0.5, nan, 0.0, 1.0, 0.0]
2019-02-19T18:05:16.148610: step 266, loss 5.85984, accuracy 0.3125, precision [0.0, 0.0, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.3333333333333333, 0.0], recall [nan, 0.0, 0.0, 0.4, 0.5, nan, 0.0, 0.25, nan]
2019-02-19T18:05:16.300898: step 267, loss 5.80956, accuracy 0.375, precision [1.0, 0.0, nan, 0.2, 1.0, 0.0, nan, 0.0, 0.0], recall [0.5, 0.0, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:16.458176: step 268, loss 4.23594, accuracy 0.4375, precision [1.0, 1.0, 0.0, 0.25, 0.5, 1.0, nan, 0.0, 0.0], recall [1.0, 0.6666666666666666, 0.0, 0.5, 0.25, 1.0, nan, 0.0, nan]
2019-02-19T18:05:16.610391: step 269, loss 2.73892, accuracy 0.5625, precision [nan, 0.6666666666666666, 0.0, 0.4, 0.75, 1.0, nan, 0.5, nan], recall [0.0, 0.6666666666666666, nan, 0.6666666666666666, 1.0, 1.0, nan, 0.5, 0.0]
2019-02-19T18:05:16.762400: step 270, loss 4.43016, accuracy 0.4375, precision [0.0, 0.3333333333333333, 1.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.25, 1.0, 0.6, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:05:16.916428: step 271, loss 6.01908, accuracy 0.25, precision [0.0, 1.0, nan, 0.5, 0.25, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.4, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:05:17.070121: step 272, loss 3.92496, accuracy 0.375, precision [0.3333333333333333, 0.3333333333333333, nan, 0.5, 0.75, 0.0, 0.0, 0.0, nan], recall [0.5, 0.25, 0.0, 0.5, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:05:17.221300: step 273, loss 6.05767, accuracy 0.3125, precision [1.0, 0.3333333333333333, 0.0, 0.4, 0.0, nan, 0.0, 0.5, 0.0], recall [0.5, 0.25, nan, 0.5, 0.0, nan, nan, 0.25, nan]
2019-02-19T18:05:17.377818: step 274, loss 8.33684, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, nan, 0.0, 0.25, 0.0], recall [0.0, 0.0, nan, 0.0, 0.3333333333333333, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:17.529252: step 275, loss 3.55653, accuracy 0.4375, precision [nan, 0.5, 0.5, 0.6666666666666666, 0.5, 1.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.5, 0.5, 0.6666666666666666, 1.0, nan, nan, nan]
2019-02-19T18:05:17.683502: step 276, loss 2.68426, accuracy 0.4375, precision [0.5, 0.2, 0.0, 0.6666666666666666, 0.6, nan, nan, nan, nan], recall [0.25, 0.5, nan, 0.6666666666666666, 0.6, 0.0, nan, 0.0, nan]
2019-02-19T18:05:17.838898: step 277, loss 2.95865, accuracy 0.5625, precision [nan, 0.5, nan, 0.75, 0.8, nan, 0.0, nan, 0.0], recall [0.0, 0.6666666666666666, nan, 0.75, 0.8, nan, 0.0, 0.0, nan]
2019-02-19T18:05:17.988337: step 278, loss 2.47152, accuracy 0.5625, precision [0.5, 0.0, 0.0, 0.6, 1.0, 0.0, 0.0, 1.0, nan], recall [0.5, 0.0, nan, 0.6, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:05:18.146273: step 279, loss 6.28385, accuracy 0.3125, precision [0.0, 0.2, 0.0, 0.5, nan, 0.0, 0.0, 1.0, nan], recall [nan, 0.5, 0.0, 0.5, 0.0, 0.0, nan, 0.4, nan]
2019-02-19T18:05:18.298827: step 280, loss 4.44259, accuracy 0.5625, precision [nan, 0.3333333333333333, 0.3333333333333333, 0.8, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.3333333333333333, 1.0, 1.0, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:05:18.451038: step 281, loss 2.00639, accuracy 0.625, precision [nan, 1.0, 0.75, 0.5, nan, 0.5, 1.0, 0.3333333333333333, nan], recall [nan, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0]
2019-02-19T18:05:18.604540: step 282, loss 3.99782, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.6, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.0, 0.75, 0.2, 0.0, nan, 0.5, nan]
2019-02-19T18:05:18.760332: step 283, loss 4.01598, accuracy 0.5625, precision [0.0, 1.0, 0.3333333333333333, 0.4, 1.0, 0.5, nan, nan, nan], recall [nan, 0.4, 1.0, 0.5, 0.75, 1.0, nan, 0.0, nan]
2019-02-19T18:05:18.917314: step 284, loss 2.8947, accuracy 0.5625, precision [0.0, 0.3333333333333333, 0.5, 0.8571428571428571, 1.0, nan, nan, 0.0, nan], recall [nan, 0.25, 1.0, 0.8571428571428571, 0.3333333333333333, nan, 0.0, nan, nan]
2019-02-19T18:05:19.066862: step 285, loss 3.335, accuracy 0.4375, precision [0.0, 1.0, nan, 0.3333333333333333, 0.0, nan, nan, 0.3333333333333333, nan], recall [nan, 0.6666666666666666, 0.0, 0.4, nan, nan, 0.0, 0.5, nan]
2019-02-19T18:05:19.222021: step 286, loss 5.56504, accuracy 0.375, precision [1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 1.0, nan, 0.0, 0.0], recall [0.5, 0.0, 0.3333333333333333, 0.2, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:05:19.377991: step 287, loss 5.92172, accuracy 0.4375, precision [0.0, 0.5, nan, 0.5, 1.0, nan, nan, 0.5, nan], recall [nan, 0.16666666666666666, nan, 0.5714285714285714, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:05:19.527051: step 288, loss 4.43133, accuracy 0.375, precision [0.3333333333333333, 0.5, 0.0, 0.5, 0.5, 0.0, nan, nan, nan], recall [1.0, 0.25, 0.0, 0.5, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T18:05:19.679054: step 289, loss 5.80173, accuracy 0.4375, precision [nan, 0.5, 0.0, 0.4, 1.0, nan, 0.0, 0.6666666666666666, 0.0], recall [nan, 0.2, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, nan]
2019-02-19T18:05:19.831214: step 290, loss 3.14074, accuracy 0.5, precision [0.0, 0.5, 0.6666666666666666, 0.5, 0.75, 0.0, 0.0, nan, nan], recall [0.0, 1.0, 0.5, 0.6666666666666666, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:05:19.984004: step 291, loss 5.58475, accuracy 0.1875, precision [0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, nan, nan, nan], recall [0.0, 1.0, 0.3333333333333333, 0.0, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:20.137068: step 292, loss 5.04942, accuracy 0.25, precision [nan, 0.0, nan, 0.42857142857142855, 0.0, 0.3333333333333333, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.375, nan, 1.0, 0.0, 0.0, nan]
2019-02-19T18:05:20.289880: step 293, loss 6.25727, accuracy 0.1875, precision [nan, 0.3333333333333333, nan, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.0, 0.0, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T18:05:20.446499: step 294, loss 4.92167, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.5, 0.5, 0.0, 0.0, 1.0, nan], recall [1.0, nan, 0.25, 0.6, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:20.601934: step 295, loss 5.17834, accuracy 0.5, precision [1.0, 0.2, 1.0, 0.75, nan, nan, nan, 0.0, nan], recall [0.6666666666666666, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:20.751276: step 296, loss 6.15272, accuracy 0.375, precision [nan, 0.0, 1.0, 0.5, 0.75, nan, 0.0, 0.0, nan], recall [0.0, nan, 1.0, 0.4, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:20.906115: step 297, loss 2.72441, accuracy 0.3125, precision [0.5, 0.0, nan, 0.3333333333333333, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.25, 0.0, nan, 0.4, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:21.062372: step 298, loss 4.38792, accuracy 0.4375, precision [nan, 0.25, 0.5, 0.6, 1.0, 0.0, nan, 1.0, 0.0], recall [nan, 1.0, 1.0, 0.375, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:05:21.216098: step 299, loss 6.0004, accuracy 0.25, precision [nan, 0.5, 0.0, 0.5, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.25, nan, 0.2, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T18:05:21.376301: step 300, loss 4.01895, accuracy 0.375, precision [0.0, 0.0, nan, 0.6666666666666666, 0.0, nan, 0.0, 0.0, nan], recall [0.0, nan, nan, 0.6, 0.0, nan, nan, nan, 0.0]
2019-02-19T18:05:21.531563: step 301, loss 5.03796, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:21.687909: step 302, loss 4.18823, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.625, 0.0, 0.0, nan, 0.0, 0.0], recall [nan, 0.0, 0.0, 0.625, nan, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:21.842186: step 303, loss 5.11033, accuracy 0.375, precision [nan, 1.0, nan, 0.2857142857142857, 0.4, 1.0, 0.0, nan, 0.0], recall [0.0, 0.2, nan, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, nan]
2019-02-19T18:05:21.999091: step 304, loss 4.93633, accuracy 0.375, precision [0.0, 0.6666666666666666, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, nan], recall [nan, 0.4, nan, 0.2, 1.0, 1.0, nan, 0.0, 0.0]
2019-02-19T18:05:22.153010: step 305, loss 2.06272, accuracy 0.5625, precision [0.5, 1.0, 0.0, 1.0, 0.6666666666666666, nan, 0.0, 0.0, 0.0], recall [1.0, 0.5, nan, 0.3333333333333333, 0.8, nan, nan, nan, nan]
2019-02-19T18:05:22.306861: step 306, loss 3.96004, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.25, nan], recall [1.0, 0.3333333333333333, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:05:22.456594: step 307, loss 6.59784, accuracy 0.4375, precision [nan, 0.6, 0.0, 0.5, nan, nan, 0.5, nan, 0.0], recall [0.0, 0.6, nan, 0.5, nan, 0.0, 1.0, 0.0, nan]
2019-02-19T18:05:22.610328: step 308, loss 5.21598, accuracy 0.4375, precision [0.5, 0.5, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.3333333333333333, nan, 0.4, 0.6666666666666666, nan, 0.0, nan, nan]
2019-02-19T18:05:22.761873: step 309, loss 3.67618, accuracy 0.375, precision [nan, 0.5, nan, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.0, nan], recall [nan, 0.5, 0.0, 0.2857142857142857, 0.6666666666666666, nan, 0.5, 0.0, nan]
2019-02-19T18:05:22.916347: step 310, loss 4.77057, accuracy 0.25, precision [nan, 0.0, 0.5, 0.2857142857142857, nan, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, nan, 0.25, 0.0]
2019-02-19T18:05:23.067810: step 311, loss 5.36374, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, nan], recall [nan, 1.0, 0.0, 0.0, 1.0, nan, 0.0, 0.25, nan]
2019-02-19T18:05:23.221513: step 312, loss 7.06452, accuracy 0.4375, precision [0.5, 0.0, nan, 0.8, 0.3333333333333333, 0.0, 0.0, nan, nan], recall [1.0, nan, 0.0, 0.6666666666666666, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T18:05:23.374417: step 313, loss 5.80989, accuracy 0.375, precision [0.3333333333333333, 0.6666666666666666, nan, 0.25, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [1.0, 0.4, nan, 0.25, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T18:05:23.530677: step 314, loss 3.81962, accuracy 0.6875, precision [0.0, 0.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, nan, 1.0, nan], recall [nan, nan, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:05:23.688741: step 315, loss 1.76338, accuracy 0.5625, precision [nan, 1.0, 0.5, 0.6666666666666666, 0.25, 0.0, 1.0, nan, nan], recall [0.0, 1.0, 0.3333333333333333, 0.8, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:05:23.839787: step 316, loss 2.51184, accuracy 0.3125, precision [0.0, 0.0, 0.3333333333333333, 0.5, 0.5, 0.0, nan, 1.0, 0.0], recall [0.0, 0.0, 1.0, 0.25, 0.5, nan, nan, 0.4, nan]
2019-02-19T18:05:23.993083: step 317, loss 3.28934, accuracy 0.4375, precision [0.0, 0.0, 1.0, 1.0, 0.5, 0.0, nan, 1.0, nan], recall [0.0, 0.0, 0.6666666666666666, 0.42857142857142855, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:24.143864: step 318, loss 6.06279, accuracy 0.5, precision [0.3333333333333333, 0.0, nan, 0.6, 1.0, nan, 0.5, 0.0, nan], recall [0.3333333333333333, 0.0, nan, 0.6, 1.0, 0.0, 0.5, nan, 0.0]
2019-02-19T18:05:24.292001: step 319, loss 3.39343, accuracy 0.375, precision [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, nan, nan, 0.3333333333333333, 0.0], recall [0.0, 0.6666666666666666, 0.5, 0.0, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T18:05:24.444971: step 320, loss 2.46027, accuracy 0.5625, precision [nan, 0.3333333333333333, 0.6666666666666666, 0.6, 1.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.6666666666666666, 0.6, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:24.595957: step 321, loss 4.70342, accuracy 0.5, precision [0.6666666666666666, 0.0, nan, 0.25, 0.8, 1.0, nan, 0.0, 0.0], recall [0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:05:24.748811: step 322, loss 6.02997, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.5, 0.6666666666666666, nan, 0.0, 0.5, 0.0], recall [0.0, 0.5, nan, 0.4, 0.5, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:24.900626: step 323, loss 5.37598, accuracy 0.375, precision [nan, 0.5, 0.0, 0.6, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.6, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:05:25.054977: step 324, loss 4.29056, accuracy 0.5625, precision [0.0, 0.4, 0.6666666666666666, 1.0, 1.0, nan, 0.0, 1.0, nan], recall [0.0, 1.0, 1.0, 0.3333333333333333, 0.2, nan, nan, 1.0, nan]
2019-02-19T18:05:25.208751: step 325, loss 2.57708, accuracy 0.375, precision [1.0, 0.3333333333333333, nan, 0.16666666666666666, 0.75, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 0.0, 0.25, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:25.360125: step 326, loss 4.23799, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.0, 0.6666666666666666, nan, 0.0, 0.5, nan], recall [1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:05:25.511191: step 327, loss 2.14406, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.6, 0.75, 0.0, 0.0, 1.0, nan], recall [0.0, 0.5, 0.5, 0.75, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:05:25.662524: step 328, loss 3.39699, accuracy 0.5625, precision [1.0, 1.0, 0.5, 0.6, 0.5, nan, 0.0, 0.0, nan], recall [0.6666666666666666, 0.5, 1.0, 0.75, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T18:05:25.814020: step 329, loss 5.5839, accuracy 0.1875, precision [nan, 0.0, 0.3333333333333333, 0.2, 0.25, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.5, 0.3333333333333333, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T18:05:25.967233: step 330, loss 4.6301, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.2, 0.6, nan, nan, 0.5, nan], recall [0.3333333333333333, 0.5, 0.0, 0.25, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:05:26.117163: step 331, loss 3.98532, accuracy 0.5, precision [0.6, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.75, 0.0, 0.5, 0.3333333333333333, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:05:26.272108: step 332, loss 6.33559, accuracy 0.25, precision [0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [0.3333333333333333, 0.25, nan, 0.14285714285714285, 0.5, nan, nan, nan, nan]
2019-02-19T18:05:26.429484: step 333, loss 3.17233, accuracy 0.25, precision [0.0, nan, 0.0, 0.8, 0.0, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.5, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:26.586380: step 334, loss 3.98851, accuracy 0.625, precision [nan, 1.0, 0.6666666666666666, 0.5714285714285714, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.6, 0.6666666666666666, 1.0, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:26.742116: step 335, loss 2.41837, accuracy 0.625, precision [0.5, 0.3333333333333333, nan, 0.75, 1.0, 0.0, 1.0, nan, nan], recall [0.5, 0.2, 0.0, 1.0, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:05:26.894310: step 336, loss 5.69876, accuracy 0.4375, precision [nan, 1.0, 0.0, 0.5, 0.4, 0.0, nan, nan, nan], recall [nan, 0.75, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T18:05:27.049817: step 337, loss 1.5995, accuracy 0.5625, precision [1.0, nan, 0.0, 0.4, 0.8333333333333334, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.0, 0.0, 0.5, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:05:27.204739: step 338, loss 5.21023, accuracy 0.5, precision [nan, 0.5, 0.0, 1.0, 0.0, nan, nan, 0.5, nan], recall [0.0, 1.0, nan, 0.5, nan, nan, nan, 1.0, 0.0]
2019-02-19T18:05:27.358134: step 339, loss 4.10624, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.6666666666666666, 0.4, nan, nan, 0.5, nan], recall [nan, 0.5, 0.0, 0.25, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:05:27.507217: step 340, loss 5.20383, accuracy 0.3125, precision [0.25, 0.0, 0.0, 0.5714285714285714, nan, 0.0, 0.0, nan, nan], recall [0.3333333333333333, 0.0, 0.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:05:27.665188: step 341, loss 6.66129, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.25, nan], recall [0.0, nan, 0.0, 0.42857142857142855, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:27.822837: step 342, loss 6.84562, accuracy 0.25, precision [0.0, nan, 0.0, 0.5, 0.3333333333333333, 0.0, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 0.0, 0.3333333333333333, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:05:27.978701: step 343, loss 3.55375, accuracy 0.4375, precision [nan, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, nan], recall [nan, 0.0, 0.3333333333333333, 0.5714285714285714, 0.0, nan, 0.5, 0.5, nan]
2019-02-19T18:05:28.134539: step 344, loss 7.68183, accuracy 0.375, precision [nan, 0.0, 0.5, 0.6666666666666666, 0.3333333333333333, nan, 0.0, nan, 0.0], recall [0.0, 0.0, 0.5, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:28.290860: step 345, loss 3.11214, accuracy 0.625, precision [0.3333333333333333, nan, 0.0, 1.0, 0.8333333333333334, nan, nan, 0.5, nan], recall [1.0, nan, 0.0, 0.5, 0.8333333333333334, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:05:28.443447: step 346, loss 3.90667, accuracy 0.3125, precision [0.5, nan, 0.0, 0.5, nan, 0.0, 0.0, nan, 0.0], recall [0.6666666666666666, 0.0, 0.0, 0.6, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:05:28.604583: step 347, loss 5.09977, accuracy 0.4375, precision [0.0, 0.4, 1.0, 0.2, 1.0, nan, 1.0, 0.0, nan], recall [0.0, 0.6666666666666666, 1.0, 0.25, 0.6666666666666666, 0.0, 1.0, 0.0, nan]
2019-02-19T18:05:28.755367: step 348, loss 4.76326, accuracy 0.5, precision [nan, 0.0, 0.5, 0.8333333333333334, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, nan, 1.0, 0.7142857142857143, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:28.916041: step 349, loss 3.39137, accuracy 0.375, precision [0.0, 0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, nan], recall [nan, 0.5, 1.0, 0.2, 0.4, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:05:29.076031: step 350, loss 3.93507, accuracy 0.375, precision [0.0, nan, nan, 0.0, 0.75, 0.0, 0.5, 0.5, nan], recall [nan, 0.0, 0.0, 0.0, 0.75, 0.0, 1.0, 0.5, nan]
2019-02-19T18:05:29.228642: step 351, loss 4.32775, accuracy 0.4375, precision [0.3333333333333333, 1.0, 1.0, 0.0, 0.75, nan, nan, nan, 0.0], recall [0.5, 1.0, 0.25, nan, 0.6, 0.0, nan, 0.0, nan]
2019-02-19T18:05:29.381607: step 352, loss 4.75876, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.5, 0.16666666666666666, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 1.0, 1.0, 0.25, 0.2857142857142857, 0.0, nan, nan, nan]
2019-02-19T18:05:29.538062: step 353, loss 4.12703, accuracy 0.4375, precision [0.3333333333333333, 0.0, 0.5, 0.4, 1.0, nan, nan, nan, 0.0], recall [1.0, nan, 0.5, 0.4, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T18:05:29.692160: step 354, loss 3.99398, accuracy 0.3125, precision [0.0, 0.75, 0.0, 0.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.75, 0.0, 0.0, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:05:29.848917: step 355, loss 4.12903, accuracy 0.5, precision [1.0, 0.5, 0.5, 0.3333333333333333, 0.3333333333333333, nan, 0.0, 0.6666666666666666, 1.0], recall [0.5, 0.5, 0.5, 0.25, 0.3333333333333333, nan, nan, 1.0, 1.0]
2019-02-19T18:05:30.012102: step 356, loss 4.58869, accuracy 0.25, precision [0.0, 0.0, 1.0, 0.3333333333333333, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:05:30.166280: step 357, loss 6.02177, accuracy 0.3125, precision [nan, 0.0, 0.5, 0.4, 1.0, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, nan, 0.5, 1.0, 0.5, 0.0, nan, 0.25, 0.0]
2019-02-19T18:05:30.319153: step 358, loss 4.52775, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, nan, nan, nan], recall [0.3333333333333333, 0.5, 0.0, 0.3333333333333333, 1.0, nan, nan, nan, nan]
2019-02-19T18:05:30.469640: step 359, loss 3.13648, accuracy 0.625, precision [0.6666666666666666, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [1.0, 0.3333333333333333, 1.0, 0.6, 0.6666666666666666, nan, nan, 1.0, 0.0]
2019-02-19T18:05:30.619503: step 360, loss 5.19056, accuracy 0.4375, precision [0.0, 0.0, nan, 0.75, 1.0, 0.0, nan, 0.6666666666666666, 0.0], recall [nan, 0.0, nan, 0.42857142857142855, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:05:30.775872: step 361, loss 3.61726, accuracy 0.4375, precision [0.0, 0.3333333333333333, nan, 0.42857142857142855, 1.0, nan, 0.5, 0.5, nan], recall [0.0, 0.5, 0.0, 0.42857142857142855, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:05:30.928193: step 362, loss 4.21863, accuracy 0.4375, precision [1.0, nan, 0.5, 0.3333333333333333, 0.5, nan, 0.0, 0.5, nan], recall [1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:05:31.085053: step 363, loss 7.59896, accuracy 0.25, precision [0.0, 0.25, nan, 0.4, 0.0, 0.5, 0.0, nan, 0.0], recall [0.0, 0.2, nan, 0.6666666666666666, 0.0, 0.5, nan, 0.0, nan]
2019-02-19T18:05:31.236457: step 364, loss 3.96069, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, nan, nan, 0.25, 0.0], recall [0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:05:31.395451: step 365, loss 2.21009, accuracy 0.75, precision [nan, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, nan, 0.7, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:05:31.551815: step 366, loss 4.87725, accuracy 0.3125, precision [0.0, nan, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.5, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:05:31.704610: step 367, loss 4.93933, accuracy 0.375, precision [0.0, 0.5, 1.0, 0.16666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.25, 0.5, nan, 0.0, 0.3333333333333333, 0.0]
2019-02-19T18:05:31.861086: step 368, loss 4.41035, accuracy 0.25, precision [1.0, 0.0, nan, 0.125, 0.0, 0.0, nan, 1.0, 0.0], recall [0.5, nan, nan, 0.3333333333333333, 0.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:05:32.010886: step 369, loss 2.71961, accuracy 0.375, precision [0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.5714285714285714, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:32.160573: step 370, loss 5.34765, accuracy 0.4375, precision [1.0, 0.6666666666666666, 0.0, 1.0, 0.5, nan, 0.0, 0.2, nan], recall [1.0, 1.0, nan, 0.14285714285714285, 0.6666666666666666, 0.0, 0.0, 1.0, nan]
2019-02-19T18:05:32.307915: step 371, loss 2.27236, accuracy 0.5625, precision [0.0, 0.5, nan, 1.0, 0.5, nan, nan, 0.3333333333333333, nan], recall [0.0, 0.5, nan, 0.5714285714285714, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:05:32.463051: step 372, loss 2.03852, accuracy 0.4375, precision [0.5, 0.25, 1.0, 0.16666666666666666, 1.0, nan, nan, 1.0, nan], recall [0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:05:32.617165: step 373, loss 5.13934, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.3333333333333333, 0.5, 0.0, nan, nan, nan], recall [0.0, 1.0, nan, 0.2, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:32.773753: step 374, loss 5.68423, accuracy 0.3125, precision [nan, 0.25, 0.0, 0.6666666666666666, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.25, 0.0, 0.5714285714285714, nan, nan, nan, 0.0, nan]
2019-02-19T18:05:32.926784: step 375, loss 9.76081, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, nan, 0.0], recall [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:05:33.080748: step 376, loss 3.47756, accuracy 0.5, precision [nan, 0.0, 0.5, 1.0, 1.0, 0.5, nan, 0.6666666666666666, nan], recall [0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, nan, 0.6666666666666666, 0.0]
2019-02-19T18:05:33.232359: step 377, loss 2.88083, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, nan, 0.0], recall [0.0, 0.4, 1.0, 0.4, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:05:33.387731: step 378, loss 4.22692, accuracy 0.125, precision [0.0, 0.3333333333333333, 0.0, 0.16666666666666666, nan, 0.0, 0.0, 0.0, nan], recall [nan, 0.5, 0.0, 0.14285714285714285, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:05:33.543183: step 379, loss 6.56592, accuracy 0.4375, precision [0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.3333333333333333, 1.0, 0.2, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:05:33.695385: step 380, loss 3.72895, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.2, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.42857142857142855, 0.0, 0.5, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:05:33.851080: step 381, loss 6.05538, accuracy 0.25, precision [nan, 0.25, nan, 0.14285714285714285, 0.5, 0.0, nan, 1.0, 0.0], recall [nan, 0.2, 0.0, 0.5, 0.25, 0.0, 0.0, 0.5, nan]
2019-02-19T18:05:34.011383: step 382, loss 3.46029, accuracy 0.375, precision [0.0, 0.0, nan, 0.6666666666666666, 0.5, 0.5, nan, nan, nan], recall [nan, 0.0, 0.0, 0.5714285714285714, 1.0, 0.5, nan, 0.0, nan]
2019-02-19T18:05:34.165414: step 383, loss 2.70962, accuracy 0.4375, precision [0.5, 0.3333333333333333, 0.0, 0.3333333333333333, 0.75, 0.0, nan, 0.5, nan], recall [0.5, 0.5, 0.0, 0.5, 1.0, nan, 0.0, 0.25, nan]
2019-02-19T18:05:34.320571: step 384, loss 5.91876, accuracy 0.3125, precision [0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, 0.0], recall [nan, 0.2857142857142857, 0.5, 0.2, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:34.479468: step 385, loss 3.48701, accuracy 0.4375, precision [nan, 1.0, 0.5, 0.4, 0.0, 0.5, nan, 0.25, nan], recall [0.0, 0.4, 1.0, 0.5, nan, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T18:05:34.633763: step 386, loss 3.95648, accuracy 0.375, precision [nan, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.8, nan, 0.0, nan, 0.0, nan]
2019-02-19T18:05:34.784381: step 387, loss 3.68941, accuracy 0.5625, precision [0.5, 1.0, 1.0, 0.5, 0.6, 0.0, nan, 0.0, nan], recall [0.5, 0.4, 0.5, 1.0, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:34.938187: step 388, loss 2.77325, accuracy 0.5625, precision [0.0, 1.0, nan, 0.5, 0.8, 0.0, nan, nan, nan], recall [nan, 1.0, nan, 0.6666666666666666, 0.8, 0.0, nan, 0.0, nan]
2019-02-19T18:05:35.091233: step 389, loss 2.4735, accuracy 0.625, precision [0.0, nan, 0.5, 0.7142857142857143, 1.0, 1.0, nan, 1.0, 0.0], recall [nan, 0.0, 0.5, 1.0, 0.6666666666666666, 0.5, nan, 0.5, nan]
2019-02-19T18:05:35.243714: step 390, loss 2.22308, accuracy 0.5625, precision [0.3333333333333333, 0.5, 1.0, 0.6, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.5, 0.5, 1.0, 0.6, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T18:05:35.400209: step 391, loss 6.10295, accuracy 0.3125, precision [0.0, 0.25, nan, 0.0, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 0.5, nan, 0.0, 0.8, 0.0, nan, 0.0, nan]
2019-02-19T18:05:35.552916: step 392, loss 3.72466, accuracy 0.4375, precision [nan, 0.2, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [0.0, 1.0, 1.0, 0.42857142857142855, 0.4, nan, nan, nan, nan]
2019-02-19T18:05:35.702745: step 393, loss 3.10389, accuracy 0.5625, precision [0.5, 0.0, nan, 1.0, 0.6, nan, 0.0, 0.0, nan], recall [0.5, nan, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:05:35.854222: step 394, loss 4.65396, accuracy 0.25, precision [0.0, 0.5, 0.0, 0.5, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.5, 0.25, 0.0, nan, nan, nan]
2019-02-19T18:05:36.006838: step 395, loss 2.30582, accuracy 0.75, precision [nan, 0.0, 0.6666666666666666, 0.75, 1.0, nan, nan, 1.0, nan], recall [nan, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:05:36.158912: step 396, loss 4.29527, accuracy 0.3125, precision [0.2, nan, nan, 0.75, 0.5, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, 0.0, 0.6, 0.5, 0.0, nan, nan, 0.0]
2019-02-19T18:05:36.314002: step 397, loss 4.79321, accuracy 0.4375, precision [nan, nan, 1.0, 0.5, 0.5, 0.0, nan, 0.0, nan], recall [0.0, nan, 1.0, 0.2857142857142857, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:05:36.471302: step 398, loss 4.66801, accuracy 0.3125, precision [nan, 0.0, 0.5, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 1.0, nan, 0.0, nan]
2019-02-19T18:05:36.625243: step 399, loss 4.03938, accuracy 0.4375, precision [0.5, 0.5, 0.5, 1.0, 0.0, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 1.0, 0.6666666666666666, 0.42857142857142855, nan, nan, nan, 0.0, nan]
2019-02-19T18:05:36.782105: step 400, loss 2.65114, accuracy 0.5, precision [nan, 0.0, 1.0, 0.42857142857142855, 1.0, nan, 0.0, 0.0, nan], recall [0.0, nan, 0.4, 0.75, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:05:36.935568: step 401, loss 3.71524, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.5, 0.5, nan, nan, nan, 0.0], recall [0.0, nan, 0.0, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:05:37.092886: step 402, loss 1.91513, accuracy 0.5, precision [1.0, 1.0, 0.3333333333333333, 0.2857142857142857, 1.0, nan, nan, nan, 0.0], recall [0.5, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:05:37.244763: step 403, loss 2.98402, accuracy 0.5625, precision [0.6666666666666666, 0.0, nan, nan, 0.5714285714285714, 1.0, 1.0, 0.5, nan], recall [1.0, nan, 0.0, 0.0, 1.0, 0.25, 1.0, 1.0, nan]
2019-02-19T18:05:37.395706: step 404, loss 5.83108, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.5, nan, nan, nan, 0.5, nan], recall [0.0, 0.0, 0.0, 0.375, 0.0, nan, nan, 1.0, 0.0]
2019-02-19T18:05:37.552878: step 405, loss 3.59233, accuracy 0.4375, precision [nan, 0.2, nan, 0.6, 1.0, 0.0, 1.0, 0.5, nan], recall [0.0, 0.5, 0.0, 0.42857142857142855, 1.0, nan, 1.0, 1.0, 0.0]
2019-02-19T18:05:37.703023: step 406, loss 2.16246, accuracy 0.5, precision [0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, nan, 0.6, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:37.862611: step 407, loss 3.61466, accuracy 0.5, precision [0.0, nan, nan, 0.7777777777777778, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.0, nan, 0.7777777777777778, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:05:38.018387: step 408, loss 2.81206, accuracy 0.4375, precision [nan, 0.6, 1.0, 0.0, 0.5, nan, nan, 0.5, nan], recall [0.0, 0.6, 0.3333333333333333, nan, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:05:38.176330: step 409, loss 5.95468, accuracy 0.25, precision [0.0, 0.0, nan, 0.5, nan, 0.0, nan, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.42857142857142855, nan, nan, 0.0, 0.5, 0.0]
2019-02-19T18:05:38.328304: step 410, loss 2.89047, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.8, 0.5, 0.0, 0.0, 1.0, nan], recall [nan, nan, 0.0, 0.5714285714285714, 0.5, 0.0, 0.0, 0.3333333333333333, 0.0]
2019-02-19T18:05:38.478508: step 411, loss 1.99908, accuracy 0.5625, precision [0.0, 1.0, 0.5, 0.625, 1.0, nan, 0.0, nan, nan], recall [nan, 0.3333333333333333, 1.0, 0.625, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:38.639112: step 412, loss 4.84996, accuracy 0.3125, precision [0.5, 0.5, 0.0, 0.0, nan, 0.0, nan, nan, nan], recall [0.5, 0.5, 0.0, 0.0, nan, nan, nan, 0.0, nan]
2019-02-19T18:05:38.792166: step 413, loss 3.92959, accuracy 0.4375, precision [1.0, 0.25, 0.5, 0.0, 0.6666666666666666, nan, 0.0, nan, nan], recall [0.5, 0.3333333333333333, 0.5, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:38.948483: step 414, loss 2.68443, accuracy 0.5625, precision [0.0, 0.5, 0.0, 0.8, 0.6666666666666666, 0.0, nan, nan, nan], recall [0.0, 0.5, nan, 0.5714285714285714, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:05:39.102775: step 415, loss 3.7501, accuracy 0.5, precision [nan, 0.5, 1.0, 0.25, 0.5, nan, 0.0, 1.0, nan], recall [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, nan, 0.6666666666666666, 0.0]
2019-02-19T18:05:39.257218: step 416, loss 3.69305, accuracy 0.5, precision [1.0, 0.6, 0.0, 0.4, 0.5, nan, 0.0, nan, nan], recall [0.6666666666666666, 0.6, nan, 1.0, 0.25, nan, nan, 0.0, 0.0]
2019-02-19T18:05:39.412431: step 417, loss 2.67746, accuracy 0.5625, precision [0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 1.0, 0.8, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:05:39.570744: step 418, loss 2.83524, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.8, 0.6666666666666666, nan, nan, 0.3333333333333333, 0.0], recall [0.6666666666666666, 1.0, nan, 0.8, 0.4, nan, nan, 0.5, nan]
2019-02-19T18:05:39.725910: step 419, loss 5.86266, accuracy 0.5, precision [0.6666666666666666, 1.0, 0.0, 0.6, 1.0, nan, nan, 0.0, nan], recall [0.6666666666666666, 0.6666666666666666, nan, 0.5, 0.5, nan, nan, nan, 0.0]
2019-02-19T18:05:39.882025: step 420, loss 4.53195, accuracy 0.375, precision [0.25, 0.0, 0.0, 0.4, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.5, 0.0, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.5, nan]
2019-02-19T18:05:40.032778: step 421, loss 6.32217, accuracy 0.375, precision [1.0, nan, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0], recall [0.6, 0.0, nan, 0.6, 0.0, nan, nan, nan, nan]
2019-02-19T18:05:40.186597: step 422, loss 4.24992, accuracy 0.375, precision [nan, 0.25, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 1.0, nan], recall [0.0, 0.5, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:40.337263: step 423, loss 3.96161, accuracy 0.4375, precision [0.5, 0.6, 0.0, nan, 0.6, nan, 0.0, 0.0, nan], recall [0.3333333333333333, 0.6, nan, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:40.487673: step 424, loss 4.74322, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0], recall [0.2, 0.0, nan, 0.5, 0.4, nan, nan, nan, nan]
2019-02-19T18:05:40.644666: step 425, loss 4.24755, accuracy 0.3125, precision [0.0, nan, 0.0, 0.4, 1.0, 0.0, 0.5, 0.0, nan], recall [0.0, 0.0, 0.0, 0.5, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:05:40.800488: step 426, loss 2.55859, accuracy 0.4375, precision [0.5, 0.0, nan, 0.5, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.0, nan, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 0.0]
2019-02-19T18:05:40.951302: step 427, loss 4.28053, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.2, 1.0, 1.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.6666666666666666, nan]
2019-02-19T18:05:41.111601: step 428, loss 5.62726, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.4, 0.5, nan, 0.0, 0.0, nan], recall [nan, 0.0, 1.0, 0.4, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:05:41.263614: step 429, loss 2.56928, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.42857142857142855, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.0, nan, 1.0, 0.6, 1.0, 0.0, nan, 0.2, nan]
2019-02-19T18:05:41.415724: step 430, loss 4.50742, accuracy 0.3125, precision [0.6666666666666666, 0.0, 0.0, 0.6, 0.0, nan, nan, 0.0, 0.0], recall [1.0, 0.0, nan, 0.375, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:41.572341: step 431, loss 2.8062, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.6666666666666666, 0.4, nan, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.5, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:05:41.724801: step 432, loss 2.87307, accuracy 0.4375, precision [0.5, 0.0, nan, 0.6666666666666666, 0.5, 0.5, 0.0, 0.0, nan], recall [0.5, nan, 0.0, 0.5, 0.5, 1.0, nan, 0.0, nan]
2019-02-19T18:05:41.879201: step 433, loss 5.56801, accuracy 0.375, precision [0.4, 0.0, nan, 0.3333333333333333, 0.75, 0.0, nan, nan, 0.0], recall [1.0, nan, 0.0, 0.25, 0.6, nan, 0.0, 0.0, nan]
2019-02-19T18:05:42.039268: step 434, loss 3.25783, accuracy 0.5625, precision [0.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.0, nan, 0.0, 0.0], recall [nan, 1.0, 0.6666666666666666, 0.8333333333333334, 0.3333333333333333, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:42.200865: step 435, loss 2.25505, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.6666666666666666, 0.5, nan, nan, 1.0, nan], recall [0.0, 0.25, 1.0, 0.8, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:05:42.355518: step 436, loss 2.86502, accuracy 0.4375, precision [0.5, 0.5, 1.0, 0.25, 0.75, nan, 0.0, 0.0, nan], recall [1.0, 0.3333333333333333, 0.2, 1.0, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T18:05:42.511041: step 437, loss 7.21237, accuracy 0.3125, precision [0.6666666666666666, 0.5, 0.0, 0.25, nan, 1.0, nan, nan, 0.0], recall [1.0, 0.25, 0.0, 0.25, nan, 0.3333333333333333, 0.0, nan, nan]
2019-02-19T18:05:42.664433: step 438, loss 3.59756, accuracy 0.5625, precision [nan, 0.0, nan, 0.7142857142857143, 1.0, 0.0, nan, 0.5, nan], recall [nan, nan, 0.0, 0.8333333333333334, 0.6666666666666666, nan, 0.0, 0.4, nan]
2019-02-19T18:05:42.815284: step 439, loss 3.61882, accuracy 0.5625, precision [0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 1.0, 1.0, 0.42857142857142855, 0.8, nan, 0.0, nan, nan]
2019-02-19T18:05:42.972556: step 440, loss 3.6395, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.3333333333333333, 0.5, nan, 0.0, 0.0, nan], recall [nan, 0.75, 0.5, 0.25, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:05:43.132358: step 441, loss 2.33261, accuracy 0.6875, precision [nan, 0.6666666666666666, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T18:05:43.290790: step 442, loss 3.89666, accuracy 0.1875, precision [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.14285714285714285, 0.0, 0.0, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:05:43.441955: step 443, loss 3.08228, accuracy 0.4375, precision [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, nan, 0.0], recall [1.0, nan, nan, 0.42857142857142855, 0.75, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:43.595638: step 444, loss 2.87582, accuracy 0.4375, precision [nan, 0.0, 0.5, 0.375, 1.0, nan, nan, 0.0, nan], recall [0.0, nan, 1.0, 0.5, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:05:43.746340: step 445, loss 3.15599, accuracy 0.375, precision [1.0, 1.0, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.3333333333333333, 1.0, 0.0, 0.2857142857142857, 0.6666666666666666, nan, nan, nan, 0.0]
2019-02-19T18:05:43.898187: step 446, loss 3.15156, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.5, 0.5, nan, 0.0, nan, 1.0], recall [nan, 0.0, 0.3333333333333333, 0.6, 1.0, nan, nan, nan, 0.2]
2019-02-19T18:05:44.052393: step 447, loss 2.48597, accuracy 0.5625, precision [nan, 0.4, 0.0, 0.75, 1.0, nan, 0.0, nan, nan], recall [nan, 0.6666666666666666, nan, 0.42857142857142855, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:44.205955: step 448, loss 4.81614, accuracy 0.25, precision [0.0, 0.0, 0.6666666666666666, 0.2857142857142857, 0.0, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.5, 0.4, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:44.364582: step 449, loss 3.60975, accuracy 0.5625, precision [1.0, 1.0, 0.5, 0.0, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.3333333333333333, 1.0, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:44.518677: step 450, loss 3.63522, accuracy 0.4375, precision [0.5, 0.5, nan, 0.4444444444444444, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 1.0, nan, 0.5, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:44.674975: step 451, loss 2.73609, accuracy 0.5625, precision [0.0, 0.25, 0.0, 1.0, 1.0, nan, nan, 0.3333333333333333, nan], recall [nan, 1.0, 0.0, 0.5, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:05:44.827244: step 452, loss 3.03633, accuracy 0.4375, precision [0.0, 0.5, 0.6666666666666666, 0.25, 0.75, nan, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.5, 0.25, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:44.981371: step 453, loss 2.36569, accuracy 0.5, precision [nan, 0.0, 0.5, 0.5, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 1.0, 0.8, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:05:45.135557: step 454, loss 2.9273, accuracy 0.5625, precision [1.0, 0.5, 0.5, 0.6, 0.6666666666666666, nan, nan, 0.3333333333333333, nan], recall [0.25, 1.0, 1.0, 0.6, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:05:45.292343: step 455, loss 2.1167, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.5, 0.0], recall [0.5, 0.4, nan, 0.75, 1.0, nan, 0.0, 0.5, 0.0]
2019-02-19T18:05:45.445580: step 456, loss 3.1826, accuracy 0.3125, precision [nan, 0.5, nan, 0.2, 0.3333333333333333, 1.0, nan, 0.0, 0.0], recall [0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, nan, 0.0, nan]
2019-02-19T18:05:45.598229: step 457, loss 2.39873, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 0.5, 0.0, nan], recall [nan, 0.5, 1.0, 0.5714285714285714, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:05:45.756387: step 458, loss 3.07828, accuracy 0.3125, precision [nan, 0.6666666666666666, nan, 0.2, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.2, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:05:45.905318: step 459, loss 3.98928, accuracy 0.3125, precision [0.25, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, nan, 0.0, 0.0, 0.0], recall [0.25, 0.5, nan, 0.5, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T18:05:46.059794: step 460, loss 3.44537, accuracy 0.4375, precision [1.0, 0.25, 0.0, 1.0, 0.3333333333333333, nan, 0.5, 0.6666666666666666, nan], recall [0.5, 1.0, nan, 0.2, 0.5, nan, 1.0, 0.4, nan]
2019-02-19T18:05:46.211584: step 461, loss 0.988181, accuracy 0.6875, precision [0.0, 0.6666666666666666, 0.5, 1.0, 0.75, nan, 0.0, nan, nan], recall [nan, 0.6666666666666666, 1.0, 0.7142857142857143, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:46.368142: step 462, loss 1.76941, accuracy 0.5, precision [0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [0.5, 0.0, nan, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:05:46.521518: step 463, loss 5.39825, accuracy 0.5, precision [nan, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:46.676841: step 464, loss 3.87066, accuracy 0.5625, precision [0.5, 1.0, nan, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.6666666666666666, 0.0, 0.75, 0.4, 0.0, nan, nan, nan]
2019-02-19T18:05:46.831917: step 465, loss 5.56661, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.8, 1.0, nan, 0.0, 0.0, 0.0], recall [0.0, 0.3333333333333333, 0.0, 0.5, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:05:46.986100: step 466, loss 2.74458, accuracy 0.5, precision [nan, 1.0, 1.0, 0.5, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.5, 1.0, 0.42857142857142855, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:47.144095: step 467, loss 5.70833, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, nan, 0.5, 0.0, 0.0], recall [0.2, 0.0, nan, 0.6666666666666666, 0.5, nan, 0.5, 0.0, nan]
2019-02-19T18:05:47.295392: step 468, loss 4.73015, accuracy 0.3125, precision [0.3333333333333333, 0.6, nan, 0.0, 0.3333333333333333, 0.0, nan, 0.0, 0.0], recall [0.5, 0.42857142857142855, 0.0, 0.0, 1.0, nan, nan, nan, nan]
2019-02-19T18:05:47.447432: step 469, loss 4.2611, accuracy 0.1875, precision [0.0, 0.0, 0.3333333333333333, 0.3333333333333333, nan, nan, nan, 0.0, 0.0], recall [0.0, 0.0, 0.25, 0.4, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:05:47.604900: step 470, loss 7.11882, accuracy 0.1875, precision [nan, nan, 0.0, 0.0, 0.6, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.0, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T18:05:47.760175: step 471, loss 4.10331, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.5714285714285714, 0.6666666666666666, 0.0, nan, nan, nan], recall [nan, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:05:47.912477: step 472, loss 4.79727, accuracy 0.1875, precision [0.0, 0.6666666666666666, nan, 0.14285714285714285, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, nan, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:48.071805: step 473, loss 4.18317, accuracy 0.5, precision [0.3333333333333333, nan, nan, 1.0, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.0, 0.0, 0.75, 0.6666666666666666, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:48.221795: step 474, loss 4.48566, accuracy 0.5625, precision [nan, 0.0, 0.75, 0.6, 0.75, nan, nan, 0.0, nan], recall [nan, 0.0, 1.0, 0.75, 0.6, nan, 0.0, nan, nan]
2019-02-19T18:05:48.377378: step 475, loss 4.07548, accuracy 0.625, precision [nan, 0.5, 1.0, 0.42857142857142855, 1.0, nan, nan, 0.5, nan], recall [nan, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:05:48.530656: step 476, loss 3.777, accuracy 0.625, precision [1.0, 0.5, nan, 0.5, 0.625, nan, nan, 1.0, nan], recall [0.5, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:48.684999: step 477, loss 3.65712, accuracy 0.375, precision [0.3333333333333333, 0.5, 0.0, 0.25, 0.5, nan, 0.0, 1.0, nan], recall [0.3333333333333333, 0.3333333333333333, nan, 0.5, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:05:48.841851: step 478, loss 4.09325, accuracy 0.3125, precision [nan, 0.14285714285714285, nan, 0.5, 0.6666666666666666, nan, nan, 0.25, nan], recall [nan, 0.5, 0.0, 0.25, 0.3333333333333333, 0.0, nan, 1.0, nan]
2019-02-19T18:05:48.999255: step 479, loss 3.12344, accuracy 0.375, precision [0.5, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.3333333333333333, 0.0], recall [1.0, 0.0, 1.0, 0.25, 0.4, 0.0, nan, 1.0, 0.0]
2019-02-19T18:05:49.150596: step 480, loss 3.49538, accuracy 0.375, precision [nan, 0.5, 0.0, 0.5, 0.5, 0.0, nan, nan, 0.0], recall [nan, 0.5, nan, 0.5714285714285714, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:49.302546: step 481, loss 3.62217, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [0.5, 1.0, nan, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:05:49.458381: step 482, loss 4.9707, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.5, 0.5, 0.0, nan, 0.3333333333333333, nan], recall [1.0, nan, nan, 0.2, 0.5, nan, 0.0, 0.5, nan]
2019-02-19T18:05:49.612318: step 483, loss 4.3586, accuracy 0.3125, precision [0.0, 0.6666666666666666, nan, 0.6, nan, 0.0, 0.0, 0.0, nan], recall [nan, 0.5, 0.0, 0.375, nan, nan, 0.0, 0.0, 0.0]
2019-02-19T18:05:49.763760: step 484, loss 2.66759, accuracy 0.4375, precision [nan, 0.25, nan, 0.5, 0.0, nan, nan, 1.0, 0.0], recall [0.0, 0.5, 0.0, 0.5714285714285714, nan, nan, nan, 0.5, 0.0]
2019-02-19T18:05:49.921067: step 485, loss 2.75951, accuracy 0.4375, precision [nan, 0.0, 0.5, 0.7142857142857143, 0.5, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:05:50.076110: step 486, loss 3.90674, accuracy 0.4375, precision [0.5, 1.0, nan, 0.5, 0.25, nan, 0.0, 1.0, nan], recall [1.0, 0.25, nan, 0.6, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:05:50.225362: step 487, loss 5.87287, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.2857142857142857, 0.0, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.2857142857142857, 0.0, nan, nan, 0.0, 0.0]
2019-02-19T18:05:50.378741: step 488, loss 5.54274, accuracy 0.25, precision [0.0, 0.3333333333333333, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 1.0, 0.2857142857142857, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:05:50.529688: step 489, loss 2.4369, accuracy 0.5, precision [nan, 0.3333333333333333, 0.0, 0.7142857142857143, 0.5, nan, 0.0, nan, nan], recall [nan, 1.0, nan, 0.45454545454545453, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:05:50.685153: step 490, loss 3.42215, accuracy 0.5625, precision [0.5, 0.5, 0.0, 0.6, 1.0, 1.0, nan, nan, nan], recall [0.3333333333333333, 0.5, nan, 1.0, 0.4, 1.0, nan, nan, nan]
2019-02-19T18:05:50.841718: step 491, loss 1.45747, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.6, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [1.0, 0.25, 1.0, 0.75, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:05:50.994207: step 492, loss 4.18905, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.4, 0.75, 1.0, nan, 0.0, nan], recall [nan, 0.25, nan, 0.6666666666666666, 0.75, 0.3333333333333333, 0.0, 0.0, nan]
2019-02-19T18:05:51.149372: step 493, loss 4.23035, accuracy 0.3125, precision [0.0, 0.5, 0.5, 0.6, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.2, 1.0, 0.75, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:51.302886: step 494, loss 4.13095, accuracy 0.5, precision [nan, 0.75, nan, 0.0, 0.8333333333333334, nan, nan, 0.0, 0.0], recall [nan, 1.0, 0.0, 0.0, 0.625, 0.0, 0.0, nan, nan]
2019-02-19T18:05:51.455818: step 495, loss 1.89256, accuracy 0.625, precision [0.0, 0.6666666666666666, 0.5, 0.8, 1.0, nan, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:05:51.611401: step 496, loss 2.84897, accuracy 0.4375, precision [0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 1.0, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:05:51.771215: step 497, loss 1.71322, accuracy 0.5625, precision [0.0, 0.5, 0.0, 0.7142857142857143, 0.6666666666666666, nan, nan, 1.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.7142857142857143, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:05:51.926180: step 498, loss 1.89898, accuracy 0.625, precision [0.6666666666666666, 1.0, nan, 0.8, 0.25, nan, nan, 0.5, nan], recall [0.6666666666666666, 1.0, nan, 0.5, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:05:52.079666: step 499, loss 1.70231, accuracy 0.5625, precision [nan, 0.0, nan, 0.625, 1.0, 0.0, 0.0, nan, nan], recall [nan, 0.0, 0.0, 0.8333333333333334, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:05:52.233093: step 500, loss 2.18653, accuracy 0.625, precision [0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, nan, 0.0, nan, nan], recall [1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]

Evaluation:
[[ 45   7   3  21   1   0   0   5   0]
 [ 13  62   5  63   6   1   0   6   0]
 [  1   3  66  17   3   0   1   3   0]
 [  4  19  39 212   9   1   3  13   0]
 [  5   2   9  13 140   1   1   2   0]
 [  7   4   3  39   1   2   2   2   0]
 [  1   1   2  12   4   0   8   2   0]
 [  5   5   5  44   8   0   0  38   0]
 [  2   0   4  16   3   0   0   0   0]]
2019-02-19T18:05:54.648206: step 500, loss 1.97039, accuracy 0.559024, precision [0.5487804878048781, 0.3974358974358974, 0.7021276595744681, 0.7066666666666667, 0.8092485549132948, 0.03333333333333333, 0.26666666666666666, 0.3619047619047619, 0.0], recall [0.5421686746987951, 0.6019417475728155, 0.4852941176470588, 0.4851258581235698, 0.8, 0.4, 0.5333333333333333, 0.5352112676056338, nan]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-500

2019-02-19T18:05:54.939822: step 501, loss 5.07634, accuracy 0.375, precision [0.0, 0.6666666666666666, nan, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.6666666666666666, 0.0, 0.25, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T18:05:55.095087: step 502, loss 3.2448, accuracy 0.4375, precision [nan, 0.0, 0.3333333333333333, 0.5, 1.0, 0.5, nan, 0.0, nan], recall [0.0, nan, 0.5, 0.6, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:05:55.248918: step 503, loss 5.17406, accuracy 0.375, precision [0.25, 0.0, nan, 0.8, 1.0, 0.0, nan, 0.0, 0.0], recall [0.5, 0.0, nan, 0.5, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:05:55.405061: step 504, loss 2.70353, accuracy 0.5625, precision [0.0, 0.25, 1.0, 0.75, 0.75, nan, 0.0, nan, nan], recall [0.0, 1.0, 0.6666666666666666, 0.375, 1.0, nan, nan, nan, nan]
2019-02-19T18:05:55.559349: step 505, loss 3.80042, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.0, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 0.2, 0.0, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:05:55.717813: step 506, loss 1.34542, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.6, 0.75, nan, nan, 0.6666666666666666, 0.0], recall [1.0, 1.0, 0.5, 0.6, 0.75, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:05:55.878944: step 507, loss 2.91606, accuracy 0.5625, precision [0.5, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, nan, nan], recall [1.0, 1.0, nan, 0.2857142857142857, 0.75, nan, 1.0, 0.0, nan]
2019-02-19T18:05:56.037663: step 508, loss 2.21915, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.2857142857142857, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.4, nan, 0.0, 1.0, 1.0, 0.0, nan, 0.25, nan]
2019-02-19T18:05:56.186759: step 509, loss 2.76112, accuracy 0.3125, precision [0.0, 0.0, nan, 0.4, 0.5, 0.0, nan, nan, nan], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:05:56.344871: step 510, loss 3.23989, accuracy 0.375, precision [1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, nan], recall [0.3333333333333333, 0.3333333333333333, nan, 0.2, 0.3333333333333333, nan, nan, 1.0, nan]
2019-02-19T18:05:56.498881: step 511, loss 4.80065, accuracy 0.4375, precision [nan, 0.0, 1.0, 0.8, 0.4, 0.0, nan, nan, nan], recall [nan, nan, 0.3333333333333333, 0.5714285714285714, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:56.656460: step 512, loss 2.70406, accuracy 0.3125, precision [0.0, 0.25, 0.0, 0.0, 1.0, nan, 1.0, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.0, 0.75, 0.0, 1.0, 0.0, 0.0]
2019-02-19T18:05:56.812901: step 513, loss 2.02049, accuracy 0.5, precision [1.0, 0.0, nan, 0.6666666666666666, nan, 1.0, nan, 0.0, 0.0], recall [0.5, 0.0, nan, 0.6666666666666666, nan, 0.5, nan, nan, nan]
2019-02-19T18:05:56.970838: step 514, loss 2.786, accuracy 0.5, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, nan], recall [0.0, nan, 0.0, 0.4444444444444444, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:05:57.123818: step 515, loss 3.40353, accuracy 0.4375, precision [0.0, 0.5, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, 0.3333333333333333, 0.0, 0.5714285714285714, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:05:57.282519: step 516, loss 1.33462, accuracy 0.6875, precision [0.75, 0.5, 0.0, 0.75, 1.0, nan, nan, 0.5, nan], recall [0.75, 0.3333333333333333, nan, 1.0, 0.6, nan, nan, 1.0, nan]
2019-02-19T18:05:57.436146: step 517, loss 2.44328, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.8, 1.0, 0.0, 1.0, 0.0, nan], recall [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:05:57.588673: step 518, loss 2.31185, accuracy 0.625, precision [1.0, 0.0, 0.0, 0.5, 0.8, nan, nan, 1.0, nan], recall [0.8, nan, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:05:57.742664: step 519, loss 2.63148, accuracy 0.4375, precision [nan, 0.25, 0.25, 0.6, 1.0, 1.0, 0.0, nan, nan], recall [0.0, 0.5, 1.0, 0.42857142857142855, 0.5, 0.3333333333333333, nan, nan, nan]
2019-02-19T18:05:57.897978: step 520, loss 2.63889, accuracy 0.625, precision [0.5, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 1.0, 0.4, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:05:58.055366: step 521, loss 4.18938, accuracy 0.5, precision [0.0, 0.0, 0.3333333333333333, 0.8333333333333334, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.0, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:58.211562: step 522, loss 2.91957, accuracy 0.4375, precision [nan, 0.5, 0.0, 0.4, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [nan, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, nan, 0.4, nan]
2019-02-19T18:05:58.365742: step 523, loss 3.75248, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.25, 1.0, nan, 0.0, nan, 0.0], recall [0.6666666666666666, 0.25, 0.0, 0.3333333333333333, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:05:58.519198: step 524, loss 4.00903, accuracy 0.3125, precision [0.5, 1.0, 0.0, 0.5, 0.0, nan, 0.0, 0.0, 0.0], recall [1.0, 0.42857142857142855, nan, 0.25, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:05:58.668951: step 525, loss 2.5567, accuracy 0.5625, precision [0.0, 0.8, 1.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.5714285714285714, 0.5, 1.0, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:05:58.823437: step 526, loss 6.13164, accuracy 0.125, precision [0.0, 0.0, nan, 0.0, 0.5, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:05:58.976728: step 527, loss 3.03325, accuracy 0.375, precision [0.0, 1.0, 0.0, 0.4, 0.5, 0.5, nan, 0.0, 0.0], recall [0.0, 0.4, 0.0, 0.5, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:05:59.126984: step 528, loss 1.33701, accuracy 0.6875, precision [nan, 0.6, 1.0, 0.5, 1.0, 1.0, nan, 0.5, nan], recall [0.0, 0.75, 1.0, 0.6666666666666666, 1.0, 0.5, nan, 1.0, nan]
2019-02-19T18:05:59.283383: step 529, loss 2.77402, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.2, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 0.3333333333333333, 0.5, 0.75, nan, 0.0, 0.5, 0.0]
2019-02-19T18:05:59.435967: step 530, loss 2.58153, accuracy 0.5, precision [0.3333333333333333, 0.5, nan, 0.25, 0.8, 1.0, 0.0, nan, nan], recall [1.0, 0.3333333333333333, nan, 0.2, 0.8, 0.5, nan, nan, nan]
2019-02-19T18:05:59.589871: step 531, loss 3.05845, accuracy 0.5625, precision [nan, nan, 0.3333333333333333, 0.625, 1.0, 0.5, nan, 0.0, nan], recall [nan, 0.0, 0.5, 0.7142857142857143, 0.6666666666666666, 0.5, nan, 0.0, nan]
2019-02-19T18:05:59.740938: step 532, loss 1.83386, accuracy 0.6875, precision [1.0, 0.5, nan, 0.7142857142857143, 1.0, 0.0, 1.0, 0.0, nan], recall [0.5, 1.0, 0.0, 0.8333333333333334, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:05:59.894512: step 533, loss 2.02371, accuracy 0.4375, precision [0.0, nan, 1.0, 0.6, 0.25, 0.0, 0.0, nan, 0.0], recall [0.0, nan, 0.6, 0.75, 0.25, 0.0, nan, nan, nan]
2019-02-19T18:06:00.049802: step 534, loss 1.71018, accuracy 0.5, precision [1.0, 0.5, 0.6, 0.3333333333333333, 0.5, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.75, 0.2, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:06:00.201391: step 535, loss 1.85032, accuracy 0.5625, precision [0.0, nan, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, nan, 0.0, nan], recall [0.0, nan, 0.4, 0.8, 1.0, 0.5, nan, nan, 0.0]
2019-02-19T18:06:00.355792: step 536, loss 2.85016, accuracy 0.5, precision [0.5, 0.0, nan, 0.5555555555555556, 0.3333333333333333, nan, nan, 1.0, nan], recall [0.5, nan, 0.0, 0.7142857142857143, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:06:00.510262: step 537, loss 3.01228, accuracy 0.5, precision [0.0, 0.0, 0.0, 1.0, 0.75, nan, 0.0, 0.3333333333333333, nan], recall [0.0, nan, 0.0, 0.4444444444444444, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:06:00.668225: step 538, loss 2.72962, accuracy 0.625, precision [0.3333333333333333, 0.5, 0.0, 0.5, 1.0, nan, 1.0, 1.0, nan], recall [0.3333333333333333, 0.25, nan, 1.0, 0.6666666666666666, nan, 1.0, 1.0, nan]
2019-02-19T18:06:00.819727: step 539, loss 1.5309, accuracy 0.625, precision [nan, 0.6666666666666666, 1.0, 0.5, 0.75, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 1.0, 0.5, 1.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:06:00.970183: step 540, loss 4.3492, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.2857142857142857, 1.0, nan, 0.0, 1.0, nan], recall [nan, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, nan, 1.0, nan]
2019-02-19T18:06:01.125693: step 541, loss 2.037, accuracy 0.6875, precision [0.0, 0.6666666666666666, nan, 0.8333333333333334, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 1.0, nan, 0.8333333333333334, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:06:01.284938: step 542, loss 4.82745, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.0, nan, 0.16666666666666666, 0.75, nan, nan, 0.5, nan]
2019-02-19T18:06:01.439611: step 543, loss 2.26276, accuracy 0.5, precision [0.5, 0.0, 0.3333333333333333, 0.0, 1.0, nan, 0.0, 1.0, 0.0], recall [0.5, 0.0, 1.0, 0.0, 0.6, nan, 0.0, 0.75, nan]
2019-02-19T18:06:01.594890: step 544, loss 7.64548, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.25, 1.0, 0.0, nan, 1.0, 0.0], recall [0.0, 0.0, nan, 0.125, 1.0, nan, nan, 0.6666666666666666, 0.0]
2019-02-19T18:06:01.754746: step 545, loss 3.43559, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.0, 0.5714285714285714, nan, 0.0, 0.5, nan, nan], recall [0.6666666666666666, 0.5, 0.0, 0.5714285714285714, 0.0, nan, 1.0, nan, nan]
2019-02-19T18:06:01.909931: step 546, loss 4.03494, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan], recall [0.5, 1.0, 0.0, 0.5, 0.4, 0.0, nan, nan, nan]
2019-02-19T18:06:02.062521: step 547, loss 2.97777, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 0.25, nan]
2019-02-19T18:06:02.217060: step 548, loss 2.83072, accuracy 0.375, precision [nan, 0.0, 0.3333333333333333, 0.6, 1.0, 0.0, nan, 0.0, 0.0], recall [nan, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:06:02.378467: step 549, loss 3.10307, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.2857142857142857, nan, 0.0, nan, 0.6666666666666666, nan], recall [0.5, 0.0, 0.0, 0.3333333333333333, 0.0, nan, 0.0, 0.5, nan]
2019-02-19T18:06:02.529108: step 550, loss 2.5246, accuracy 0.4375, precision [nan, 0.0, 1.0, 0.5, 0.5, nan, 0.0, nan, nan], recall [0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:06:02.686244: step 551, loss 1.71297, accuracy 0.5625, precision [0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, nan, nan, 0.5, nan], recall [1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:02.840022: step 552, loss 2.52822, accuracy 0.375, precision [0.25, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.3333333333333333, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:06:02.995709: step 553, loss 1.97415, accuracy 0.5625, precision [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:03.148157: step 554, loss 2.56212, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.5, 0.0], recall [nan, 0.3333333333333333, 0.5, 0.2857142857142857, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:03.303825: step 555, loss 2.6842, accuracy 0.4375, precision [0.0, 0.25, 0.5, 0.75, 0.5, nan, 0.0, 0.5, nan], recall [nan, 0.3333333333333333, 1.0, 0.375, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:03.453321: step 556, loss 4.6688, accuracy 0.4375, precision [0.3333333333333333, nan, nan, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0], recall [1.0, nan, 0.0, 0.5714285714285714, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:06:03.611277: step 557, loss 2.59788, accuracy 0.5, precision [nan, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, nan, 0.5, 0.0], recall [0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0]
2019-02-19T18:06:03.763075: step 558, loss 3.96886, accuracy 0.3125, precision [0.5, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, nan, 0.0]
2019-02-19T18:06:03.917644: step 559, loss 3.83238, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.4, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.8, 0.0, nan, 0.0, nan]
2019-02-19T18:06:04.076505: step 560, loss 3.61775, accuracy 0.4375, precision [0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, nan, nan, 0.0, nan], recall [nan, 0.2, 0.75, 0.5, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:06:04.229167: step 561, loss 3.01224, accuracy 0.5, precision [0.6666666666666666, 0.5, 0.5, 0.0, 1.0, nan, 0.0, nan, 0.0], recall [1.0, 0.5, 0.6666666666666666, 0.0, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:04.382544: step 562, loss 5.2647, accuracy 0.3125, precision [1.0, 0.0, 1.0, 0.25, 0.3333333333333333, nan, nan, nan, nan], recall [0.5, 0.0, 0.16666666666666666, 0.5, 0.5, nan, nan, nan, nan]
2019-02-19T18:06:04.537227: step 563, loss 2.38228, accuracy 0.3125, precision [0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 0.0, nan, nan, 0.25, nan], recall [0.5, 0.3333333333333333, 0.2, 0.5, nan, 0.0, nan, 1.0, 0.0]
2019-02-19T18:06:04.689466: step 564, loss 3.57163, accuracy 0.3125, precision [0.0, 0.5, 0.5, 0.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [nan, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:06:04.841116: step 565, loss 2.12234, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.5714285714285714, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.5, nan, 0.5714285714285714, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:06:04.998182: step 566, loss 3.34029, accuracy 0.4375, precision [1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.75, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 1.0, 0.5, 0.5, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:05.153369: step 567, loss 2.47243, accuracy 0.375, precision [0.3333333333333333, 0.0, nan, 0.16666666666666666, 0.75, nan, 0.0, 1.0, nan], recall [0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6, nan, 0.0, 1.0, nan]
2019-02-19T18:06:05.307436: step 568, loss 1.86492, accuracy 0.5, precision [0.5, 0.0, nan, 0.6666666666666666, 0.6, nan, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:06:05.463977: step 569, loss 1.77101, accuracy 0.625, precision [1.0, nan, 1.0, 0.5, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [0.6666666666666666, 0.0, 0.5, 0.6, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:06:05.621213: step 570, loss 2.68703, accuracy 0.625, precision [1.0, 0.0, 0.0, 1.0, 1.0, nan, nan, 0.25, 0.0], recall [1.0, nan, nan, 0.7142857142857143, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T18:06:05.776044: step 571, loss 3.36023, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, nan, 0.2857142857142857, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T18:06:05.930847: step 572, loss 4.30665, accuracy 0.4375, precision [0.0, 0.5, nan, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.0, 0.16666666666666666, 0.7142857142857143, nan, nan, nan, nan]
2019-02-19T18:06:06.082627: step 573, loss 3.06254, accuracy 0.5, precision [0.6666666666666666, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, nan, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:06.236128: step 574, loss 4.34015, accuracy 0.5625, precision [1.0, 0.5, 0.0, 1.0, nan, 0.0, nan, 0.0, 0.0], recall [0.6666666666666666, 1.0, nan, 0.625, 0.0, nan, 0.0, nan, 0.0]
2019-02-19T18:06:06.392282: step 575, loss 2.18309, accuracy 0.4375, precision [nan, 0.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.5, nan], recall [0.0, nan, nan, 0.3, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:06.544417: step 576, loss 3.90615, accuracy 0.5, precision [nan, 0.25, 0.6666666666666666, 1.0, 0.75, nan, 0.0, 0.5, 0.0], recall [0.0, 1.0, 1.0, 0.16666666666666666, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:06:06.789339: step 577, loss 1.92054, accuracy 0.6, precision [1.0, 0.5, 0.3333333333333333, 0.5, 1.0, nan, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:06.945036: step 578, loss 3.30916, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.3333333333333333, nan, 0.375, 0.3333333333333333, nan, 0.0, 0.0, nan]
2019-02-19T18:06:07.100819: step 579, loss 2.17627, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.25, 0.5, 0.5, nan, 0.5, nan], recall [1.0, nan, 1.0, 0.3333333333333333, 0.5, 0.5, 0.0, 0.3333333333333333, 0.0]
2019-02-19T18:06:07.256650: step 580, loss 2.08089, accuracy 0.6875, precision [0.5, nan, 0.0, 1.0, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.5, nan, nan, 0.8333333333333334, 0.8, nan, nan, 0.5, 0.0]
2019-02-19T18:06:07.409260: step 581, loss 2.51, accuracy 0.4375, precision [nan, nan, 0.0, 0.5, 0.6666666666666666, 0.5, 1.0, 0.0, nan], recall [0.0, 0.0, nan, 0.42857142857142855, 0.5, 1.0, 1.0, nan, nan]
2019-02-19T18:06:07.560241: step 582, loss 2.2843, accuracy 0.4375, precision [nan, 0.0, 0.6666666666666666, 0.5, 0.5, 0.0, nan, nan, nan], recall [0.0, 0.0, 1.0, 0.6, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:08.184891: step 583, loss 2.99079, accuracy 0.375, precision [nan, 0.0, 0.5, 0.5, 0.6666666666666666, nan, nan, 0.3333333333333333, nan], recall [0.0, nan, 0.5, 0.2857142857142857, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:06:08.336408: step 584, loss 1.53132, accuracy 0.5625, precision [1.0, 0.0, 0.6666666666666666, 0.8333333333333334, nan, nan, nan, 0.3333333333333333, 0.0], recall [0.5, 0.0, 0.6666666666666666, 0.7142857142857143, nan, nan, nan, 0.5, nan]
2019-02-19T18:06:08.487242: step 585, loss 2.66721, accuracy 0.5, precision [0.0, 0.25, 1.0, 0.5, 0.8, 0.3333333333333333, nan, nan, nan], recall [nan, 1.0, 0.25, 0.5, 0.8, 1.0, 0.0, 0.0, 0.0]
2019-02-19T18:06:08.644468: step 586, loss 1.94355, accuracy 0.625, precision [0.0, 0.3333333333333333, 1.0, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.5, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:08.797287: step 587, loss 3.12379, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.16666666666666666, 0.5, 0.5, 1.0, 1.0, nan], recall [0.5, 0.0, 1.0, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0, 1.0, 0.0]
2019-02-19T18:06:08.955713: step 588, loss 2.38897, accuracy 0.375, precision [nan, 1.0, 0.5, 0.4, 1.0, 0.0, nan, 0.2, nan], recall [0.0, 0.5, 0.5, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:06:09.106557: step 589, loss 3.28577, accuracy 0.375, precision [nan, 0.2857142857142857, 1.0, 0.0, 1.0, nan, nan, nan, nan], recall [0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:06:09.256558: step 590, loss 3.63493, accuracy 0.6875, precision [nan, 1.0, 1.0, 0.3333333333333333, 0.75, 0.5, 1.0, 1.0, 0.0], recall [0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, nan]
2019-02-19T18:06:09.413929: step 591, loss 3.61081, accuracy 0.375, precision [nan, 0.0, 1.0, 0.4, 0.3333333333333333, nan, 0.5, 0.3333333333333333, nan], recall [0.0, nan, 0.25, 0.5, 1.0, 0.0, 1.0, 0.3333333333333333, nan]
2019-02-19T18:06:09.567618: step 592, loss 2.5935, accuracy 0.5625, precision [nan, 1.0, nan, 0.16666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.5, 1.0, 1.0, nan]
2019-02-19T18:06:09.724276: step 593, loss 5.00099, accuracy 0.375, precision [0.0, 0.2, 1.0, 0.6, 0.3333333333333333, nan, nan, nan, nan], recall [nan, 0.25, 1.0, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:09.878437: step 594, loss 2.34561, accuracy 0.5, precision [0.0, 0.0, nan, 0.5714285714285714, 0.6666666666666666, nan, 1.0, 0.5, nan], recall [0.0, 0.0, nan, 0.8, 1.0, 0.0, 1.0, 0.3333333333333333, nan]
2019-02-19T18:06:10.038171: step 595, loss 2.89618, accuracy 0.4375, precision [0.0, 0.6, 0.6666666666666666, 0.5, 0.0, 0.0, nan, 1.0, nan], recall [nan, 0.75, 0.6666666666666666, 0.2, 0.0, 0.0, nan, 0.5, nan]
2019-02-19T18:06:10.196302: step 596, loss 1.10341, accuracy 0.625, precision [0.5, 1.0, 1.0, 0.5, 0.75, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.5, 1.0, 0.75, 0.0, 0.0, nan, nan]
2019-02-19T18:06:10.348441: step 597, loss 2.18856, accuracy 0.6875, precision [0.5, 1.0, 1.0, 0.7142857142857143, 1.0, 0.0, 1.0, 0.0, nan], recall [1.0, 1.0, 0.5, 0.625, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:06:10.497022: step 598, loss 1.43447, accuracy 0.625, precision [0.0, 1.0, nan, 0.6666666666666666, 0.6666666666666666, nan, nan, 0.5, nan], recall [nan, 0.25, nan, 0.8571428571428571, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:06:10.647984: step 599, loss 2.70786, accuracy 0.5, precision [0.5, 0.0, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 0.5, nan], recall [1.0, 0.0, 1.0, 0.25, 0.75, 0.0, nan, 1.0, nan]
2019-02-19T18:06:10.800782: step 600, loss 2.50959, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.0, 0.75, 0.5, 0.0, 1.0, 0.0, nan], recall [nan, 0.5, 0.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:06:10.954369: step 601, loss 2.81197, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, nan], recall [nan, 0.25, 0.6666666666666666, 0.5, 1.0, 0.5, nan, 0.0, nan]
2019-02-19T18:06:11.108322: step 602, loss 1.4862, accuracy 0.625, precision [0.0, 0.6, nan, 0.8333333333333334, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.75, nan, 1.0, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:06:11.261710: step 603, loss 2.22841, accuracy 0.5625, precision [0.0, 1.0, nan, 0.5714285714285714, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:11.415035: step 604, loss 1.8066, accuracy 0.5625, precision [0.0, 1.0, 0.5, 0.625, 1.0, nan, 0.5, nan, nan], recall [nan, 0.3333333333333333, 1.0, 0.625, 0.5, 0.0, 1.0, nan, nan]
2019-02-19T18:06:11.571740: step 605, loss 1.56274, accuracy 0.625, precision [0.5, 0.5, 0.0, 0.75, 1.0, nan, nan, 0.5, nan], recall [0.5, 0.5, nan, 0.6, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:11.722781: step 606, loss 3.73337, accuracy 0.3125, precision [0.0, nan, 0.0, 0.4, 0.6666666666666666, nan, 0.0, 0.25, nan], recall [nan, 0.0, nan, 0.2857142857142857, 0.4, nan, nan, 0.5, nan]
2019-02-19T18:06:11.879440: step 607, loss 3.11219, accuracy 0.625, precision [0.5, 0.5, 0.6666666666666666, 0.8, 0.6666666666666666, 0.0, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:06:12.035300: step 608, loss 3.03042, accuracy 0.4375, precision [0.0, 1.0, 0.25, 0.5, 0.5, nan, 0.0, 0.6666666666666666, nan], recall [0.0, 0.5, 1.0, 0.14285714285714285, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:06:12.191448: step 609, loss 1.81996, accuracy 0.6875, precision [1.0, nan, 0.4, 0.8, 1.0, nan, 1.0, nan, 0.0], recall [1.0, 0.0, 1.0, 1.0, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:06:12.346848: step 610, loss 3.85866, accuracy 0.375, precision [1.0, 0.0, nan, 0.5, 0.3333333333333333, nan, nan, 0.5, 0.0], recall [0.3333333333333333, 0.0, 0.0, 0.5, 1.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:06:12.500982: step 611, loss 2.74417, accuracy 0.625, precision [0.5, 1.0, nan, 0.8333333333333334, 0.5, nan, 0.0, 1.0, 0.0], recall [0.5, 0.6666666666666666, nan, 0.5555555555555556, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:12.655842: step 612, loss 2.61465, accuracy 0.4375, precision [0.5, 0.3333333333333333, 1.0, 0.5, 0.3333333333333333, 0.0, nan, nan, 0.0], recall [0.5, 0.3333333333333333, 1.0, 0.4, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:06:12.808940: step 613, loss 1.27519, accuracy 0.75, precision [1.0, 0.5, 1.0, nan, 1.0, nan, nan, 0.3333333333333333, 1.0], recall [0.75, 1.0, 0.5, nan, 0.8, nan, nan, 0.5, 1.0]
2019-02-19T18:06:12.963291: step 614, loss 3.72135, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.0, 1.0, 0.2, 0.0, 0.6666666666666666, nan], recall [0.0, 0.0, 0.5, 0.0, 0.5, 1.0, nan, 1.0, nan]
2019-02-19T18:06:13.115000: step 615, loss 2.18733, accuracy 0.4375, precision [0.6666666666666666, 0.0, 1.0, 0.0, 1.0, nan, 0.6666666666666666, nan, nan], recall [0.4, nan, 0.25, 0.0, 0.5, nan, 1.0, nan, nan]
2019-02-19T18:06:13.273196: step 616, loss 1.51047, accuracy 0.5625, precision [nan, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6, nan], recall [0.0, nan, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.6, nan]
2019-02-19T18:06:13.425333: step 617, loss 2.34705, accuracy 0.5625, precision [1.0, 0.5, 1.0, 0.3333333333333333, 0.75, nan, nan, 0.0, nan], recall [0.25, 1.0, 0.3333333333333333, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:13.579095: step 618, loss 2.34786, accuracy 0.5, precision [1.0, 0.0, 0.5, 0.3333333333333333, nan, 0.0, 0.0, 1.0, nan], recall [0.75, nan, 1.0, 0.5, nan, nan, 0.0, 0.4, nan]
2019-02-19T18:06:13.732594: step 619, loss 1.84145, accuracy 0.6875, precision [nan, 0.0, 1.0, 0.8, 0.6666666666666666, nan, nan, 1.0, 0.5], recall [0.0, nan, 0.6666666666666666, 0.8, 1.0, nan, nan, 0.5, 1.0]
2019-02-19T18:06:13.891659: step 620, loss 1.6358, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.5, 0.0, nan, 1.0, 0.75, 0.0], recall [0.5, nan, 0.0, 0.6666666666666666, nan, nan, 0.5, 0.75, 0.0]
2019-02-19T18:06:14.043660: step 621, loss 2.61301, accuracy 0.5, precision [1.0, 0.0, 0.75, 0.2, 1.0, 0.0, 1.0, nan, nan], recall [0.6666666666666666, 0.0, 0.6, 0.5, 0.25, nan, 1.0, nan, nan]
2019-02-19T18:06:14.197578: step 622, loss 2.97932, accuracy 0.625, precision [nan, 0.5, 0.5, 0.5714285714285714, 1.0, nan, 0.0, nan, nan], recall [0.0, 0.5, 0.3333333333333333, 0.8, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:06:14.350145: step 623, loss 1.89504, accuracy 0.625, precision [0.5, 0.6, 1.0, 0.0, 1.0, nan, nan, 0.75, nan], recall [1.0, 0.75, 1.0, nan, 0.5, nan, 0.0, 0.6, nan]
2019-02-19T18:06:14.505572: step 624, loss 2.51383, accuracy 0.3125, precision [0.5, nan, 0.5, 0.125, 0.3333333333333333, nan, 1.0, nan, nan], recall [1.0, 0.0, 0.2, 1.0, 1.0, nan, 1.0, 0.0, 0.0]
2019-02-19T18:06:14.654048: step 625, loss 1.51455, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.5714285714285714, 1.0, nan, nan, nan, nan], recall [0.0, 0.0, 0.5, 0.5, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:06:14.811242: step 626, loss 2.63821, accuracy 0.4375, precision [0.6666666666666666, 0.0, 0.5, 0.42857142857142855, 1.0, nan, nan, 0.0, 0.0], recall [0.6666666666666666, 0.0, 1.0, 0.42857142857142855, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T18:06:14.965874: step 627, loss 3.09642, accuracy 0.5, precision [nan, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0], recall [nan, 0.5, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, nan, 1.0, 0.0, nan]
2019-02-19T18:06:15.116312: step 628, loss 3.02687, accuracy 0.375, precision [0.5, 0.25, nan, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.5, 0.3333333333333333, nan, 0.2857142857142857, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:06:15.269141: step 629, loss 2.05561, accuracy 0.3125, precision [0.0, 0.0, nan, 0.375, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6, 0.4, nan, 0.0, nan, nan]
2019-02-19T18:06:15.424052: step 630, loss 3.18805, accuracy 0.4375, precision [1.0, 0.5, nan, 0.4, 0.75, 0.0, nan, 0.0, nan], recall [0.5, 0.5, nan, 0.4, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:06:15.578323: step 631, loss 1.7173, accuracy 0.625, precision [1.0, 0.0, nan, 1.0, 0.75, nan, nan, 0.0, 0.0], recall [0.6666666666666666, nan, nan, 0.7142857142857143, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:06:15.734687: step 632, loss 3.30976, accuracy 0.5, precision [0.0, 0.6666666666666666, 0.0, 0.8333333333333334, 0.5, nan, nan, nan, nan], recall [nan, 0.5, nan, 0.625, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:06:15.888962: step 633, loss 1.42805, accuracy 0.625, precision [0.5, 0.6, 0.0, 0.75, 1.0, nan, nan, 0.5, nan], recall [1.0, 0.6, nan, 0.75, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:06:16.044331: step 634, loss 3.71631, accuracy 0.375, precision [nan, nan, 0.0, 0.6, 0.4, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, 0.0, nan, 0.5, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:06:16.203822: step 635, loss 3.77511, accuracy 0.3125, precision [0.0, 0.2, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, nan], recall [nan, 0.5, nan, 0.3, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:06:16.362836: step 636, loss 1.71054, accuracy 0.75, precision [0.0, 1.0, 1.0, 0.8333333333333334, nan, nan, nan, 0.5, nan], recall [nan, 0.8, 1.0, 0.625, nan, nan, nan, 1.0, nan]
2019-02-19T18:06:16.516133: step 637, loss 1.30943, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.8333333333333334, 0.0, nan, nan, 1.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.7142857142857143, nan, 0.0, nan, 1.0, 0.0]
2019-02-19T18:06:16.666230: step 638, loss 1.75169, accuracy 0.625, precision [1.0, 1.0, 0.3333333333333333, 0.4, 1.0, nan, nan, 0.0, nan], recall [0.5, 0.42857142857142855, 1.0, 0.6666666666666666, 1.0, nan, nan, nan, nan]
2019-02-19T18:06:16.819618: step 639, loss 3.50349, accuracy 0.375, precision [0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.0, nan, 0.5, nan], recall [1.0, 0.25, nan, 0.0, nan, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:16.971241: step 640, loss 1.41468, accuracy 0.8125, precision [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, nan, nan, nan], recall [1.0, 0.5, 1.0, 0.8333333333333334, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:06:17.130096: step 641, loss 2.79712, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.5, 0.6666666666666666, nan, 1.0, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.3333333333333333, 1.0, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:06:17.281592: step 642, loss 2.04989, accuracy 0.625, precision [1.0, 0.0, 0.5, 0.75, 0.6666666666666666, nan, 1.0, 1.0, nan], recall [0.5, nan, 1.0, 0.6, 0.6666666666666666, nan, 1.0, 1.0, 0.0]
2019-02-19T18:06:17.441618: step 643, loss 2.86494, accuracy 0.5, precision [0.5, 0.625, nan, 0.25, 0.5, nan, nan, nan, nan], recall [0.5, 0.7142857142857143, 0.0, 0.3333333333333333, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:06:17.598727: step 644, loss 2.16834, accuracy 0.4375, precision [nan, 0.2, 0.0, 0.6666666666666666, 0.8, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:06:17.758196: step 645, loss 2.62103, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.5714285714285714, nan, 0.0, 1.0, 1.0, nan], recall [0.5, 0.0, 0.0, 0.5714285714285714, nan, 0.0, 1.0, 0.5, nan]
2019-02-19T18:06:17.916499: step 646, loss 2.90805, accuracy 0.5, precision [1.0, 0.6666666666666666, nan, 0.2, nan, 0.0, 0.0, 1.0, nan], recall [1.0, 0.6666666666666666, 0.0, 0.3333333333333333, nan, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:06:18.073155: step 647, loss 1.51766, accuracy 0.625, precision [1.0, 1.0, nan, 0.5714285714285714, 1.0, 0.0, 1.0, 0.0, nan], recall [0.5, 0.3333333333333333, 0.0, 0.8, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:06:18.222379: step 648, loss 1.60653, accuracy 0.5625, precision [1.0, 0.5, nan, 0.42857142857142855, 0.75, nan, nan, 0.5, nan], recall [0.25, 0.5, 0.0, 1.0, 0.75, nan, nan, 1.0, 0.0]
2019-02-19T18:06:18.378322: step 649, loss 1.26535, accuracy 0.5, precision [1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [0.5, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:18.532758: step 650, loss 2.99818, accuracy 0.4375, precision [0.0, 0.3333333333333333, nan, 0.4, 0.75, 1.0, nan, nan, 0.0], recall [0.0, 0.25, 0.0, 0.6666666666666666, 0.75, 0.5, nan, nan, nan]
2019-02-19T18:06:18.687427: step 651, loss 1.76347, accuracy 0.5, precision [0.0, 0.6666666666666666, nan, 1.0, 0.5, 0.0, nan, 0.0, nan], recall [nan, 1.0, nan, 0.375, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:06:18.846087: step 652, loss 1.27723, accuracy 0.5625, precision [0.0, 0.6, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.75, 1.0, 0.5, 0.5, nan, nan, nan, nan]
2019-02-19T18:06:18.998965: step 653, loss 2.1764, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.25, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.5, nan, 0.3333333333333333, 0.5, 0.0, 0.0, 1.0, nan]
2019-02-19T18:06:19.159621: step 654, loss 3.79474, accuracy 0.4375, precision [0.5, 0.5, 0.5, 0.0, 1.0, nan, nan, nan, 0.0], recall [1.0, 0.4, 1.0, 0.0, 0.4, nan, nan, 0.0, nan]
2019-02-19T18:06:19.312351: step 655, loss 1.62146, accuracy 0.4375, precision [0.3333333333333333, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, nan], recall [0.5, 0.3333333333333333, nan, 0.5, 0.5, 0.0, 1.0, 0.5, 0.0]
2019-02-19T18:06:19.463305: step 656, loss 1.30808, accuracy 0.75, precision [0.0, nan, 1.0, 0.8571428571428571, 1.0, 0.0, nan, 0.5, nan], recall [nan, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:06:19.618765: step 657, loss 2.15514, accuracy 0.4375, precision [1.0, nan, 0.5, 0.16666666666666666, 0.75, nan, nan, 0.0, nan], recall [0.5, 0.0, 0.6666666666666666, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:19.772271: step 658, loss 1.43908, accuracy 0.625, precision [1.0, 1.0, 0.3333333333333333, 0.25, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 0.5, 0.5, 0.5, 0.8333333333333334, nan, 0.0, 0.5, nan]
2019-02-19T18:06:19.930054: step 659, loss 1.51047, accuracy 0.75, precision [1.0, 1.0, 0.5, 0.75, 1.0, nan, 0.0, nan, nan], recall [1.0, 0.4, 1.0, 1.0, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:06:20.088916: step 660, loss 2.03341, accuracy 0.4375, precision [0.0, 0.75, nan, 0.4, 0.5, nan, 0.0, nan, nan], recall [nan, 0.6, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:20.244950: step 661, loss 0.918081, accuracy 0.625, precision [1.0, nan, 0.5, 0.6666666666666666, 0.75, 0.0, nan, nan, 0.0], recall [1.0, nan, 0.5, 0.6666666666666666, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:06:20.396662: step 662, loss 1.69465, accuracy 0.625, precision [nan, 1.0, 1.0, 0.625, 0.5, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.3333333333333333, 0.8333333333333334, 0.6666666666666666, nan, nan, 0.5, 0.0]
2019-02-19T18:06:20.549731: step 663, loss 1.90854, accuracy 0.5625, precision [0.3333333333333333, 0.5, 0.0, 1.0, 1.0, nan, 0.0, 0.5, 0.0], recall [1.0, 0.5, 0.0, 0.625, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:06:20.705117: step 664, loss 2.41012, accuracy 0.625, precision [1.0, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 0.0, 1.0, 1.0], recall [1.0, 1.0, 0.25, 0.3333333333333333, 0.0, nan, nan, 1.0, 1.0]
2019-02-19T18:06:20.857490: step 665, loss 1.62613, accuracy 0.5, precision [0.0, 0.2, 0.0, 1.0, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.5, 0.0, 0.625, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:21.009790: step 666, loss 3.14471, accuracy 0.5, precision [1.0, 0.0, nan, 0.6, 1.0, 0.5, nan, 0.6666666666666666, nan], recall [1.0, nan, 0.0, 0.5, 0.5, 0.5, nan, 0.5, nan]
2019-02-19T18:06:21.161662: step 667, loss 2.26652, accuracy 0.5, precision [0.5, nan, 0.5, 0.25, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [1.0, 0.0, 1.0, 0.25, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T18:06:21.320730: step 668, loss 1.91445, accuracy 0.6875, precision [1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 0.75, nan], recall [1.0, nan, nan, 0.7142857142857143, 0.6666666666666666, nan, nan, 0.6, nan]
2019-02-19T18:06:21.476314: step 669, loss 1.94565, accuracy 0.3125, precision [1.0, 0.25, nan, 0.0, 0.6666666666666666, 0.5, nan, nan, nan], recall [0.3333333333333333, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:06:21.632835: step 670, loss 2.2247, accuracy 0.5, precision [nan, 0.6666666666666666, nan, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, nan], recall [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 0.75, 0.0, nan, 0.5, 0.0]
2019-02-19T18:06:21.786480: step 671, loss 3.30275, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.8333333333333334, 0.5, nan, 0.0, 0.0, nan], recall [0.5, 0.0, 0.6666666666666666, 0.8333333333333334, 0.5, nan, 0.0, nan, 0.0]
2019-02-19T18:06:21.936140: step 672, loss 1.05574, accuracy 0.5625, precision [nan, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, nan], recall [0.0, 0.6666666666666666, 0.5, 0.4, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:06:22.093422: step 673, loss 0.660846, accuracy 0.75, precision [nan, 0.6666666666666666, 0.5, 0.875, 1.0, nan, nan, 1.0, 0.0], recall [nan, 1.0, 0.5, 0.7, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:22.248397: step 674, loss 2.31202, accuracy 0.5, precision [nan, 0.25, nan, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [nan, 1.0, 0.0, 0.5, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:06:22.399950: step 675, loss 2.1346, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.16666666666666666, 0.6, nan, nan, 1.0, nan], recall [0.3333333333333333, 0.5, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:22.554857: step 676, loss 1.36316, accuracy 0.5625, precision [nan, 0.75, 0.0, 0.7142857142857143, 0.3333333333333333, nan, nan, 0.0, nan], recall [nan, 0.6, 0.0, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T18:06:22.710466: step 677, loss 1.18118, accuracy 0.6875, precision [nan, 0.6666666666666666, 0.5, 0.6, 1.0, 0.5, nan, nan, nan], recall [nan, 0.6666666666666666, 0.3333333333333333, 0.75, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T18:06:22.862331: step 678, loss 3.00614, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.5, 0.5, 0.75, nan, 0.5, 0.0], recall [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.75, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:23.014432: step 679, loss 1.95374, accuracy 0.5625, precision [0.3333333333333333, 0.5, 0.3333333333333333, 1.0, 0.8, nan, nan, nan, 0.0], recall [1.0, 0.3333333333333333, 1.0, 0.4, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:06:23.169947: step 680, loss 2.00398, accuracy 0.5, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan], recall [0.0, nan, nan, 0.6666666666666666, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:06:23.322134: step 681, loss 2.79693, accuracy 0.375, precision [nan, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.3333333333333333, nan], recall [0.0, 0.0, 0.0, 0.4, 0.5, 0.5, nan, 1.0, nan]
2019-02-19T18:06:23.472681: step 682, loss 1.82179, accuracy 0.5625, precision [0.0, 0.75, 0.0, 0.8, 0.5, 0.0, nan, 0.5, nan], recall [0.0, 1.0, nan, 0.4444444444444444, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:23.627095: step 683, loss 3.07952, accuracy 0.4375, precision [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.3333333333333333, 0.0, 0.0], recall [nan, 0.0, 0.6666666666666666, 0.5714285714285714, nan, nan, 1.0, 0.0, nan]
2019-02-19T18:06:23.779863: step 684, loss 1.96786, accuracy 0.5625, precision [0.0, 0.5, 0.0, 1.0, 0.75, nan, 0.5, 0.6666666666666666, nan], recall [nan, 0.5, nan, 0.5, 0.75, 0.0, 0.3333333333333333, 1.0, nan]
2019-02-19T18:06:23.936457: step 685, loss 3.43896, accuracy 0.375, precision [0.6666666666666666, 0.25, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0], recall [0.4, 1.0, nan, 0.25, 0.0, 1.0, nan, 1.0, 0.0]
2019-02-19T18:06:24.092075: step 686, loss 2.22295, accuracy 0.375, precision [0.0, 0.25, 0.6666666666666666, 0.3333333333333333, 0.5, nan, nan, 0.5, nan], recall [0.0, 0.5, 0.6666666666666666, 0.5, 0.5, 0.0, 0.0, 0.5, nan]
2019-02-19T18:06:24.247073: step 687, loss 4.10368, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, nan, 0.0], recall [0.0, 0.5, 0.0, 0.8571428571428571, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:06:24.403423: step 688, loss 2.51399, accuracy 0.5, precision [0.75, 0.6666666666666666, 0.0, 0.0, 0.6, 0.0, nan, 0.0, nan], recall [0.75, 1.0, nan, 0.0, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:06:24.557351: step 689, loss 1.15376, accuracy 0.5625, precision [1.0, 0.5, nan, 0.375, 1.0, 0.0, 1.0, 1.0, nan], recall [0.25, 0.5, 0.0, 0.75, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:06:24.712852: step 690, loss 1.89575, accuracy 0.625, precision [0.5, 0.5, 0.75, 1.0, 0.6, 0.0, nan, nan, nan], recall [1.0, 0.3333333333333333, 0.75, 1.0, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:06:24.870790: step 691, loss 2.88017, accuracy 0.4375, precision [0.0, 0.6666666666666666, nan, 0.0, 1.0, nan, 0.0, 0.5, 1.0], recall [nan, 0.5, nan, 0.0, 0.75, 0.0, nan, 0.5, 1.0]
2019-02-19T18:06:25.022105: step 692, loss 1.76909, accuracy 0.6875, precision [0.5, 0.5, 1.0, 1.0, 0.75, 0.0, 1.0, 1.0, nan], recall [1.0, 0.5, 1.0, 0.6666666666666666, 0.75, nan, 1.0, 0.5, nan]
2019-02-19T18:06:25.176513: step 693, loss 1.85539, accuracy 0.5, precision [0.5, 1.0, 0.6666666666666666, 0.2, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.5, nan]
2019-02-19T18:06:25.330083: step 694, loss 2.44733, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.42857142857142855, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.25, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:25.483804: step 695, loss 3.16513, accuracy 0.3125, precision [1.0, nan, 0.5, 0.125, 0.5, nan, 1.0, 0.0, 0.0], recall [0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.5, nan, 1.0, 0.0, 0.0]
2019-02-19T18:06:25.635090: step 696, loss 1.20039, accuracy 0.6875, precision [nan, 1.0, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.6666666666666666, nan], recall [0.0, 0.3333333333333333, 1.0, 0.6, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:25.786261: step 697, loss 3.11079, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.5, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0], recall [1.0, 0.0, 0.3333333333333333, 0.6, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:06:25.942013: step 698, loss 1.26152, accuracy 0.6875, precision [nan, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, 0.0], recall [0.0, 0.0, 1.0, 1.0, 0.75, nan, nan, 0.5, nan]
2019-02-19T18:06:26.098084: step 699, loss 1.39409, accuracy 0.5625, precision [1.0, 0.3333333333333333, nan, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [0.6666666666666666, 1.0, 0.0, 0.4, 0.8, nan, 0.0, nan, nan]
2019-02-19T18:06:26.254501: step 700, loss 2.66277, accuracy 0.4375, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.0, nan, 0.5714285714285714, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:06:26.404497: step 701, loss 1.58282, accuracy 0.6875, precision [0.6, 0.5, 0.5, 0.8333333333333334, 1.0, nan, nan, nan, nan], recall [0.75, 0.5, 1.0, 0.7142857142857143, 0.5, nan, nan, nan, nan]
2019-02-19T18:06:26.557252: step 702, loss 1.48221, accuracy 0.4375, precision [nan, 0.25, 0.0, 0.75, 0.6666666666666666, nan, nan, 0.5, 0.0], recall [0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:26.712861: step 703, loss 2.07407, accuracy 0.5625, precision [1.0, 0.6, nan, 0.75, 1.0, nan, 0.0, 0.0, 0.0], recall [0.6666666666666666, 0.75, nan, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:06:26.871121: step 704, loss 1.78621, accuracy 0.5625, precision [nan, 0.0, 0.3333333333333333, 0.7142857142857143, 0.6666666666666666, nan, nan, 0.5, nan], recall [nan, nan, 0.25, 0.625, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:06:27.028401: step 705, loss 3.21564, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.25, 0.6666666666666666, nan, 0.0, nan, 0.0], recall [0.3333333333333333, nan, 0.6, 0.5, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:27.183804: step 706, loss 1.29313, accuracy 0.625, precision [nan, 0.8, nan, 0.4, 1.0, 0.0, nan, nan, 0.0], recall [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:06:27.338007: step 707, loss 1.97875, accuracy 0.5625, precision [0.6666666666666666, 0.0, nan, 1.0, 0.25, 0.5, nan, 1.0, 0.0], recall [1.0, 0.0, nan, 0.5714285714285714, 1.0, 0.3333333333333333, nan, 1.0, nan]
2019-02-19T18:06:27.493501: step 708, loss 2.68453, accuracy 0.25, precision [nan, 0.5, 0.0, 0.2, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [nan, 1.0, 0.0, 0.2, 0.5, 0.0, 0.0, nan, 0.0]
2019-02-19T18:06:27.645387: step 709, loss 2.52024, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.6, 0.5, nan, 1.0, 0.5, nan], recall [nan, 0.5, 0.6666666666666666, 0.6, 0.5, nan, 0.5, 1.0, 0.0]
2019-02-19T18:06:27.798052: step 710, loss 1.53879, accuracy 0.625, precision [0.0, 0.5, 0.0, 0.8888888888888888, 1.0, 0.0, nan, nan, nan], recall [nan, 0.5, 0.0, 0.8888888888888888, 1.0, 0.0, 0.0, nan, 0.0]
2019-02-19T18:06:27.955597: step 711, loss 1.54097, accuracy 0.5625, precision [0.0, 0.5, 0.0, 0.8, 0.75, 1.0, 0.0, nan, nan], recall [nan, 0.5, nan, 0.5714285714285714, 1.0, 0.5, nan, nan, 0.0]
2019-02-19T18:06:28.110826: step 712, loss 1.44494, accuracy 0.5, precision [0.0, 0.3333333333333333, 1.0, 0.5, 1.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.3333333333333333, 0.8, 0.6666666666666666, 0.0, 0.0, nan, 0.0]
2019-02-19T18:06:28.263537: step 713, loss 2.46966, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.5714285714285714, 0.5, 0.0, 0.0, 0.0, nan], recall [nan, nan, 0.3333333333333333, 0.5, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:28.413719: step 714, loss 2.17358, accuracy 0.625, precision [1.0, 0.25, 0.5, 1.0, 1.0, nan, 0.5, 1.0, 0.0], recall [1.0, 1.0, 1.0, 0.5, 0.6, 0.0, 1.0, 1.0, nan]
2019-02-19T18:06:28.563079: step 715, loss 0.940184, accuracy 0.75, precision [nan, 1.0, 0.5, 0.6666666666666666, 0.5, nan, 1.0, 1.0, 1.0], recall [nan, 1.0, 0.3333333333333333, 0.8, 1.0, nan, 1.0, 0.5, 1.0]
2019-02-19T18:06:28.715984: step 716, loss 2.93771, accuracy 0.625, precision [0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.6, 0.8, nan, nan, nan, 0.0]
2019-02-19T18:06:28.870854: step 717, loss 2.77486, accuracy 0.3125, precision [0.0, nan, 1.0, 0.4, 0.4, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.3333333333333333, 0.2857142857142857, 0.4, nan, nan, nan, nan]
2019-02-19T18:06:29.028217: step 718, loss 3.3289, accuracy 0.375, precision [nan, 0.25, 0.6666666666666666, 0.5, nan, nan, 0.0, 0.5, 0.0], recall [0.0, 1.0, 0.5, 0.4, 0.0, nan, nan, 1.0, 0.0]
2019-02-19T18:06:29.184001: step 719, loss 2.7362, accuracy 0.625, precision [0.5, 0.0, 0.5, 1.0, 1.0, 0.5, nan, nan, nan], recall [1.0, 0.0, 0.6666666666666666, 0.5714285714285714, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:06:29.339924: step 720, loss 1.73671, accuracy 0.5625, precision [nan, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 1.0, 0.5, 0.75, 0.5, 0.0, nan, nan, 0.0]
2019-02-19T18:06:29.488804: step 721, loss 1.96868, accuracy 0.5, precision [0.6, 0.5, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:29.641250: step 722, loss 2.6963, accuracy 0.4375, precision [nan, nan, 0.0, 0.42857142857142855, 0.6666666666666666, nan, 0.0, 0.5, nan], recall [0.0, 0.0, 0.0, 0.75, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:06:29.792683: step 723, loss 3.1831, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, nan, 1.0, 0.0], recall [0.5, 0.3333333333333333, nan, 0.3333333333333333, nan, 1.0, nan, 1.0, nan]
2019-02-19T18:06:29.947674: step 724, loss 2.05416, accuracy 0.5625, precision [1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.5, nan, 0.5, 1.0, nan], recall [0.5, 0.4, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, nan]
2019-02-19T18:06:30.103794: step 725, loss 0.947386, accuracy 0.6875, precision [1.0, 0.5, nan, 0.5, 0.8, nan, nan, 1.0, nan], recall [0.25, 1.0, nan, 0.5, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:06:30.252805: step 726, loss 2.50748, accuracy 0.5, precision [0.0, 0.5, 0.6, nan, 0.8, 0.0, nan, 0.0, nan], recall [nan, 0.25, 1.0, 0.0, 0.8, 0.0, nan, 0.0, nan]
2019-02-19T18:06:30.407105: step 727, loss 1.99433, accuracy 0.4375, precision [0.6666666666666666, 0.5, 0.0, 0.0, 1.0, nan, 1.0, 1.0, nan], recall [0.5, 1.0, nan, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0]
2019-02-19T18:06:30.564127: step 728, loss 1.62186, accuracy 0.4375, precision [0.0, 0.5, nan, 0.5, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [nan, 0.8, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:30.714360: step 729, loss 2.43222, accuracy 0.5, precision [nan, 0.3333333333333333, nan, 0.625, 0.5, 0.5, nan, nan, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.625, 1.0, 0.5, 0.0, nan, nan]
2019-02-19T18:06:30.870829: step 730, loss 2.05568, accuracy 0.5, precision [nan, 1.0, 0.5, 0.75, 0.0, 1.0, 0.0, 0.5, nan], recall [0.0, 0.5, 0.5, 0.5, nan, 1.0, 0.0, 0.6666666666666666, nan]
2019-02-19T18:06:31.025564: step 731, loss 2.13425, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.3333333333333333, 0.0], recall [0.5, 0.5, 0.0, 0.4, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:06:31.181481: step 732, loss 0.519003, accuracy 0.6875, precision [0.5, 0.5, 1.0, 0.3333333333333333, 1.0, nan, nan, 0.75, nan], recall [0.5, 0.5, 0.5, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:31.334354: step 733, loss 1.53455, accuracy 0.375, precision [0.0, 0.5, 1.0, 0.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [nan, 0.25, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:06:31.486401: step 734, loss 2.6503, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.2, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, nan, nan, 0.2, 0.0]
2019-02-19T18:06:31.642094: step 735, loss 3.45447, accuracy 0.375, precision [0.5, 0.5, 0.0, 0.5, 1.0, 0.0, nan, 0.0, 0.0], recall [0.5, 0.2, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:31.795720: step 736, loss 2.02435, accuracy 0.5625, precision [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, nan], recall [nan, 1.0, nan, 0.42857142857142855, 0.0, nan, 0.5, 0.6666666666666666, nan]
2019-02-19T18:06:31.948642: step 737, loss 2.52568, accuracy 0.4375, precision [0.3333333333333333, 0.5, 0.5, 0.5, 1.0, 0.0, nan, nan, 0.0], recall [1.0, 1.0, 0.5, 0.75, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:06:32.106333: step 738, loss 2.39758, accuracy 0.4375, precision [0.5, 0.6666666666666666, 0.0, 0.4, 1.0, nan, nan, 0.0, nan], recall [0.5, 0.6666666666666666, 0.0, 0.4, 0.6666666666666666, nan, nan, nan, 0.0]
2019-02-19T18:06:32.259039: step 739, loss 1.06343, accuracy 0.625, precision [0.5, 1.0, 0.5, 0.8, 1.0, 0.0, 1.0, 0.0, 0.5], recall [0.5, 1.0, 0.5, 0.6666666666666666, 0.5, nan, 0.5, nan, 1.0]
2019-02-19T18:06:32.410322: step 740, loss 1.40342, accuracy 0.75, precision [1.0, 0.75, nan, 0.5, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.75, nan, 1.0, 0.75, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:06:32.569897: step 741, loss 2.19674, accuracy 0.5625, precision [0.0, 0.5, 0.5, 0.75, 0.6, 0.0, nan, 1.0, nan], recall [nan, 0.5, 0.3333333333333333, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:32.723010: step 742, loss 1.57668, accuracy 0.5625, precision [nan, 0.6666666666666666, 1.0, 0.3333333333333333, nan, nan, 1.0, 1.0, nan], recall [0.0, 0.6666666666666666, 0.3333333333333333, 0.75, 0.0, nan, 1.0, 0.6666666666666666, nan]
2019-02-19T18:06:32.876338: step 743, loss 2.81947, accuracy 0.5, precision [1.0, 0.25, 0.5, 1.0, 0.0, 0.0, nan, nan, nan], recall [0.5, 1.0, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:06:33.037444: step 744, loss 2.52223, accuracy 0.5, precision [0.5, 0.25, 0.5, 0.0, 1.0, 0.0, nan, 1.0, 1.0], recall [0.5, 0.5, 0.5, 0.0, 1.0, nan, nan, 1.0, 1.0]
2019-02-19T18:06:33.194629: step 745, loss 0.878866, accuracy 0.6875, precision [nan, nan, 1.0, 0.6666666666666666, 0.8, nan, nan, 0.5, nan], recall [nan, nan, 0.25, 0.8, 0.8, nan, nan, 1.0, nan]
2019-02-19T18:06:33.351215: step 746, loss 2.30788, accuracy 0.5625, precision [nan, 0.6666666666666666, 1.0, 0.6, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [nan, 1.0, 0.5, 0.42857142857142855, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:06:33.508799: step 747, loss 3.42595, accuracy 0.375, precision [1.0, 0.3333333333333333, 0.5, 0.25, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.25, 1.0, 0.2, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:33.660785: step 748, loss 2.37708, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.0, 1.0, 0.5714285714285714, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:06:33.817599: step 749, loss 1.38103, accuracy 0.625, precision [1.0, nan, 1.0, 0.75, 0.6666666666666666, 0.0, nan, 0.5, 0.0], recall [1.0, 0.0, 0.5, 0.5, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:06:33.971572: step 750, loss 1.2392, accuracy 0.6875, precision [1.0, 0.25, 0.5, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.5, 1.0, 0.5714285714285714, 0.6666666666666666, nan, nan, 1.0, nan]

Evaluation:
[[ 40  11   2  21   1   2   0   4   1]
 [ 10  83   2  52   2   0   0   3   4]
 [  0   6  51  34   1   0   1   1   0]
 [  3  35  18 220   5   6   2   8   3]
 [  2   5   3  19 132   7   1   0   4]
 [  4   7   0  36   0  10   1   0   2]
 [  1   1   0  11   2   7   6   0   2]
 [  2  13   0  44   2   1   0  40   3]
 [  2   2   0  13   1   1   0   1   5]]
2019-02-19T18:06:36.389011: step 750, loss 1.52952, accuracy 0.572683, precision [0.4878048780487805, 0.532051282051282, 0.5425531914893617, 0.7333333333333333, 0.7630057803468208, 0.16666666666666666, 0.2, 0.38095238095238093, 0.2], recall [0.625, 0.50920245398773, 0.6710526315789473, 0.4888888888888889, 0.9041095890410958, 0.29411764705882354, 0.5454545454545454, 0.7017543859649122, 0.20833333333333334]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-750

2019-02-19T18:06:36.692621: step 751, loss 1.23149, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.5, 0.8, nan, nan, nan, nan], recall [nan, 1.0, 1.0, 0.75, 0.8, 0.0, nan, 0.0, nan]
2019-02-19T18:06:36.854673: step 752, loss 1.41983, accuracy 0.5625, precision [nan, 1.0, 0.3333333333333333, 0.6666666666666666, nan, 0.0, 1.0, nan, 0.0], recall [0.0, 0.75, 1.0, 0.8, nan, 0.0, 1.0, 0.0, 0.0]
2019-02-19T18:06:37.008983: step 753, loss 0.943978, accuracy 0.75, precision [0.5, 0.6666666666666666, 0.5, 0.5, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:37.164769: step 754, loss 1.50574, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.75, 1.0, 0.0, 0.0, 0.6666666666666666, nan], recall [1.0, nan, 0.3333333333333333, 0.42857142857142855, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:06:37.320392: step 755, loss 2.16144, accuracy 0.4375, precision [0.5, 0.6666666666666666, nan, 0.4, 0.3333333333333333, 1.0, 0.0, 0.0, nan], recall [0.5, 0.4, 0.0, 0.4, 1.0, 1.0, nan, nan, 0.0]
2019-02-19T18:06:37.472058: step 756, loss 2.15384, accuracy 0.375, precision [0.0, 1.0, 0.0, 0.3333333333333333, 0.6, nan, 0.5, 0.0, nan], recall [nan, 0.5, 0.0, 0.25, 1.0, 0.0, 0.5, nan, 0.0]
2019-02-19T18:06:37.624230: step 757, loss 2.78368, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.375, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.5, 1.0, 0.5, nan, 0.0, nan, 0.0]
2019-02-19T18:06:37.783509: step 758, loss 1.37283, accuracy 0.5625, precision [nan, 0.0, nan, 0.7142857142857143, 0.6666666666666666, 1.0, nan, 0.3333333333333333, nan], recall [0.0, nan, 0.0, 1.0, 1.0, 0.3333333333333333, nan, 1.0, nan]
2019-02-19T18:06:37.935604: step 759, loss 1.72032, accuracy 0.625, precision [0.0, 0.6666666666666666, 1.0, 0.6, 1.0, 1.0, 0.0, 1.0, 0.0], recall [nan, 1.0, 0.5, 0.75, 0.6666666666666666, 1.0, nan, 1.0, 0.0]
2019-02-19T18:06:38.088568: step 760, loss 2.10663, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.0, 0.75, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.5, 0.0, 0.6, 0.75, 0.0, nan, nan, 0.0]
2019-02-19T18:06:38.240673: step 761, loss 2.32804, accuracy 0.4375, precision [0.0, 0.0, nan, 0.25, 0.8571428571428571, nan, nan, 0.0, nan], recall [0.0, 0.0, nan, 0.3333333333333333, 0.75, 0.0, nan, nan, nan]
2019-02-19T18:06:38.394878: step 762, loss 1.18114, accuracy 0.5625, precision [0.6666666666666666, 0.0, nan, 0.42857142857142855, 1.0, nan, 1.0, 0.5, nan], recall [0.6666666666666666, 0.0, 0.0, 0.75, 1.0, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T18:06:38.546505: step 763, loss 1.77573, accuracy 0.5625, precision [nan, 1.0, nan, 0.5, 0.75, 0.0, nan, nan, nan], recall [nan, 0.6666666666666666, 0.0, 0.8, 0.6, 0.0, nan, 0.0, nan]
2019-02-19T18:06:38.697645: step 764, loss 1.8097, accuracy 0.625, precision [nan, 1.0, nan, 0.3333333333333333, 1.0, nan, nan, 1.0, 0.0], recall [0.0, 0.8, nan, 1.0, 0.75, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:06:38.850051: step 765, loss 1.09432, accuracy 0.6875, precision [0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, nan], recall [nan, 1.0, nan, 0.8, 0.0, 1.0, 0.5, 0.5, 0.0]
2019-02-19T18:06:39.004171: step 766, loss 3.89419, accuracy 0.5, precision [0.0, 1.0, 0.75, 0.6666666666666666, 0.2, 0.0, nan, nan, nan], recall [nan, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:06:39.156637: step 767, loss 1.78578, accuracy 0.5625, precision [0.5, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.5, 1.0, 1.0, 0.4444444444444444, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:39.309897: step 768, loss 2.40888, accuracy 0.375, precision [0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:39.463603: step 769, loss 1.29277, accuracy 0.5625, precision [1.0, 0.4, 1.0, 0.5714285714285714, nan, nan, 1.0, 0.0, nan], recall [0.3333333333333333, 1.0, 1.0, 0.6666666666666666, nan, 0.0, 0.5, nan, 0.0]
2019-02-19T18:06:39.618111: step 770, loss 1.22397, accuracy 0.75, precision [0.0, 1.0, nan, 0.75, 1.0, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, nan, 0.8571428571428571, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:39.771742: step 771, loss 3.15886, accuracy 0.4375, precision [0.5, nan, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.0], recall [1.0, 0.0, 0.0, 0.75, 0.6666666666666666, nan, nan, 0.25, nan]
2019-02-19T18:06:39.926423: step 772, loss 2.07245, accuracy 0.5625, precision [0.5, 0.5, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, nan], recall [0.3333333333333333, 1.0, nan, 0.25, 0.75, 0.0, 1.0, 1.0, nan]
2019-02-19T18:06:40.080697: step 773, loss 3.55753, accuracy 0.375, precision [0.5, 0.3333333333333333, 0.25, 1.0, 0.0, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 0.5, 0.3333333333333333, nan, nan, 0.0, nan, 0.0]
2019-02-19T18:06:40.234867: step 774, loss 1.51918, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.5714285714285714, 1.0, nan, 0.3333333333333333, 1.0, 0.0], recall [0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, nan]
2019-02-19T18:06:40.388994: step 775, loss 1.69466, accuracy 0.625, precision [1.0, 0.3333333333333333, nan, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.8, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:06:40.538594: step 776, loss 0.781686, accuracy 0.75, precision [0.5, 0.0, 0.0, 1.0, 1.0, nan, nan, 1.0, nan], recall [1.0, nan, nan, 0.7, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:06:40.696832: step 777, loss 2.27937, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.5, nan], recall [nan, 1.0, 1.0, 0.4, 0.4, nan, nan, 1.0, 0.0]
2019-02-19T18:06:40.850019: step 778, loss 3.01854, accuracy 0.4375, precision [0.6666666666666666, nan, 1.0, 0.6, 1.0, 0.0, nan, 0.0, 0.0], recall [0.6666666666666666, 0.0, 0.2, 0.6, 1.0, nan, nan, nan, nan]
2019-02-19T18:06:41.003611: step 779, loss 2.9511, accuracy 0.25, precision [1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.3333333333333333, 0.3333333333333333, 0.0, 0.14285714285714285, 0.5, nan, nan, nan, nan]
2019-02-19T18:06:41.158014: step 780, loss 2.85363, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.0], recall [0.6666666666666666, 0.5, nan, 0.2, 0.6666666666666666, nan, 0.0, 1.0, 0.0]
2019-02-19T18:06:41.313540: step 781, loss 1.36365, accuracy 0.8125, precision [1.0, 0.5, nan, 1.0, 1.0, nan, nan, nan, 0.0], recall [0.5, 1.0, 0.0, 1.0, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:06:41.464254: step 782, loss 1.97383, accuracy 0.5, precision [0.5, 1.0, 0.0, 0.5, 0.6666666666666666, nan, 0.5, nan, 0.0], recall [1.0, 0.5, nan, 0.5, 0.6666666666666666, nan, 1.0, 0.0, nan]
2019-02-19T18:06:41.626969: step 783, loss 2.57802, accuracy 0.5, precision [0.5, 0.5, 0.6666666666666666, 0.4, 0.0, nan, nan, 1.0, nan], recall [0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, nan, 0.0, 0.25, nan]
2019-02-19T18:06:41.783342: step 784, loss 2.65524, accuracy 0.375, precision [0.0, 0.4, 0.0, 0.75, 0.0, nan, nan, 0.25, nan], recall [0.0, 1.0, 0.0, 0.42857142857142855, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:41.942853: step 785, loss 2.38207, accuracy 0.4375, precision [1.0, nan, 0.0, 0.6666666666666666, 0.6, 0.0, nan, 0.0, 0.0], recall [0.5, nan, nan, 0.5, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T18:06:42.097779: step 786, loss 2.29312, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 0.3333333333333333, 0.4, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:06:42.250039: step 787, loss 1.19039, accuracy 0.625, precision [nan, 0.0, 0.0, 0.8, 0.8, nan, 1.0, 0.3333333333333333, nan], recall [nan, nan, nan, 0.5, 0.8, nan, 1.0, 1.0, 0.0]
2019-02-19T18:06:42.406282: step 788, loss 1.60489, accuracy 0.5625, precision [nan, 0.5, nan, 0.6, 0.75, 1.0, 0.0, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.6, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:06:42.561753: step 789, loss 2.06494, accuracy 0.625, precision [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, nan], recall [0.0, nan, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:06:42.719548: step 790, loss 1.24607, accuracy 0.5625, precision [1.0, 0.0, nan, 0.6666666666666666, 0.75, nan, nan, 0.3333333333333333, nan], recall [0.5, 0.0, nan, 0.8, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:42.878022: step 791, loss 1.44805, accuracy 0.5625, precision [nan, nan, 0.0, 1.0, 1.0, 0.25, 0.5, 0.6666666666666666, nan], recall [nan, nan, nan, 0.5, 0.75, 1.0, 0.5, 0.4, nan]
2019-02-19T18:06:43.032186: step 792, loss 1.66461, accuracy 0.5, precision [0.0, 1.0, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan], recall [nan, 0.5, 1.0, 1.0, 0.4, 0.0, nan, 0.5, nan]
2019-02-19T18:06:43.186211: step 793, loss 2.34923, accuracy 0.4375, precision [1.0, 1.0, 0.2, 0.2, 1.0, nan, nan, 0.0, nan], recall [0.5, 1.0, 0.5, 0.5, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:43.339649: step 794, loss 1.56627, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.25, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:06:43.489947: step 795, loss 1.83057, accuracy 0.5, precision [nan, 0.0, 1.0, 0.0, 0.6, 0.0, 1.0, 0.6666666666666666, 0.0], recall [0.0, nan, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, nan]
2019-02-19T18:06:43.642092: step 796, loss 3.19522, accuracy 0.3125, precision [0.0, 0.0, nan, 0.2, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, nan, 0.3333333333333333, nan]
2019-02-19T18:06:43.797692: step 797, loss 2.71317, accuracy 0.3125, precision [0.0, 0.25, 0.3333333333333333, 0.4, nan, 0.0, nan, 1.0, 0.0], recall [nan, 0.5, 0.5, 0.3333333333333333, 0.0, 0.0, nan, 0.25, nan]
2019-02-19T18:06:43.952329: step 798, loss 1.8185, accuracy 0.5, precision [0.5, 0.5, 1.0, 0.25, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 0.3333333333333333, 0.6666666666666666, 1.0, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:06:44.109083: step 799, loss 1.48843, accuracy 0.625, precision [nan, 1.0, 0.6666666666666666, 0.4, 0.75, nan, 1.0, 0.0, nan], recall [nan, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.0, nan]
2019-02-19T18:06:44.263765: step 800, loss 1.55128, accuracy 0.625, precision [0.0, 0.5, 1.0, 0.6, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 0.5, 1.0, 0.6, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:06:44.420199: step 801, loss 1.62869, accuracy 0.625, precision [0.6, 1.0, 0.5, 0.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.75, 1.0, 1.0, 0.0, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:06:44.570724: step 802, loss 3.72817, accuracy 0.375, precision [0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, nan, nan, nan], recall [0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, nan, 0.0, 0.0]
2019-02-19T18:06:44.726023: step 803, loss 3.36911, accuracy 0.375, precision [0.3333333333333333, nan, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, nan], recall [1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, nan]
2019-02-19T18:06:44.877074: step 804, loss 2.90622, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.75, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.5, nan, 0.375, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:06:45.033870: step 805, loss 2.35196, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.0, 0.75, 0.6, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 0.0, 0.375, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:45.192736: step 806, loss 2.39569, accuracy 0.5625, precision [0.5, 0.0, 1.0, 0.5, 1.0, 0.25, nan, nan, nan], recall [1.0, 0.0, 1.0, 0.2, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:06:45.346644: step 807, loss 2.60781, accuracy 0.375, precision [0.4, 0.5, 0.5, 0.5, nan, 0.0, nan, 0.0, nan], recall [0.6666666666666666, 0.25, 1.0, 0.2857142857142857, nan, nan, 0.0, nan, nan]
2019-02-19T18:06:45.502143: step 808, loss 2.18402, accuracy 0.5625, precision [0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.5, 0.0, 0.0, 0.8333333333333334, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:06:45.653854: step 809, loss 2.77459, accuracy 0.375, precision [0.4, 0.16666666666666666, nan, 0.3333333333333333, 1.0, nan, nan, nan, nan], recall [0.4, 0.5, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:06:45.815898: step 810, loss 2.14339, accuracy 0.4375, precision [0.5, 0.5, 0.0, 0.0, 0.75, 0.0, 0.6666666666666666, 0.0, nan], recall [0.5, 0.5, 0.0, 0.0, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:06:45.966499: step 811, loss 0.910407, accuracy 0.6875, precision [1.0, 0.5, 0.0, 0.5714285714285714, 1.0, nan, nan, 1.0, nan], recall [0.3333333333333333, 1.0, 0.0, 0.8, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:46.120506: step 812, loss 2.60052, accuracy 0.4375, precision [0.5, 0.5, 0.0, 0.0, 1.0, 1.0, nan, nan, nan], recall [0.3333333333333333, 0.6666666666666666, nan, 0.0, 0.6666666666666666, 0.3333333333333333, nan, nan, nan]
2019-02-19T18:06:46.274058: step 813, loss 2.53771, accuracy 0.5625, precision [1.0, 1.0, 0.3333333333333333, 0.4, 0.75, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.5, 0.5, 1.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:46.428910: step 814, loss 1.64895, accuracy 0.5, precision [1.0, 0.25, 0.5, 0.6, 1.0, nan, nan, 0.0, nan], recall [0.25, 1.0, 1.0, 0.6, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:06:46.585151: step 815, loss 2.26776, accuracy 0.375, precision [0.6666666666666666, 0.25, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [0.5, 0.5, 0.5, 0.0, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:06:46.746720: step 816, loss 4.02174, accuracy 0.4375, precision [nan, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:06:46.905460: step 817, loss 3.82062, accuracy 0.375, precision [0.0, 0.5, 0.2, 0.5, 0.0, 0.0, nan, 1.0, nan], recall [0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:06:47.060145: step 818, loss 2.14679, accuracy 0.625, precision [0.0, 0.5, 0.0, 1.0, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.0, 0.25, nan, 0.8333333333333334, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:47.215587: step 819, loss 3.39969, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [0.3333333333333333, 0.3333333333333333, nan, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:06:47.368821: step 820, loss 2.54665, accuracy 0.375, precision [nan, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.3333333333333333, 0.0, 0.4, 0.75, nan, nan, nan, nan]
2019-02-19T18:06:47.522766: step 821, loss 1.35014, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:06:47.677095: step 822, loss 0.992516, accuracy 0.8125, precision [nan, 0.8, nan, 0.8, 1.0, 0.5, nan, nan, nan], recall [nan, 0.8, nan, 0.8, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:06:47.832770: step 823, loss 1.67469, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.8333333333333334, 0.4, nan, 0.0, nan, nan], recall [1.0, 0.25, 1.0, 1.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:47.988552: step 824, loss 1.74337, accuracy 0.5, precision [1.0, 0.3333333333333333, 1.0, 0.5, 0.5, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.5, 0.2857142857142857, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:48.144499: step 825, loss 3.23617, accuracy 0.4375, precision [0.5, 0.3333333333333333, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, nan, nan], recall [1.0, 0.25, 0.0, 0.5714285714285714, 0.5, nan, nan, nan, nan]
2019-02-19T18:06:48.297603: step 826, loss 2.1404, accuracy 0.5, precision [0.0, 1.0, 0.5, 0.25, 1.0, nan, 0.0, 0.6, nan], recall [0.0, 1.0, 0.3333333333333333, 0.25, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:06:48.449815: step 827, loss 1.40825, accuracy 0.4375, precision [0.5, 0.6666666666666666, 0.5, 0.5, nan, nan, 0.0, 0.0, nan], recall [1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, nan, nan, nan, nan, nan]
2019-02-19T18:06:48.602363: step 828, loss 2.58917, accuracy 0.4375, precision [0.5, 0.5, 0.3333333333333333, 0.5, 0.5, nan, 0.0, 1.0, 0.0], recall [1.0, 0.5, 0.3333333333333333, 0.25, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:06:48.756986: step 829, loss 1.74891, accuracy 0.5625, precision [0.5, 1.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.5, nan], recall [1.0, 0.6666666666666666, 0.0, 0.6, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:48.907628: step 830, loss 1.36914, accuracy 0.6875, precision [0.8, 0.5, 1.0, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [0.5714285714285714, 1.0, 0.5, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:49.063339: step 831, loss 1.34135, accuracy 0.6875, precision [0.0, nan, nan, 0.625, 0.8333333333333334, nan, nan, 1.0, nan], recall [nan, 0.0, nan, 0.7142857142857143, 0.8333333333333334, nan, 0.0, 1.0, nan]
2019-02-19T18:06:49.214398: step 832, loss 3.148, accuracy 0.4375, precision [0.0, 0.6, 1.0, 0.3333333333333333, 1.0, nan, nan, nan, 0.0], recall [0.0, 0.75, 0.6666666666666666, 0.2, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:06:49.368120: step 833, loss 3.14102, accuracy 0.375, precision [nan, 0.0, 0.3333333333333333, 0.0, 0.8333333333333334, 0.0, nan, nan, nan], recall [nan, 0.0, 0.5, 0.0, 0.7142857142857143, 0.0, nan, nan, nan]
2019-02-19T18:06:49.521330: step 834, loss 1.66287, accuracy 0.625, precision [1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 0.5, nan, nan], recall [1.0, 0.6666666666666666, nan, 0.3333333333333333, 0.5714285714285714, nan, 1.0, nan, nan]
2019-02-19T18:06:49.673737: step 835, loss 2.13912, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, nan, nan, nan], recall [nan, 1.0, 0.5, 0.3333333333333333, 0.25, nan, nan, nan, nan]
2019-02-19T18:06:49.829756: step 836, loss 2.29884, accuracy 0.4375, precision [1.0, 0.5, 1.0, 0.5, 0.5, 0.0, nan, 0.0, 0.0], recall [0.5, 1.0, 1.0, 0.4, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:06:49.986349: step 837, loss 3.27392, accuracy 0.375, precision [0.0, 0.0, nan, 0.7142857142857143, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.625, 0.25, nan, 0.0, nan, nan]
2019-02-19T18:06:50.136838: step 838, loss 2.23891, accuracy 0.5, precision [0.0, 0.5, nan, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, nan], recall [nan, 0.5, nan, 0.75, 0.0, 0.0, nan, 0.25, nan]
2019-02-19T18:06:50.292665: step 839, loss 1.33572, accuracy 0.625, precision [0.5, 0.5, nan, 0.3333333333333333, 1.0, nan, 1.0, 0.3333333333333333, nan], recall [1.0, 1.0, 0.0, 0.3333333333333333, 0.8333333333333334, 0.0, 0.5, 1.0, nan]
2019-02-19T18:06:50.445307: step 840, loss 1.54359, accuracy 0.4375, precision [0.5, 1.0, nan, 0.2, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.5, 0.3333333333333333, nan, 0.2, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:06:50.603115: step 841, loss 1.85795, accuracy 0.5625, precision [0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, nan, 0.5, 1.0, nan], recall [0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, nan, 1.0, 1.0, nan]
2019-02-19T18:06:50.758080: step 842, loss 1.53864, accuracy 0.5625, precision [nan, 0.25, 0.0, 0.75, 1.0, 0.5, nan, 1.0, nan], recall [0.0, 0.5, nan, 0.75, 0.75, 0.5, nan, 0.5, nan]
2019-02-19T18:06:50.911446: step 843, loss 1.88093, accuracy 0.5625, precision [0.3333333333333333, 0.6666666666666666, 0.6, 0.6, nan, nan, nan, nan, nan], recall [1.0, 0.6666666666666666, 0.75, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:06:51.064612: step 844, loss 1.68234, accuracy 0.6875, precision [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.75, 0.0, 1.0, 0.6666666666666666, nan], recall [1.0, 0.25, nan, 0.6666666666666666, 1.0, nan, 1.0, 0.6666666666666666, nan]
2019-02-19T18:06:51.221491: step 845, loss 3.08832, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, nan, 1.0], recall [nan, 1.0, 0.0, 0.5, 0.5, 0.0, nan, 0.0, 1.0]
2019-02-19T18:06:51.374776: step 846, loss 1.81522, accuracy 0.6875, precision [nan, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 0.5, 1.0, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:06:51.529195: step 847, loss 2.02371, accuracy 0.5625, precision [nan, 1.0, 0.6666666666666666, 0.5, 0.5, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:51.681794: step 848, loss 2.6158, accuracy 0.4375, precision [1.0, nan, 0.0, 0.8, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 0.0, nan, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:06:51.834598: step 849, loss 2.66116, accuracy 0.375, precision [0.0, 0.75, nan, 0.16666666666666666, 0.6666666666666666, 0.0, nan, nan, 0.0], recall [0.0, 0.6, 0.0, 0.25, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:51.984378: step 850, loss 2.24024, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.5, nan, 0.0, 0.5, nan]
2019-02-19T18:06:52.140074: step 851, loss 2.35599, accuracy 0.4375, precision [1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, nan], recall [0.3333333333333333, 0.6666666666666666, nan, 0.25, nan, nan, 1.0, 1.0, nan]
2019-02-19T18:06:52.293781: step 852, loss 2.03299, accuracy 0.5625, precision [0.3333333333333333, nan, 0.5, 0.6, 0.75, nan, 0.0, 1.0, nan], recall [1.0, 0.0, 1.0, 0.6, 0.75, 0.0, nan, 0.5, nan]
2019-02-19T18:06:52.445262: step 853, loss 2.51163, accuracy 0.4375, precision [0.6666666666666666, 0.0, 0.0, 0.6, 0.6666666666666666, 0.0, nan, nan, 0.0], recall [0.5, 0.0, 0.0, 0.75, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:52.605540: step 854, loss 1.78999, accuracy 0.4375, precision [0.6666666666666666, 0.5, 0.0, 0.5, 1.0, nan, 1.0, 0.0, 0.0], recall [0.5, 0.5, 0.0, 0.2857142857142857, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:06:52.758865: step 855, loss 1.81765, accuracy 0.5, precision [nan, 0.75, nan, 0.5, 1.0, 0.0, 0.0, nan, 0.0], recall [0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:52.912428: step 856, loss 2.03118, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.75, 1.0, 0.0, nan, nan, nan], recall [nan, 0.3333333333333333, nan, 0.375, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:06:53.063762: step 857, loss 2.16138, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.25, 0.0], recall [0.5, nan, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:06:53.216415: step 858, loss 1.68833, accuracy 0.625, precision [0.6666666666666666, 0.0, 1.0, 0.7142857142857143, 0.5, nan, 0.0, nan, nan], recall [1.0, 0.0, 0.6666666666666666, 0.8333333333333334, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:06:53.370871: step 859, loss 1.39096, accuracy 0.5625, precision [nan, 0.0, nan, 0.625, 1.0, nan, nan, 0.25, nan], recall [0.0, 0.0, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:06:53.527173: step 860, loss 2.33489, accuracy 0.5, precision [0.75, nan, 0.0, 0.5, nan, 0.0, 0.0, 0.6666666666666666, nan], recall [0.6, nan, 0.0, 0.75, 0.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:06:53.679182: step 861, loss 1.90938, accuracy 0.5625, precision [0.0, 0.0, 1.0, 1.0, 1.0, nan, nan, 0.0, nan], recall [nan, nan, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:06:53.837305: step 862, loss 1.17344, accuracy 0.625, precision [1.0, 1.0, 0.5, 0.5, nan, 0.0, 0.0, 1.0, nan], recall [0.6666666666666666, 0.5, 1.0, 0.75, 0.0, nan, nan, 0.75, nan]
2019-02-19T18:06:53.988319: step 863, loss 1.6663, accuracy 0.625, precision [1.0, 0.5, nan, 0.8, 0.75, 0.0, 0.0, 0.5, nan], recall [0.3333333333333333, 1.0, nan, 0.5714285714285714, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:06:54.144755: step 864, loss 2.11491, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.4, 1.0, 1.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.5, 0.5, 0.5, 1.0, nan, nan, 0.0]
2019-02-19T18:06:54.298791: step 865, loss 3.14203, accuracy 0.375, precision [0.0, 0.0, 0.5, 0.0, 1.0, nan, nan, 1.0, 0.0], recall [0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:06:54.451558: step 866, loss 2.15007, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, nan, nan, 0.5, nan], recall [0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:06:54.608238: step 867, loss 2.06099, accuracy 0.4375, precision [nan, 0.5, 0.5, 0.4, 0.3333333333333333, 0.0, 1.0, 0.5, nan], recall [0.0, 0.3333333333333333, 0.5, 0.5, 1.0, nan, 0.5, 0.5, nan]
2019-02-19T18:06:54.762022: step 868, loss 2.22296, accuracy 0.625, precision [nan, 1.0, nan, 0.75, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, nan, 0.8571428571428571, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T18:06:54.914890: step 869, loss 1.83189, accuracy 0.625, precision [nan, 0.5, nan, 0.6, 1.0, nan, 0.5, nan, nan], recall [0.0, 0.5, nan, 0.8571428571428571, 1.0, nan, 0.3333333333333333, 0.0, nan]
2019-02-19T18:06:55.066866: step 870, loss 1.54864, accuracy 0.75, precision [0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, nan, 0.5, 0.6666666666666666, nan]
2019-02-19T18:06:55.225820: step 871, loss 2.16776, accuracy 0.5625, precision [nan, 0.5, 0.6, 0.4, 1.0, nan, nan, 1.0, 0.0], recall [nan, 0.3333333333333333, 0.75, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:06:55.383267: step 872, loss 1.53551, accuracy 0.375, precision [nan, 1.0, 0.5, 0.4, 0.0, 0.5, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 0.3333333333333333, 0.4, nan, 0.5, 0.0, 0.5, nan]
2019-02-19T18:06:55.538312: step 873, loss 1.21356, accuracy 0.6875, precision [nan, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, nan, nan, nan], recall [nan, 0.75, 1.0, 0.6, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:06:55.694510: step 874, loss 2.9141, accuracy 0.4375, precision [nan, 0.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, 0.5, nan], recall [nan, nan, 0.0, 0.625, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:06:55.849834: step 875, loss 2.94897, accuracy 0.5, precision [0.3333333333333333, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, nan], recall [1.0, 1.0, 0.3333333333333333, 0.16666666666666666, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:06:56.002535: step 876, loss 1.13056, accuracy 0.5625, precision [nan, 0.3333333333333333, 1.0, 0.8333333333333334, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 1.0, 1.0, 0.625, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:06:56.155326: step 877, loss 1.81946, accuracy 0.5, precision [0.0, nan, 0.0, 0.5, 1.0, nan, nan, nan, nan], recall [nan, nan, 0.0, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:06:56.314972: step 878, loss 1.58291, accuracy 0.5, precision [0.3333333333333333, 0.5, nan, 0.5714285714285714, 0.0, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, nan, nan, nan, 0.5, 0.0]
2019-02-19T18:06:56.473474: step 879, loss 1.43829, accuracy 0.625, precision [0.0, 0.8333333333333334, nan, 0.3333333333333333, 1.0, nan, 0.0, 1.0, 0.0], recall [0.0, 0.8333333333333334, nan, 0.3333333333333333, 0.75, 0.0, nan, 1.0, nan]
2019-02-19T18:06:56.625123: step 880, loss 2.36405, accuracy 0.5, precision [0.0, 0.25, 1.0, 0.5, 1.0, nan, 0.0, nan, 0.0], recall [nan, 1.0, 0.6666666666666666, 0.2, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:06:56.777201: step 881, loss 3.24589, accuracy 0.4375, precision [0.5, 0.0, 0.0, 0.6, 0.75, 0.0, nan, nan, nan], recall [1.0, 0.0, nan, 0.375, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:06:56.930067: step 882, loss 2.99051, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.3333333333333333, nan, nan, nan, 0.0, 0.0], recall [nan, 0.42857142857142855, 0.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:06:57.087842: step 883, loss 1.76749, accuracy 0.375, precision [nan, 0.5, 0.0, 0.4, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.5, 0.0, 0.3333333333333333, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:06:57.241625: step 884, loss 3.03184, accuracy 0.375, precision [0.3333333333333333, 0.0, 1.0, 0.5, 0.25, 0.0, nan, 1.0, nan], recall [1.0, 0.0, 0.25, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:06:57.400201: step 885, loss 3.25554, accuracy 0.3125, precision [0.0, 0.0, 0.3333333333333333, 0.75, 0.5, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 0.5, 0.75, 0.3333333333333333, 0.0, nan, 0.0, 0.0]
2019-02-19T18:06:57.554143: step 886, loss 2.20515, accuracy 0.375, precision [0.0, 0.0, 0.4, 0.5, 0.75, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 0.6666666666666666, 0.16666666666666666, 0.75, nan, nan, nan, nan]
2019-02-19T18:06:57.708682: step 887, loss 2.49135, accuracy 0.5, precision [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.6, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:06:57.861384: step 888, loss 2.61197, accuracy 0.5, precision [0.0, nan, 0.5, 0.8, 1.0, 0.5, 0.0, 0.0, nan], recall [nan, nan, 1.0, 0.5, 0.5, 0.5, 0.0, nan, 0.0]
2019-02-19T18:06:58.013247: step 889, loss 1.39975, accuracy 0.6875, precision [1.0, 0.5, nan, 0.5, 1.0, nan, nan, 1.0, nan], recall [0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:06:58.172376: step 890, loss 1.52947, accuracy 0.625, precision [nan, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.0], recall [0.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 0.3333333333333333, nan, 1.0, nan]
2019-02-19T18:06:58.326575: step 891, loss 2.43781, accuracy 0.5625, precision [nan, 1.0, 0.6666666666666666, 0.5714285714285714, 0.5, 1.0, nan, 0.0, nan], recall [0.0, 0.5, 1.0, 0.8, 0.5, 0.3333333333333333, 0.0, nan, nan]
2019-02-19T18:06:58.482509: step 892, loss 1.39978, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.6666666666666666, 0.4, 1.0, 0.5, nan, 1.0, nan], recall [0.5, 0.5, 0.6666666666666666, 0.5, 0.5, 0.5, nan, 1.0, nan]
2019-02-19T18:06:58.639959: step 893, loss 1.14652, accuracy 0.625, precision [1.0, 1.0, 0.5, 0.3333333333333333, 0.75, nan, nan, 0.6666666666666666, 0.5], recall [1.0, 0.5, 0.5, 0.3333333333333333, 1.0, 0.0, nan, 1.0, 0.5]
2019-02-19T18:06:58.795722: step 894, loss 1.83052, accuracy 0.5, precision [nan, nan, 0.0, 0.75, 0.5, 1.0, nan, 0.3333333333333333, nan], recall [nan, 0.0, 0.0, 0.6, 0.6666666666666666, 0.5, nan, 1.0, 0.0]
2019-02-19T18:06:58.955314: step 895, loss 1.54627, accuracy 0.625, precision [0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, nan], recall [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, nan, 0.5, 0.0]
2019-02-19T18:06:59.114780: step 896, loss 2.79026, accuracy 0.5, precision [1.0, 0.5, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 0.5, nan], recall [0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:06:59.271087: step 897, loss 1.02013, accuracy 0.6875, precision [0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, nan, 1.0, nan, nan], recall [0.5, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.5, 0.0, nan]
2019-02-19T18:06:59.427288: step 898, loss 1.24163, accuracy 0.75, precision [1.0, 1.0, 0.0, 1.0, 1.0, nan, nan, 0.5, nan], recall [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:06:59.581866: step 899, loss 1.9114, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.0, 0.5714285714285714, 0.0, 0.0, nan, 1.0, 0.0], recall [nan, 1.0, 0.0, 0.5, nan, 0.0, 0.0, 1.0, nan]
2019-02-19T18:06:59.737905: step 900, loss 1.09374, accuracy 0.625, precision [0.0, 0.0, 1.0, 1.0, 1.0, 0.5, nan, 0.5, nan], recall [nan, nan, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0]
2019-02-19T18:06:59.890285: step 901, loss 1.47366, accuracy 0.5625, precision [0.3333333333333333, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, nan, nan], recall [1.0, 0.6666666666666666, 0.75, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:07:00.041862: step 902, loss 2.6351, accuracy 0.5, precision [1.0, 0.5, 0.6666666666666666, 0.4, 1.0, nan, 0.0, 0.5, nan], recall [1.0, 0.5, 0.6666666666666666, 0.5, 0.5, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T18:07:00.192679: step 903, loss 2.14673, accuracy 0.5, precision [0.6666666666666666, nan, 0.0, 0.4, 1.0, 0.0, nan, nan, 0.0], recall [0.6666666666666666, nan, 0.0, 0.5, 0.8, nan, nan, 0.0, nan]
2019-02-19T18:07:00.350647: step 904, loss 1.63407, accuracy 0.625, precision [0.75, 0.5, nan, 0.5714285714285714, 0.5, nan, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:07:00.501527: step 905, loss 1.74963, accuracy 0.5, precision [0.6666666666666666, nan, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, nan], recall [1.0, nan, nan, 0.0, 1.0, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:07:00.657396: step 906, loss 3.84358, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.25, 0.5, nan, 0.0, nan, 0.0], recall [0.0, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, nan, 0.0, 0.0]
2019-02-19T18:07:00.814854: step 907, loss 1.40055, accuracy 0.6875, precision [0.5, 0.5, 0.0, 1.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:07:00.976314: step 908, loss 1.59911, accuracy 0.375, precision [nan, 1.0, 0.0, 0.3333333333333333, 0.4, nan, nan, nan, nan], recall [0.0, 0.3333333333333333, 0.0, 0.75, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:07:01.131862: step 909, loss 2.46698, accuracy 0.4375, precision [nan, 0.25, 1.0, 0.625, 0.0, nan, 0.0, nan, 0.0], recall [nan, 0.5, 0.5, 0.5555555555555556, nan, nan, 0.0, 0.0, nan]
2019-02-19T18:07:01.292371: step 910, loss 2.7379, accuracy 0.5625, precision [1.0, nan, 0.5, 0.8333333333333334, 0.5, 0.0, 0.0, 0.5, nan], recall [0.3333333333333333, 0.0, 1.0, 0.8333333333333334, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:07:01.448682: step 911, loss 1.60544, accuracy 0.5, precision [1.0, 0.3333333333333333, nan, 0.75, 1.0, 0.0, 0.0, 0.25, nan], recall [0.5, 0.3333333333333333, 0.0, 0.6, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:07:01.608472: step 912, loss 1.5313, accuracy 0.4375, precision [0.6666666666666666, 0.3333333333333333, nan, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.6666666666666666, 0.5, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:01.759650: step 913, loss 1.2078, accuracy 0.75, precision [0.0, 0.6666666666666666, 1.0, 0.75, 0.75, nan, nan, 1.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.6, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:01.914580: step 914, loss 2.15771, accuracy 0.5625, precision [0.0, nan, 0.0, 0.75, 1.0, 0.0, nan, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:02.063658: step 915, loss 2.4341, accuracy 0.375, precision [nan, 0.25, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0], recall [0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:07:02.215360: step 916, loss 2.99973, accuracy 0.5625, precision [0.0, 0.5, 0.6666666666666666, 0.8, 0.5, nan, 1.0, 0.0, nan], recall [0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:07:02.371446: step 917, loss 2.58659, accuracy 0.375, precision [0.0, nan, 0.3333333333333333, 0.5, 0.5, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, 0.5, 0.4, 1.0, nan, 0.0, 0.5, 0.0]
2019-02-19T18:07:02.520675: step 918, loss 3.84852, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.5, 0.0, 0.0, nan, nan], recall [0.3333333333333333, 1.0, 0.5, 0.5, 0.5, nan, nan, nan, nan]
2019-02-19T18:07:02.681344: step 919, loss 1.9552, accuracy 0.4375, precision [1.0, 0.0, 0.3333333333333333, 0.2, 1.0, nan, nan, nan, nan], recall [1.0, nan, 1.0, 0.16666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:02.839099: step 920, loss 1.36238, accuracy 0.5, precision [0.5, 0.0, 0.0, 0.25, 1.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, 0.0, 0.0, 0.5, 0.6, nan, 0.0, 1.0, nan]
2019-02-19T18:07:02.989608: step 921, loss 2.20367, accuracy 0.5, precision [0.0, 0.5, nan, 0.42857142857142855, 1.0, nan, 1.0, 0.5, 0.0], recall [0.0, 1.0, 0.0, 0.75, 0.4, nan, 1.0, 1.0, nan]
2019-02-19T18:07:03.139836: step 922, loss 2.34183, accuracy 0.375, precision [0.0, 0.8, 0.0, 0.3333333333333333, 0.5, 0.0, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, nan, 0.16666666666666666, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:07:03.293658: step 923, loss 1.92503, accuracy 0.5, precision [1.0, 0.5, 0.5, 0.0, 1.0, nan, nan, nan, nan], recall [0.5, 0.3333333333333333, 0.5, 0.0, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:07:03.451375: step 924, loss 2.18031, accuracy 0.5, precision [0.6666666666666666, 0.5, 1.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.25, 0.3333333333333333, 0.6, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:03.605377: step 925, loss 2.1424, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.36363636363636365, 1.0, nan, nan, nan, nan], recall [1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, nan, 0.0]
2019-02-19T18:07:03.762387: step 926, loss 2.45423, accuracy 0.4375, precision [0.2, 0.75, 1.0, 0.0, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:07:03.913480: step 927, loss 2.73109, accuracy 0.3125, precision [0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.5, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.2, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:07:04.063207: step 928, loss 1.44392, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.4, 1.0, 1.0, nan, nan, 0.0], recall [1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, nan, nan]
2019-02-19T18:07:04.219236: step 929, loss 1.14206, accuracy 0.625, precision [0.5, 0.5, nan, 0.5, 0.8333333333333334, nan, nan, 1.0, 0.0], recall [1.0, 1.0, nan, 0.6666666666666666, 0.8333333333333334, 0.0, 0.0, 0.5, nan]
2019-02-19T18:07:04.371819: step 930, loss 2.36756, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.0, 0.6666666666666666, 0.75, nan, nan, 0.3333333333333333, nan], recall [0.0, 0.5, nan, 0.3333333333333333, 0.75, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:04.529172: step 931, loss 1.64716, accuracy 0.5, precision [0.0, 1.0, nan, 0.42857142857142855, 0.75, nan, nan, 0.3333333333333333, nan], recall [0.0, 0.3333333333333333, nan, 0.6, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:04.684463: step 932, loss 1.56803, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.6, 0.5, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.0, 0.42857142857142855, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T18:07:04.839264: step 933, loss 1.24397, accuracy 0.625, precision [0.0, nan, nan, 0.7142857142857143, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, nan], recall [nan, 0.0, nan, 0.8333333333333334, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:07:04.993240: step 934, loss 2.49519, accuracy 0.4375, precision [0.5, 1.0, nan, 0.4, nan, 0.0, 1.0, 0.25, nan], recall [0.6666666666666666, 0.3333333333333333, nan, 0.3333333333333333, nan, 0.0, 1.0, 0.5, nan]
2019-02-19T18:07:05.145975: step 935, loss 1.41856, accuracy 0.625, precision [0.0, 0.0, nan, 0.7142857142857143, 0.8, nan, nan, 1.0, nan], recall [0.0, nan, nan, 0.625, 0.8, nan, nan, 0.5, nan]
2019-02-19T18:07:05.304739: step 936, loss 1.40335, accuracy 0.6875, precision [0.0, 0.0, nan, 1.0, 1.0, 0.0, nan, 0.75, 0.0], recall [0.0, nan, nan, 0.75, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:07:05.463321: step 937, loss 0.973931, accuracy 0.625, precision [nan, 0.0, nan, 0.5, 1.0, nan, 1.0, 0.75, nan], recall [0.0, 0.0, nan, 0.6, 0.75, nan, 1.0, 1.0, nan]
2019-02-19T18:07:05.618015: step 938, loss 0.851424, accuracy 0.8125, precision [1.0, 1.0, 0.5, 1.0, 0.75, nan, 1.0, 0.6666666666666666, nan], recall [1.0, 0.5, 1.0, 0.8, 1.0, nan, 1.0, 1.0, 0.0]
2019-02-19T18:07:05.773204: step 939, loss 1.88061, accuracy 0.375, precision [0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, nan], recall [nan, 0.5, 1.0, 0.25, nan, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:05.931132: step 940, loss 2.2525, accuracy 0.5, precision [1.0, 0.0, 0.5, 0.6, 0.6666666666666666, nan, nan, 1.0, nan], recall [0.3333333333333333, nan, 0.5, 0.6, 0.6666666666666666, nan, nan, 0.5, 0.0]
2019-02-19T18:07:06.089580: step 941, loss 1.8414, accuracy 0.5, precision [0.5, 0.3333333333333333, 0.3333333333333333, 0.7142857142857143, 0.0, nan, nan, nan, nan], recall [0.5, 0.5, 1.0, 0.625, nan, nan, 0.0, 0.0, nan]
2019-02-19T18:07:06.240283: step 942, loss 2.47426, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, nan, 0.6, 0.0], recall [0.0, 1.0, nan, 0.0, 0.6666666666666666, nan, nan, 0.6, nan]
2019-02-19T18:07:06.395106: step 943, loss 1.40243, accuracy 0.5625, precision [nan, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, nan, nan, 0.0, nan], recall [0.0, nan, 1.0, 0.8571428571428571, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:07:06.553942: step 944, loss 3.18431, accuracy 0.375, precision [0.75, 0.0, 0.0, 0.6666666666666666, 0.25, nan, nan, 0.0, nan], recall [1.0, nan, 0.0, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:06.713426: step 945, loss 1.52289, accuracy 0.625, precision [0.6666666666666666, 0.5, 0.0, 1.0, 0.5, 0.0, nan, 0.5, nan], recall [0.6666666666666666, 1.0, nan, 0.5555555555555556, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:06.868319: step 946, loss 1.7765, accuracy 0.5625, precision [1.0, nan, 0.42857142857142855, 0.4, 1.0, nan, nan, nan, nan], recall [0.5, nan, 1.0, 0.4, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:07:07.020112: step 947, loss 2.64587, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.0, 1.0, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.4, nan]
2019-02-19T18:07:07.180478: step 948, loss 1.37906, accuracy 0.625, precision [nan, 1.0, 0.0, 0.8333333333333334, 0.5, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, nan, 0.8333333333333334, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:07:07.337422: step 949, loss 2.46044, accuracy 0.375, precision [0.5, 0.0, 1.0, 0.42857142857142855, nan, nan, 0.0, 0.0, nan], recall [0.25, 0.0, 1.0, 0.75, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:07.493747: step 950, loss 1.8076, accuracy 0.5625, precision [1.0, 0.5, nan, 0.5714285714285714, 0.5, 0.0, nan, nan, nan], recall [1.0, 1.0, nan, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:07:07.647390: step 951, loss 1.59281, accuracy 0.4375, precision [nan, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.25, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:07.797698: step 952, loss 1.90303, accuracy 0.5625, precision [0.0, 0.3333333333333333, nan, 0.8, 1.0, 0.0, 0.0, 0.5, nan], recall [0.0, 1.0, nan, 0.5, 1.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:07:07.955416: step 953, loss 1.36447, accuracy 0.5, precision [nan, 0.6666666666666666, 1.0, 0.375, 1.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.6666666666666666, 0.6, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:07:08.109653: step 954, loss 3.11335, accuracy 0.3125, precision [0.0, 1.0, 0.5, 0.3333333333333333, 0.0, nan, nan, 0.5, 0.0], recall [0.0, 0.16666666666666666, 0.3333333333333333, 1.0, 0.0, nan, nan, 1.0, nan]
2019-02-19T18:07:08.266446: step 955, loss 2.30804, accuracy 0.5, precision [0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 1.0, nan, 0.5, nan], recall [1.0, 1.0, nan, 0.2857142857142857, 1.0, 1.0, nan, 0.25, nan]
2019-02-19T18:07:08.432091: step 956, loss 1.43903, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.75, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.0, 1.0, 0.42857142857142855, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:07:08.586507: step 957, loss 2.9207, accuracy 0.4375, precision [nan, 0.6666666666666666, 0.0, 0.4, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [nan, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T18:07:08.744782: step 958, loss 1.48319, accuracy 0.4375, precision [1.0, 0.25, 0.0, 0.6, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.25, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:08.896998: step 959, loss 1.46722, accuracy 0.5625, precision [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, nan, 1.0, 0.5, 0.0], recall [0.6666666666666666, 0.5, nan, 0.5, 0.6666666666666666, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:07:09.052941: step 960, loss 2.34266, accuracy 0.5, precision [0.0, 0.5, nan, 1.0, 0.5, 0.0, 1.0, 0.25, nan], recall [nan, 0.5, 0.0, 0.8, 1.0, nan, 0.5, 0.5, nan]
2019-02-19T18:07:09.207081: step 961, loss 1.46903, accuracy 0.5, precision [nan, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 0.2, 0.75, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:07:09.365495: step 962, loss 1.88453, accuracy 0.5625, precision [1.0, 0.0, 0.75, 0.5, 1.0, 0.0, 0.0, 0.5, nan], recall [0.5, 0.0, 1.0, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:09.516024: step 963, loss 0.706105, accuracy 0.75, precision [0.5, nan, 1.0, 0.6666666666666666, 1.0, nan, 0.0, nan, nan], recall [0.5, 0.0, 0.6666666666666666, 0.8, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:09.668712: step 964, loss 1.40936, accuracy 0.5625, precision [1.0, 1.0, 0.4, 0.6666666666666666, 0.5, nan, nan, 0.0, 0.0], recall [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.25, 0.0, nan, nan, nan]
2019-02-19T18:07:09.825282: step 965, loss 0.868182, accuracy 0.5625, precision [nan, 0.25, 1.0, 0.2, 1.0, 1.0, nan, 1.0, nan], recall [0.0, 0.5, 0.5, 0.3333333333333333, 0.75, 1.0, nan, 1.0, nan]
2019-02-19T18:07:09.980467: step 966, loss 3.38995, accuracy 0.3125, precision [1.0, 0.25, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 0.3333333333333333, nan], recall [1.0, 0.25, 0.0, 0.25, 0.5, nan, 0.0, 1.0, 0.0]
2019-02-19T18:07:10.131100: step 967, loss 2.99414, accuracy 0.375, precision [1.0, 0.2, 0.5, 0.5, 0.0, 1.0, nan, 0.0, 0.0], recall [0.5, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, nan, 0.0, nan]
2019-02-19T18:07:10.283316: step 968, loss 2.37377, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan], recall [0.5, nan, 0.0, 0.42857142857142855, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:07:10.436812: step 969, loss 2.21182, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.4, 0.5, 0.0, nan, 0.5, nan], recall [0.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, nan, 0.0, 1.0, nan]
2019-02-19T18:07:10.594481: step 970, loss 2.26437, accuracy 0.4375, precision [nan, 0.25, 1.0, 0.8, 0.5, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.25, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:10.756682: step 971, loss 2.52055, accuracy 0.5, precision [1.0, 0.5, nan, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0], recall [1.0, 0.3333333333333333, 0.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:07:10.905583: step 972, loss 2.2207, accuracy 0.4375, precision [0.25, 0.3333333333333333, nan, 0.75, 1.0, 0.0, 0.0, 0.5, nan], recall [1.0, 0.5, nan, 0.75, 1.0, 0.0, 0.0, 0.2, nan]
2019-02-19T18:07:11.061043: step 973, loss 2.22151, accuracy 0.4375, precision [nan, 1.0, 0.5, 0.5, 0.6, 0.0, nan, 0.0, 0.0], recall [0.0, 0.3333333333333333, 0.5, 0.5, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:07:11.215598: step 974, loss 0.96864, accuracy 0.5, precision [nan, 1.0, 0.5, 0.2, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.6, 1.0, 0.25, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:11.369277: step 975, loss 2.43936, accuracy 0.375, precision [0.5, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, nan, 0.0, nan], recall [0.5, 0.6666666666666666, nan, 0.5, nan, 1.0, nan, 0.0, 0.0]
2019-02-19T18:07:11.529377: step 976, loss 1.09057, accuracy 0.5625, precision [nan, 1.0, 0.5, 0.42857142857142855, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.6666666666666666, 0.6666666666666666, 0.6, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:07:11.682000: step 977, loss 2.1365, accuracy 0.5, precision [0.0, 0.0, nan, 0.0, 1.0, 0.0, 1.0, 0.75, nan], recall [0.0, 0.0, 0.0, nan, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:07:11.834284: step 978, loss 2.35034, accuracy 0.375, precision [0.0, 0.75, 1.0, 0.6666666666666666, 0.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.6, 1.0, 0.2857142857142857, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:07:11.988514: step 979, loss 3.15503, accuracy 0.625, precision [nan, 1.0, 0.0, 1.0, 1.0, nan, 0.25, 0.0, 0.0], recall [nan, 0.6666666666666666, 0.0, 0.6, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:07:12.141647: step 980, loss 3.05446, accuracy 0.25, precision [0.5, 0.0, nan, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, nan, 0.6, nan, 0.0, nan, 0.0, 0.0]
2019-02-19T18:07:12.300141: step 981, loss 2.07453, accuracy 0.3125, precision [nan, 1.0, 0.0, 0.25, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [nan, 0.25, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:12.455700: step 982, loss 1.03181, accuracy 0.75, precision [nan, 0.6666666666666666, nan, 0.625, 1.0, nan, 1.0, nan, nan], recall [nan, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:07:12.608300: step 983, loss 1.50417, accuracy 0.5625, precision [0.3333333333333333, 1.0, nan, 0.25, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.75, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:12.761902: step 984, loss 1.76149, accuracy 0.375, precision [0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.5, nan, nan, 0.0, 0.0], recall [1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:07:12.917072: step 985, loss 2.09935, accuracy 0.5, precision [0.5, 0.0, 0.6, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.5, nan, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:07:13.071111: step 986, loss 1.7655, accuracy 0.5625, precision [1.0, 1.0, nan, 0.5, 0.75, 0.0, nan, 0.25, nan], recall [1.0, 1.0, nan, 0.4, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:07:13.227747: step 987, loss 1.12737, accuracy 0.75, precision [0.6666666666666666, 0.5, nan, 1.0, 1.0, 0.5, nan, 0.0, nan], recall [1.0, 1.0, nan, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, nan]
2019-02-19T18:07:13.385924: step 988, loss 1.93701, accuracy 0.5, precision [0.5, 0.5, nan, 0.6, 0.5, 0.5, nan, 0.0, nan], recall [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T18:07:13.541921: step 989, loss 2.24456, accuracy 0.5625, precision [0.0, 0.5, nan, 1.0, 0.6666666666666666, nan, 0.0, 0.5, 0.0], recall [nan, 1.0, nan, 0.4, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:07:13.699381: step 990, loss 0.87382, accuracy 0.6875, precision [0.0, 0.5, nan, 0.8, 0.8333333333333334, nan, nan, nan, nan], recall [nan, 0.5, nan, 0.8, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:13.855512: step 991, loss 2.23236, accuracy 0.625, precision [1.0, 0.5, 0.25, 0.8333333333333334, nan, nan, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.7142857142857143, 0.0, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T18:07:14.015150: step 992, loss 2.43922, accuracy 0.5, precision [1.0, 0.4, nan, 0.6666666666666666, nan, nan, 0.0, 0.0, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:07:14.168919: step 993, loss 2.10215, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:07:14.317612: step 994, loss 1.12425, accuracy 0.625, precision [0.0, 1.0, nan, 0.6666666666666666, 0.8, 0.0, nan, 1.0, nan], recall [nan, 0.5, nan, 0.5714285714285714, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:07:14.466418: step 995, loss 1.23461, accuracy 0.6875, precision [1.0, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.0, 0.6666666666666666, nan]
2019-02-19T18:07:14.618270: step 996, loss 2.08809, accuracy 0.4375, precision [1.0, 0.25, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.3333333333333333, 0.5, nan, 0.4, 0.5, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:14.773752: step 997, loss 1.63781, accuracy 0.5, precision [0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, 0.0], recall [0.0, 0.5, nan, 0.5, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T18:07:14.928705: step 998, loss 2.06421, accuracy 0.5, precision [0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 0.75, 0.0, 0.0, 0.0, nan], recall [0.5, 0.3333333333333333, 0.5, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:15.085495: step 999, loss 1.51139, accuracy 0.625, precision [nan, 0.0, 0.5, 0.625, 1.0, nan, nan, 1.0, nan], recall [0.0, 0.0, 0.5, 0.8333333333333334, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:15.246381: step 1000, loss 0.746809, accuracy 0.75, precision [1.0, 1.0, 0.0, 0.75, 1.0, nan, nan, 0.0, nan], recall [0.6666666666666666, 0.5, nan, 0.8571428571428571, 1.0, 0.0, nan, nan, nan]

Evaluation:
[[ 45  11   0  18   2   1   0   5   0]
 [ 12  82   0  54   4   0   0   4   0]
 [  3   6  38  42   4   0   0   1   0]
 [  3  36   8 231   6   4   1  10   1]
 [  1   4   3  13 148   0   2   1   1]
 [  4   6   0  37   0  10   1   2   0]
 [  1   2   0  14   5   2   6   0   0]
 [  5  13   0  41   2   0   0  43   1]
 [  1   2   0  17   2   1   0   0   2]]
2019-02-19T18:07:17.678027: step 1000, loss 1.31067, accuracy 0.590244, precision [0.5487804878048781, 0.5256410256410257, 0.40425531914893614, 0.77, 0.8554913294797688, 0.16666666666666666, 0.2, 0.4095238095238095, 0.08], recall [0.6, 0.5061728395061729, 0.7755102040816326, 0.49464668094218417, 0.8554913294797688, 0.5555555555555556, 0.6, 0.6515151515151515, 0.4]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-1000

2019-02-19T18:07:17.977532: step 1001, loss 0.943743, accuracy 0.5625, precision [nan, 0.75, 0.3333333333333333, 0.5, 1.0, nan, nan, nan, 0.0], recall [0.0, 0.6, 1.0, 0.6, 0.6666666666666666, nan, 0.0, nan, nan]
2019-02-19T18:07:18.130629: step 1002, loss 2.47712, accuracy 0.3125, precision [0.0, nan, 1.0, 0.14285714285714285, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.16666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:18.285824: step 1003, loss 1.40043, accuracy 0.6875, precision [0.5, 0.5, nan, 0.8571428571428571, 1.0, 0.5, nan, 0.0, nan], recall [1.0, 0.3333333333333333, nan, 0.8571428571428571, 0.5, 1.0, nan, nan, nan]
2019-02-19T18:07:18.436118: step 1004, loss 1.23852, accuracy 0.6875, precision [nan, 0.6666666666666666, 1.0, 1.0, 1.0, nan, nan, 0.25, 0.0], recall [0.0, 1.0, 1.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:18.585569: step 1005, loss 1.68424, accuracy 0.625, precision [1.0, nan, 0.6666666666666666, 0.8333333333333334, nan, 0.5, 1.0, 0.0, nan], recall [0.5, 0.0, 1.0, 0.7142857142857143, nan, 0.5, 1.0, nan, nan]
2019-02-19T18:07:18.735899: step 1006, loss 2.19054, accuracy 0.5, precision [nan, 0.75, 1.0, 0.5, 0.5, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 1.0, 0.5, 0.25, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:07:18.888871: step 1007, loss 3.10764, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, nan, 0.0, 0.0], recall [nan, 0.25, nan, 0.16666666666666666, 0.5, 1.0, nan, 0.0, nan]
2019-02-19T18:07:19.045515: step 1008, loss 1.46045, accuracy 0.5, precision [1.0, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.5, 0.25, nan, 0.4, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:07:19.201287: step 1009, loss 1.35594, accuracy 0.75, precision [1.0, nan, 1.0, 0.75, 0.5, 0.0, nan, 1.0, nan], recall [1.0, nan, 0.3333333333333333, 0.75, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:19.352025: step 1010, loss 1.58399, accuracy 0.625, precision [0.5, 0.5, 0.5, 0.8333333333333334, 1.0, 0.0, 0.0, nan, nan], recall [1.0, 0.25, 1.0, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:19.503463: step 1011, loss 1.47596, accuracy 0.625, precision [0.0, 1.0, 0.0, 0.6666666666666666, 1.0, nan, 1.0, 0.25, nan], recall [nan, 1.0, 0.0, 0.4, 0.5, nan, 1.0, 0.5, nan]
2019-02-19T18:07:19.657356: step 1012, loss 1.01585, accuracy 0.625, precision [1.0, 0.5, nan, 0.5714285714285714, 0.5, nan, 1.0, 1.0, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:07:19.807241: step 1013, loss 1.63399, accuracy 0.6875, precision [1.0, nan, 1.0, 0.5714285714285714, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 0.0, 0.6666666666666666, 1.0, 0.5, nan, nan, 0.75, nan]
2019-02-19T18:07:19.962331: step 1014, loss 1.33034, accuracy 0.6875, precision [0.3333333333333333, 1.0, nan, 0.7142857142857143, 1.0, nan, 1.0, 1.0, 0.0], recall [1.0, 1.0, nan, 0.8333333333333334, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0]
2019-02-19T18:07:20.116937: step 1015, loss 2.66929, accuracy 0.375, precision [0.0, 0.5, 1.0, 0.16666666666666666, 0.3333333333333333, nan, 0.0, 1.0, nan], recall [nan, 0.3333333333333333, 1.0, 0.25, 1.0, nan, nan, 0.25, 0.0]
2019-02-19T18:07:20.270147: step 1016, loss 1.91344, accuracy 0.3125, precision [0.0, 0.0, nan, 0.6, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, nan, 0.5, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:07:20.424653: step 1017, loss 1.45629, accuracy 0.625, precision [nan, 0.3333333333333333, nan, 0.6, 0.8333333333333334, nan, nan, 1.0, 0.0], recall [nan, 1.0, nan, 0.6, 0.8333333333333334, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:07:20.574983: step 1018, loss 2.60268, accuracy 0.375, precision [0.5, 0.0, 0.5, 0.42857142857142855, 0.5, nan, 0.0, nan, nan], recall [0.3333333333333333, 0.0, 0.3333333333333333, 0.75, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:07:20.727707: step 1019, loss 1.95354, accuracy 0.4375, precision [1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.0], recall [0.3333333333333333, 0.5, 0.5, 0.5, nan, 0.0, nan, 0.6666666666666666, 0.0]
2019-02-19T18:07:20.881796: step 1020, loss 1.86459, accuracy 0.4375, precision [0.5, 1.0, 0.5, 0.2, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.2, 0.5, 1.0, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T18:07:21.039526: step 1021, loss 1.27272, accuracy 0.625, precision [0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], recall [0.5, 1.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:07:21.191774: step 1022, loss 1.42792, accuracy 0.6875, precision [1.0, nan, 0.0, 0.6666666666666666, 1.0, 1.0, nan, 0.25, nan], recall [1.0, 0.0, nan, 0.5, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:07:21.343602: step 1023, loss 0.721016, accuracy 0.8125, precision [0.0, 0.0, 0.5, 1.0, 1.0, 1.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:07:21.501475: step 1024, loss 1.43015, accuracy 0.625, precision [1.0, 0.4, 0.0, 1.0, nan, 1.0, 1.0, 1.0, 0.0], recall [0.5, 1.0, nan, 0.4444444444444444, nan, 1.0, 1.0, 1.0, nan]
2019-02-19T18:07:21.658583: step 1025, loss 2.97242, accuracy 0.5, precision [nan, 0.3333333333333333, 0.5, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.6666666666666666, 0.0], recall [nan, 1.0, 0.25, 0.4, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:07:21.814488: step 1026, loss 2.65786, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, nan, nan], recall [0.6666666666666666, 0.0, 0.0, 0.4, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:07:21.971755: step 1027, loss 1.60337, accuracy 0.5, precision [0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.6666666666666666, nan, 1.0, 0.3333333333333333, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:07:22.129535: step 1028, loss 2.23645, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.5, 0.25, 0.75, nan, nan, 0.0, 0.0], recall [1.0, 0.5, 0.25, 0.25, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:07:22.281847: step 1029, loss 1.86241, accuracy 0.4375, precision [nan, 0.25, nan, 0.75, 0.5, nan, nan, 0.4, 0.0], recall [0.0, 1.0, 0.0, 0.42857142857142855, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:07:22.436459: step 1030, loss 1.79769, accuracy 0.5625, precision [1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, nan, 0.5, 0.4, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:22.592798: step 1031, loss 1.47898, accuracy 0.5625, precision [nan, 0.5, 0.3333333333333333, 0.75, 0.5, 1.0, 1.0, 0.3333333333333333, nan], recall [nan, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, nan]
2019-02-19T18:07:22.750778: step 1032, loss 1.03954, accuracy 0.625, precision [nan, 1.0, 0.5, 0.5714285714285714, 0.6666666666666666, nan, 0.5, 1.0, nan], recall [nan, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, nan]
2019-02-19T18:07:22.902412: step 1033, loss 1.91388, accuracy 0.625, precision [0.0, 1.0, 0.7142857142857143, 0.5, 0.5, nan, 1.0, 0.5, nan], recall [0.0, 0.5, 1.0, 0.5, 1.0, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T18:07:23.057645: step 1034, loss 1.04095, accuracy 0.6875, precision [1.0, 0.75, 1.0, 0.3333333333333333, 1.0, nan, nan, nan, nan], recall [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T18:07:23.212733: step 1035, loss 1.91362, accuracy 0.5, precision [nan, 0.25, 0.5, 0.6, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [nan, 0.5, 0.25, 0.75, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:07:23.368257: step 1036, loss 1.19657, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.0, 0.0, 0.4, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:23.521594: step 1037, loss 3.18151, accuracy 0.4375, precision [0.25, 0.6666666666666666, 0.3333333333333333, 0.25, 1.0, nan, 1.0, nan, nan], recall [1.0, 0.6666666666666666, 0.3333333333333333, 0.2, 0.5, 0.0, 1.0, nan, nan]
2019-02-19T18:07:23.676401: step 1038, loss 2.88, accuracy 0.375, precision [0.5, 0.0, 0.5, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 0.25, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:23.833194: step 1039, loss 0.620693, accuracy 0.8125, precision [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:07:23.987070: step 1040, loss 0.978787, accuracy 0.625, precision [0.5, 0.5, nan, 0.5, 1.0, nan, nan, 0.0, nan], recall [1.0, 1.0, 0.0, 0.6, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:07:24.139050: step 1041, loss 2.40445, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, nan], recall [nan, 1.0, 0.5, 1.0, 0.0, nan, nan, 0.25, 0.0]
2019-02-19T18:07:24.294820: step 1042, loss 1.62536, accuracy 0.4375, precision [0.3333333333333333, 1.0, 0.25, 0.3333333333333333, 1.0, nan, nan, nan, nan], recall [0.5, 0.5, 0.5, 0.4, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:07:24.449489: step 1043, loss 1.75969, accuracy 0.5, precision [1.0, nan, nan, 0.42857142857142855, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [1.0, 0.0, 0.0, 0.5, 0.75, nan, nan, 0.5, 0.0]
2019-02-19T18:07:24.607199: step 1044, loss 1.71352, accuracy 0.5625, precision [1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 0.0, 0.25, nan], recall [1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, nan, 0.3333333333333333, 0.0]
2019-02-19T18:07:24.759165: step 1045, loss 2.24757, accuracy 0.5, precision [0.6666666666666666, 0.5, 0.5, 0.5, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.5, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:24.916424: step 1046, loss 1.35602, accuracy 0.5, precision [0.0, 1.0, 0.6666666666666666, 0.25, 0.5, nan, nan, nan, 0.0], recall [nan, 1.0, 0.4, 0.5, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T18:07:25.069649: step 1047, loss 2.3675, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.4, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:07:25.226300: step 1048, loss 1.52384, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.8, 1.0, 0.0, nan, nan, 0.0], recall [1.0, 1.0, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:25.381255: step 1049, loss 1.3595, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.7142857142857143, nan, nan, nan, 0.0, nan], recall [nan, 1.0, 0.0, 0.5555555555555556, 0.0, 0.0, 0.0, nan, nan]
2019-02-19T18:07:25.538844: step 1050, loss 1.00676, accuracy 0.625, precision [nan, 0.6666666666666666, nan, 1.0, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 1.0, nan, 0.625, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:25.696595: step 1051, loss 1.66622, accuracy 0.5625, precision [0.0, 0.6666666666666666, 0.0, 0.8, 0.6666666666666666, nan, nan, 0.3333333333333333, nan], recall [nan, 0.5, nan, 0.4444444444444444, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:25.853461: step 1052, loss 0.964868, accuracy 0.625, precision [1.0, 0.3333333333333333, 0.0, 0.7142857142857143, 1.0, 1.0, nan, nan, nan], recall [0.6666666666666666, 0.3333333333333333, nan, 0.625, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:07:26.008481: step 1053, loss 3.0078, accuracy 0.4375, precision [0.0, 0.4, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, nan, 0.2857142857142857, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:07:26.167510: step 1054, loss 1.0494, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.8333333333333334, 0.75, nan, nan, 0.0, nan], recall [0.5, nan, 1.0, 0.5555555555555556, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:07:26.323266: step 1055, loss 2.73624, accuracy 0.5625, precision [0.25, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.5, 0.5714285714285714, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T18:07:26.480330: step 1056, loss 0.752669, accuracy 0.6875, precision [1.0, 0.0, nan, 0.6, 1.0, 0.0, 1.0, 0.0, nan], recall [0.5, nan, nan, 0.75, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:07:26.631962: step 1057, loss 2.52596, accuracy 0.4375, precision [0.5, nan, 0.3333333333333333, 0.4, 0.6, 0.0, nan, nan, nan], recall [1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:26.784649: step 1058, loss 2.46818, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.75, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 1.0, nan, 0.42857142857142855, 0.0, 0.0, nan, nan, 0.0]
2019-02-19T18:07:26.941717: step 1059, loss 1.554, accuracy 0.5, precision [1.0, 0.25, nan, 0.3333333333333333, 1.0, nan, 1.0, 0.5, nan], recall [0.2, 0.5, nan, 0.6666666666666666, 0.6666666666666666, nan, 0.5, 1.0, nan]
2019-02-19T18:07:27.091831: step 1060, loss 1.937, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.5, 0.5, nan, 0.0, nan, nan], recall [0.5, 0.0, 0.0, 0.6, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:07:27.246076: step 1061, loss 1.42738, accuracy 0.5625, precision [1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.5, 0.5, nan, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:27.394649: step 1062, loss 1.01302, accuracy 0.625, precision [0.6666666666666666, 0.25, 0.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.5, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:07:27.552322: step 1063, loss 1.88075, accuracy 0.5, precision [0.25, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 1.0, 0.375, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:07:27.701711: step 1064, loss 1.34757, accuracy 0.5, precision [nan, 0.75, nan, 0.4, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.6, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.5, 0.0]
2019-02-19T18:07:27.854092: step 1065, loss 0.689988, accuracy 0.75, precision [nan, 0.75, 0.5, 0.75, 0.8, nan, nan, 1.0, nan], recall [0.0, 1.0, 0.5, 0.75, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:28.004488: step 1066, loss 2.03515, accuracy 0.5, precision [0.0, 0.25, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [nan, 0.5, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:07:28.157678: step 1067, loss 1.6525, accuracy 0.5, precision [0.25, 0.6, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.6, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:07:28.316356: step 1068, loss 0.664343, accuracy 0.75, precision [1.0, nan, 1.0, 0.5, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:28.474232: step 1069, loss 0.992049, accuracy 0.6875, precision [nan, 0.6666666666666666, nan, 0.8571428571428571, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.4, nan, 1.0, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:28.627472: step 1070, loss 1.95313, accuracy 0.5625, precision [0.0, 1.0, 0.3333333333333333, 0.4, 1.0, nan, nan, 1.0, nan], recall [0.0, 0.25, 1.0, 1.0, 0.6, 0.0, nan, 1.0, nan]
2019-02-19T18:07:28.785681: step 1071, loss 2.64623, accuracy 0.375, precision [0.6, nan, 1.0, 0.0, 1.0, nan, 0.0, 0.5, nan], recall [0.6, 0.0, 1.0, 0.0, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:28.941035: step 1072, loss 1.20274, accuracy 0.75, precision [1.0, 1.0, 0.3333333333333333, 1.0, 1.0, nan, nan, 0.0, nan], recall [0.25, 1.0, 1.0, 1.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:29.099318: step 1073, loss 1.48924, accuracy 0.5625, precision [0.0, nan, 0.3333333333333333, 0.5, 1.0, nan, nan, 1.0, nan], recall [0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:07:29.256396: step 1074, loss 3.30256, accuracy 0.25, precision [0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0], recall [1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:07:29.412047: step 1075, loss 2.37826, accuracy 0.4375, precision [nan, 0.6, nan, 0.75, 1.0, 0.0, nan, 0.0, 0.0], recall [0.0, 1.0, nan, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:29.570517: step 1076, loss 1.50468, accuracy 0.6875, precision [nan, 1.0, 0.0, 0.6666666666666666, 0.6, nan, nan, 1.0, nan], recall [nan, 0.3333333333333333, nan, 0.8, 1.0, nan, nan, 0.6, nan]
2019-02-19T18:07:29.727606: step 1077, loss 1.53867, accuracy 0.5625, precision [0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 0.4, 0.0, 0.3333333333333333, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:07:29.880327: step 1078, loss 2.3015, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.42857142857142855, 1.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.0, 0.6, 0.3333333333333333, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:07:30.039088: step 1079, loss 1.46744, accuracy 0.625, precision [1.0, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, nan, nan, nan, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:07:30.190206: step 1080, loss 2.72635, accuracy 0.4375, precision [0.5, 0.5, 0.3333333333333333, 0.5, 0.5, nan, nan, nan, 0.0], recall [1.0, 1.0, 0.3333333333333333, 0.6, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T18:07:30.345011: step 1081, loss 2.52876, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.5555555555555556, nan, 0.0, nan, 0.0, 0.0], recall [1.0, 0.0, 0.3333333333333333, 0.7142857142857143, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:07:30.497389: step 1082, loss 1.74468, accuracy 0.5, precision [nan, 0.0, nan, 0.625, 0.5, 1.0, 0.0, 1.0, nan], recall [0.0, nan, 0.0, 0.625, 0.5, 1.0, nan, 0.5, nan]
2019-02-19T18:07:30.648987: step 1083, loss 2.02587, accuracy 0.625, precision [nan, 0.5, 0.6, 1.0, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 1.0, 1.0, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:07:30.806099: step 1084, loss 1.09187, accuracy 0.625, precision [0.5, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, nan, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:07:30.958651: step 1085, loss 2.61619, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.0, 0.8, nan, nan, 0.5, 0.6666666666666666, nan], recall [0.5, 1.0, nan, 0.5714285714285714, 0.0, 0.0, 0.5, 1.0, nan]
2019-02-19T18:07:31.117391: step 1086, loss 1.21848, accuracy 0.625, precision [nan, 0.5, 1.0, 0.8, 0.6, 0.0, nan, nan, nan], recall [0.0, 1.0, 1.0, 1.0, 0.75, nan, 0.0, 0.0, 0.0]
2019-02-19T18:07:31.273926: step 1087, loss 1.98851, accuracy 0.5625, precision [nan, 0.5, 0.0, 0.875, 0.5, nan, 0.0, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.6363636363636364, 0.5, nan, nan, nan, nan]
2019-02-19T18:07:31.432665: step 1088, loss 1.62808, accuracy 0.5, precision [0.0, 0.75, nan, 0.5, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.16666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:31.585621: step 1089, loss 2.22066, accuracy 0.4375, precision [0.0, 0.0, nan, 0.7142857142857143, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.0, 0.0, 0.625, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:31.742298: step 1090, loss 1.38566, accuracy 0.625, precision [0.0, 0.5, 1.0, 1.0, 1.0, nan, 1.0, 0.5, 0.0], recall [nan, 0.5, 1.0, 0.42857142857142855, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:07:31.897218: step 1091, loss 1.17244, accuracy 0.375, precision [0.0, 0.25, 1.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.2, 1.0, 0.5, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:07:32.049484: step 1092, loss 1.42347, accuracy 0.4375, precision [0.0, 0.5, nan, 0.75, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.0, 0.4, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:32.203380: step 1093, loss 2.11106, accuracy 0.5625, precision [0.5, 0.0, 1.0, 0.6666666666666666, 0.75, nan, 0.0, 0.0, nan], recall [0.5, 0.0, 1.0, 0.5714285714285714, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:32.358429: step 1094, loss 2.08961, accuracy 0.4375, precision [0.5, 0.75, 0.5, 0.0, 0.3333333333333333, nan, nan, nan, nan], recall [1.0, 0.375, 0.5, 0.0, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:07:32.515095: step 1095, loss 2.72139, accuracy 0.4375, precision [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [0.6666666666666666, 0.5, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:32.674066: step 1096, loss 1.59962, accuracy 0.625, precision [nan, 0.75, 0.5, 0.8333333333333334, 0.0, nan, nan, 0.5, nan], recall [nan, 1.0, 0.5, 0.7142857142857143, nan, nan, 0.0, 1.0, 0.0]
2019-02-19T18:07:32.827886: step 1097, loss 1.33737, accuracy 0.6875, precision [1.0, 0.75, 0.5, 1.0, 0.6666666666666666, nan, 0.0, nan, nan], recall [1.0, 0.75, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:32.982759: step 1098, loss 2.30831, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.5, 0.25, nan, nan, 1.0, 0.0], recall [0.0, 0.3333333333333333, nan, 0.5, 1.0, nan, 0.0, 0.25, nan]
2019-02-19T18:07:33.138745: step 1099, loss 1.37466, accuracy 0.4375, precision [nan, 0.5, 0.0, 0.0, 0.8333333333333334, nan, 0.0, nan, nan], recall [0.0, 0.3333333333333333, nan, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:33.290084: step 1100, loss 2.41844, accuracy 0.5625, precision [1.0, 1.0, 0.0, 0.75, 0.3333333333333333, nan, nan, 0.0, 0.0], recall [0.5, 0.3333333333333333, nan, 0.8571428571428571, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:07:33.445898: step 1101, loss 1.79697, accuracy 0.5625, precision [1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 0.5, 0.0, nan], recall [1.0, 0.0, nan, 0.625, 0.5, 1.0, 1.0, 0.0, nan]
2019-02-19T18:07:33.602749: step 1102, loss 1.17943, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.6, 1.0, nan, 1.0, nan, nan], recall [0.0, 0.0, 1.0, 0.42857142857142855, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:07:33.758393: step 1103, loss 1.88818, accuracy 0.625, precision [0.5, 0.75, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.75, nan, 0.7142857142857143, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:07:33.908819: step 1104, loss 1.49178, accuracy 0.625, precision [1.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, nan, 1.0, nan], recall [0.5, 0.25, 1.0, 0.3333333333333333, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:07:34.062782: step 1105, loss 0.792395, accuracy 0.625, precision [1.0, 1.0, nan, 0.5, 1.0, nan, 1.0, 0.3333333333333333, nan], recall [0.5, 0.5, 0.0, 0.8, 0.6666666666666666, nan, 0.5, 1.0, nan]
2019-02-19T18:07:34.216661: step 1106, loss 1.17826, accuracy 0.5625, precision [0.5, 0.5, 1.0, 0.42857142857142855, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, 0.5, 0.5, 0.6, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:07:34.371990: step 1107, loss 1.37469, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, nan, nan], recall [1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 1.0, 0.0, nan]
2019-02-19T18:07:34.524617: step 1108, loss 1.91396, accuracy 0.5625, precision [0.6666666666666666, 0.3333333333333333, nan, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 1.0, nan, 0.5, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:07:34.680406: step 1109, loss 1.33202, accuracy 0.75, precision [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, nan, 1.0, 0.0], recall [1.0, 0.0, nan, 0.7777777777777778, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:34.834940: step 1110, loss 2.40088, accuracy 0.375, precision [nan, 0.0, 0.3333333333333333, 0.5, 1.0, 0.0, 0.5, 0.0, nan], recall [0.0, 0.0, 1.0, 0.2, 0.75, nan, 1.0, 0.0, nan]
2019-02-19T18:07:34.987530: step 1111, loss 3.12483, accuracy 0.3125, precision [0.0, 0.4, 0.0, 0.75, nan, 0.0, nan, 0.0, 0.0], recall [0.0, 0.4, 0.0, 0.42857142857142855, 0.0, nan, nan, nan, nan]
2019-02-19T18:07:35.147067: step 1112, loss 2.45426, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.5, 0.5, 1.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.2, 0.75, 0.6666666666666666, 1.0, nan, 0.0, nan]
2019-02-19T18:07:35.300459: step 1113, loss 1.63786, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.5, 0.6666666666666666, nan, 0.0, nan, 0.5, 0.0], recall [1.0, 0.5, 1.0, 0.3333333333333333, 0.0, nan, nan, 1.0, nan]
2019-02-19T18:07:35.452066: step 1114, loss 2.20158, accuracy 0.5625, precision [0.5, 1.0, 1.0, 0.6, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.5, 0.5, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:07:35.603241: step 1115, loss 1.49512, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.4, 0.8333333333333334, nan, 0.0, 1.0, nan], recall [nan, 0.0, nan, 0.5, 0.8333333333333334, nan, 0.0, 0.5, 0.0]
2019-02-19T18:07:35.760405: step 1116, loss 2.30559, accuracy 0.4375, precision [0.0, nan, 0.6666666666666666, 0.5714285714285714, 0.0, 0.0, nan, 0.3333333333333333, nan], recall [nan, 0.0, 1.0, 0.5, nan, 0.0, 0.0, 0.5, nan]
2019-02-19T18:07:35.914446: step 1117, loss 1.79258, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.6, nan, 0.5, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.375, 0.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:07:36.070014: step 1118, loss 2.2676, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, nan], recall [nan, 0.5, nan, 0.42857142857142855, 0.5, nan, nan, nan, 0.0]
2019-02-19T18:07:36.224357: step 1119, loss 2.9379, accuracy 0.4375, precision [0.0, nan, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0], recall [0.0, nan, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.25, nan]
2019-02-19T18:07:36.380386: step 1120, loss 2.90609, accuracy 0.375, precision [0.0, 0.25, 0.0, 0.5, 0.0, nan, 0.3333333333333333, 1.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, nan, 0.0, 0.5, 0.6, nan]
2019-02-19T18:07:36.536387: step 1121, loss 1.55176, accuracy 0.625, precision [1.0, 0.3333333333333333, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.0, 0.6666666666666666, 0.75, 0.0, nan, 1.0, nan]
2019-02-19T18:07:36.687846: step 1122, loss 1.85538, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.0, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:07:36.840860: step 1123, loss 1.41614, accuracy 0.4375, precision [1.0, 0.0, nan, 0.5, 0.0, nan, 1.0, 0.5, nan], recall [0.3333333333333333, 0.0, 0.0, 0.6, nan, 0.0, 0.5, 1.0, nan]
2019-02-19T18:07:36.996482: step 1124, loss 1.90894, accuracy 0.5, precision [0.6666666666666666, 0.0, 1.0, 0.42857142857142855, 0.6666666666666666, 0.0, nan, nan, nan], recall [1.0, 0.0, 1.0, 0.6, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:07:37.147384: step 1125, loss 0.989109, accuracy 0.6875, precision [0.0, 0.3333333333333333, nan, 1.0, 1.0, 0.5, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 1.0, 0.8, 1.0, nan, 0.0, nan]
2019-02-19T18:07:37.302667: step 1126, loss 1.48265, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.5, 0.6666666666666666, 0.0, 0.5, 1.0, nan], recall [0.6666666666666666, nan, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.0]
2019-02-19T18:07:37.461984: step 1127, loss 2.57159, accuracy 0.4375, precision [0.3333333333333333, 0.0, 0.0, 0.6, 1.0, 0.5, nan, 0.0, nan], recall [1.0, 0.0, nan, 0.6, 0.6666666666666666, 0.5, nan, 0.0, 0.0]
2019-02-19T18:07:37.615803: step 1128, loss 1.07021, accuracy 0.5, precision [0.6666666666666666, 0.2, 1.0, 0.0, 0.75, nan, 1.0, 0.0, nan], recall [0.6666666666666666, 1.0, 1.0, 0.0, 0.75, nan, 1.0, nan, 0.0]
2019-02-19T18:07:37.769678: step 1129, loss 1.95622, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.0, 0.8333333333333334, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:07:37.921998: step 1130, loss 2.68489, accuracy 0.375, precision [1.0, 0.5, 0.0, 0.2, 0.4, nan, nan, nan, nan], recall [0.5, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:38.072849: step 1131, loss 1.82463, accuracy 0.625, precision [0.0, 0.3333333333333333, 1.0, 0.75, 1.0, 0.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.6666666666666666, 1.0, 1.0, nan, 0.0, 0.3333333333333333, 0.0]
2019-02-19T18:07:38.227241: step 1132, loss 0.901206, accuracy 0.5625, precision [nan, 1.0, 0.6666666666666666, 0.4444444444444444, 0.0, nan, nan, 1.0, nan], recall [0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:38.384321: step 1133, loss 2.31967, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.5, nan, nan, nan, 0.0, nan], recall [0.5, 0.0, nan, 0.5714285714285714, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:38.539152: step 1134, loss 1.58754, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.25, 0.75, 1.0, nan, 1.0, nan], recall [0.0, nan, 0.5, 0.2, 1.0, 0.5, nan, 1.0, nan]
2019-02-19T18:07:38.694500: step 1135, loss 1.02314, accuracy 0.75, precision [1.0, 0.5, 1.0, 1.0, 0.5, nan, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.8333333333333334, 1.0, nan, 0.0, 1.0, 0.0]
2019-02-19T18:07:38.848981: step 1136, loss 1.54278, accuracy 0.625, precision [nan, 1.0, nan, 0.3333333333333333, 0.8333333333333334, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:38.999655: step 1137, loss 1.95539, accuracy 0.5625, precision [nan, 1.0, 0.6666666666666666, 0.5714285714285714, 0.0, nan, nan, 0.6666666666666666, 0.0], recall [nan, 0.2, 0.6666666666666666, 0.8, nan, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:39.153979: step 1138, loss 2.14082, accuracy 0.4375, precision [nan, nan, 0.0, 0.5555555555555556, 0.5, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:39.313972: step 1139, loss 1.10432, accuracy 0.6875, precision [0.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, nan, 1.0, 1.0, nan], recall [nan, 0.25, nan, 0.75, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:07:39.472392: step 1140, loss 1.16872, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.5, 1.0, 1.0, nan, 0.3333333333333333, 0.0], recall [0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, nan]
2019-02-19T18:07:39.623403: step 1141, loss 2.64604, accuracy 0.5, precision [1.0, 0.0, nan, 0.8333333333333334, 0.25, 0.0, 0.0, nan, nan], recall [1.0, 0.0, nan, 0.625, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:07:39.777051: step 1142, loss 1.97995, accuracy 0.5625, precision [1.0, 0.0, 0.0, 1.0, 0.5, 0.0, nan, 0.0, nan], recall [1.0, 0.0, nan, 0.625, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:07:39.932215: step 1143, loss 1.3759, accuracy 0.75, precision [nan, 0.0, nan, 0.8888888888888888, 1.0, nan, nan, nan, 0.0], recall [nan, 0.0, nan, 0.8, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:40.085885: step 1144, loss 1.6862, accuracy 0.625, precision [1.0, 0.6666666666666666, nan, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0], recall [0.5, 1.0, 0.0, 0.5714285714285714, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:07:40.241950: step 1145, loss 2.01438, accuracy 0.625, precision [1.0, 0.0, 0.5, 1.0, 1.0, 0.0, nan, nan, nan], recall [1.0, nan, 1.0, 0.4, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:40.391937: step 1146, loss 1.92648, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, nan, nan, 0.36363636363636365, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T18:07:40.545308: step 1147, loss 1.31679, accuracy 0.625, precision [1.0, 0.5, 0.6666666666666666, 0.8, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [0.5, 0.5, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:40.703164: step 1148, loss 2.33624, accuracy 0.5625, precision [0.5, 0.8, 0.3333333333333333, 0.75, 0.0, nan, 0.0, nan, nan], recall [1.0, 0.8, 1.0, 0.42857142857142855, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:07:40.857132: step 1149, loss 1.68882, accuracy 0.5625, precision [1.0, 0.0, nan, 0.8571428571428571, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, nan, 0.0, 0.5454545454545454, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:41.016103: step 1150, loss 2.04565, accuracy 0.5, precision [0.25, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, nan, nan, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0]
2019-02-19T18:07:41.167731: step 1151, loss 2.22641, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0], recall [1.0, 0.0, 1.0, 0.4, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:07:41.319993: step 1152, loss 1.38181, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.0, 0.42857142857142855, 1.0, nan, nan, nan, nan], recall [0.5, 0.0, 0.0, 0.75, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:07:41.473247: step 1153, loss 2.23561, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.5, 1.0, nan, nan, nan, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 0.7142857142857143, nan, nan, 0.0, nan]
2019-02-19T18:07:41.587827: step 1154, loss 1.76569, accuracy 0.5, precision [nan, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 0.0, 0.6666666666666666, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:07:41.741734: step 1155, loss 1.27471, accuracy 0.5, precision [nan, 0.2, nan, 0.8333333333333334, 1.0, 0.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.0, 0.5, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:07:41.899967: step 1156, loss 1.98673, accuracy 0.375, precision [0.0, 0.0, 0.0, 1.0, 0.6, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, nan, 0.0, 0.2222222222222222, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:42.050081: step 1157, loss 1.95828, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.5, 1.0, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.2222222222222222, 0.75, nan, nan, nan, nan]
2019-02-19T18:07:42.205106: step 1158, loss 1.69766, accuracy 0.4375, precision [0.3333333333333333, nan, 0.0, 0.6666666666666666, 0.5, nan, nan, 1.0, nan], recall [0.3333333333333333, nan, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:07:42.360796: step 1159, loss 1.21634, accuracy 0.5625, precision [nan, 0.5, 0.3333333333333333, 0.5714285714285714, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.5, 0.5, 0.6666666666666666, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:07:42.519145: step 1160, loss 0.945044, accuracy 0.6875, precision [1.0, 1.0, nan, 0.3333333333333333, 1.0, 0.0, 1.0, 0.75, nan], recall [0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 1.0, nan, 1.0, 0.75, nan]
2019-02-19T18:07:42.673678: step 1161, loss 1.74201, accuracy 0.4375, precision [0.5, 0.2, 1.0, 0.25, 1.0, nan, nan, 1.0, 0.0], recall [0.5, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:07:42.831761: step 1162, loss 0.810016, accuracy 0.75, precision [nan, 1.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan], recall [nan, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:07:42.987294: step 1163, loss 1.51886, accuracy 0.4375, precision [0.0, 0.0, nan, 0.6, 0.5, nan, nan, nan, nan], recall [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:07:43.146102: step 1164, loss 1.25227, accuracy 0.5, precision [1.0, 0.0, 0.75, 0.4, 1.0, 1.0, nan, nan, 0.0], recall [1.0, nan, 0.5, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0]
2019-02-19T18:07:43.298440: step 1165, loss 1.76419, accuracy 0.4375, precision [0.0, nan, 0.3333333333333333, 0.25, 1.0, 0.3333333333333333, nan, 0.6666666666666666, nan], recall [nan, 0.0, 0.5, 0.2, 1.0, 0.3333333333333333, nan, 0.6666666666666666, nan]
2019-02-19T18:07:43.451513: step 1166, loss 0.850909, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.5, 0.0], recall [0.75, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:07:43.604877: step 1167, loss 1.19445, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.5, 0.6, 1.0, 0.0, nan, 0.5, 0.0], recall [0.3333333333333333, 0.6666666666666666, 0.5, 0.75, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:07:43.759111: step 1168, loss 2.82879, accuracy 0.6875, precision [0.5, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, 1.0, 0.4, 1.0, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:07:43.912840: step 1169, loss 0.548593, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, nan], recall [0.5, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.5, nan, 1.0, 0.0]
2019-02-19T18:07:44.072239: step 1170, loss 2.0359, accuracy 0.6875, precision [1.0, nan, 1.0, 0.75, 1.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan], recall [1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0]
2019-02-19T18:07:44.227863: step 1171, loss 1.45106, accuracy 0.5, precision [0.6666666666666666, 1.0, 1.0, 0.2857142857142857, nan, nan, nan, 0.5, nan], recall [0.6666666666666666, 0.5, 1.0, 0.5, nan, 0.0, nan, 0.5, nan]
2019-02-19T18:07:44.385316: step 1172, loss 1.28318, accuracy 0.5625, precision [nan, nan, 0.5, 0.5, 0.6666666666666666, nan, 0.0, 0.6, nan], recall [nan, 0.0, 1.0, 0.16666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:44.538360: step 1173, loss 0.903998, accuracy 0.75, precision [0.75, 0.3333333333333333, 1.0, 0.75, 1.0, nan, nan, nan, nan], recall [1.0, 0.5, 0.3333333333333333, 0.75, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:44.697746: step 1174, loss 1.52078, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan], recall [0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:07:44.861689: step 1175, loss 1.09851, accuracy 0.6875, precision [1.0, 0.5, nan, 0.6666666666666666, 1.0, nan, nan, 0.5, nan], recall [1.0, 1.0, nan, 0.75, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:07:45.016778: step 1176, loss 1.244, accuracy 0.5625, precision [nan, 1.0, 0.5, 0.6666666666666666, 0.4, nan, nan, 1.0, 0.0], recall [0.0, 0.5, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:07:45.172339: step 1177, loss 1.50235, accuracy 0.5625, precision [1.0, 0.75, 0.0, 0.5, 0.0, nan, nan, 1.0, nan], recall [0.75, 0.5, 0.0, 1.0, 0.0, nan, nan, 1.0, 0.0]
2019-02-19T18:07:45.326674: step 1178, loss 0.87754, accuracy 0.6875, precision [0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, nan, nan, nan, nan], recall [0.5, 1.0, 1.0, 0.75, 0.6, nan, nan, nan, nan]
2019-02-19T18:07:45.478705: step 1179, loss 1.67375, accuracy 0.6875, precision [1.0, 0.0, 0.6666666666666666, 0.8, 0.0, nan, nan, 1.0, nan], recall [0.6666666666666666, 0.0, 1.0, 0.8, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T18:07:45.636937: step 1180, loss 1.21278, accuracy 0.5625, precision [nan, 1.0, 0.5, 0.7142857142857143, 0.25, nan, 0.0, nan, nan], recall [0.0, 0.5, 1.0, 0.8333333333333334, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T18:07:45.789140: step 1181, loss 0.984668, accuracy 0.625, precision [1.0, 0.0, 0.0, 1.0, 0.5, 0.0, nan, 1.0, 1.0], recall [1.0, nan, nan, 0.6, 1.0, 0.0, nan, 1.0, 0.5]
2019-02-19T18:07:45.944274: step 1182, loss 1.28084, accuracy 0.5625, precision [nan, 0.3333333333333333, 0.0, 0.75, 0.8, nan, nan, 0.0, 1.0], recall [nan, 0.5, nan, 0.3333333333333333, 1.0, nan, nan, nan, 1.0]
2019-02-19T18:07:46.099661: step 1183, loss 1.3218, accuracy 0.75, precision [nan, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.5714285714285714, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:46.251680: step 1184, loss 0.966855, accuracy 0.75, precision [1.0, nan, 0.0, 0.8888888888888888, 0.0, nan, 1.0, 1.0, nan], recall [0.6666666666666666, nan, nan, 0.8, nan, nan, 1.0, 0.5, nan]
2019-02-19T18:07:46.401920: step 1185, loss 1.40496, accuracy 0.5, precision [1.0, 0.5, 0.5, 1.0, 0.0, nan, nan, 0.3333333333333333, 0.0], recall [1.0, 1.0, 1.0, 0.14285714285714285, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:07:46.559267: step 1186, loss 0.727018, accuracy 0.75, precision [0.5, 0.0, nan, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.0, nan, 0.7, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:46.710078: step 1187, loss 0.986381, accuracy 0.6875, precision [nan, 1.0, 0.0, 0.75, 0.8333333333333334, 0.0, 0.0, 1.0, nan], recall [nan, 1.0, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:46.864109: step 1188, loss 1.20643, accuracy 0.5625, precision [0.0, 1.0, 0.4, 0.6666666666666666, 1.0, nan, nan, 0.5, nan], recall [nan, 0.75, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:07:47.022364: step 1189, loss 1.57812, accuracy 0.5, precision [0.5, 0.5, 1.0, 0.2857142857142857, nan, 0.0, nan, 1.0, nan], recall [0.5, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:47.176294: step 1190, loss 1.08997, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan], recall [0.8, 0.6666666666666666, 1.0, 0.25, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:47.331411: step 1191, loss 1.79123, accuracy 0.5, precision [0.5, 1.0, nan, 0.5714285714285714, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [1.0, 0.3333333333333333, nan, 0.5714285714285714, 0.25, nan, nan, 1.0, nan]
2019-02-19T18:07:47.480966: step 1192, loss 0.78584, accuracy 0.75, precision [1.0, 0.6666666666666666, nan, 0.5, 1.0, 1.0, nan, nan, 0.5], recall [1.0, 0.6666666666666666, nan, 1.0, 0.7142857142857143, 1.0, nan, nan, 0.5]
2019-02-19T18:07:47.639876: step 1193, loss 1.88765, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.5, 0.5, nan, nan, nan, 0.0, nan], recall [nan, 1.0, 0.3333333333333333, 0.6, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:07:47.792548: step 1194, loss 1.67048, accuracy 0.375, precision [nan, 0.0, 0.0, 0.42857142857142855, 0.5, nan, nan, 0.6666666666666666, nan], recall [0.0, 0.0, 0.0, 0.5, 0.5, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:47.948029: step 1195, loss 1.7371, accuracy 0.5625, precision [nan, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan], recall [0.0, 1.0, nan, 0.625, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:07:48.098170: step 1196, loss 1.18527, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, nan, nan, nan, 0.5, nan], recall [0.6666666666666666, 0.8, 1.0, 0.6666666666666666, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:07:48.252159: step 1197, loss 1.3141, accuracy 0.5625, precision [0.5, 1.0, 0.0, 0.5714285714285714, 1.0, nan, nan, nan, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:48.405949: step 1198, loss 1.39034, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.6666666666666666, 0.75, nan, 0.0, 0.5, nan], recall [1.0, 0.0, 0.0, 0.4, 1.0, nan, nan, 0.4, nan]
2019-02-19T18:07:48.561960: step 1199, loss 1.42295, accuracy 0.5, precision [1.0, 0.0, nan, 0.5, 1.0, 0.0, 1.0, 0.25, 0.0], recall [1.0, nan, 0.0, 0.4, 0.5, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T18:07:48.717950: step 1200, loss 2.03204, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.5, 0.42857142857142855, 0.0, 0.0, nan, 1.0, nan], recall [1.0, 0.0, 0.3333333333333333, 0.5, nan, 0.0, nan, 0.5, 0.0]
2019-02-19T18:07:48.871489: step 1201, loss 1.32465, accuracy 0.6875, precision [1.0, 0.5, nan, 0.75, 1.0, nan, 0.5, 0.5, nan], recall [1.0, 0.5, 0.0, 1.0, 1.0, nan, 1.0, 0.25, nan]
2019-02-19T18:07:49.023302: step 1202, loss 0.988233, accuracy 0.75, precision [nan, 1.0, 1.0, 0.75, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.6, 0.5, 0.8571428571428571, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:49.174759: step 1203, loss 0.994973, accuracy 0.75, precision [0.5, 0.5, 0.5, 0.8571428571428571, 1.0, nan, nan, 1.0, nan], recall [1.0, 1.0, 1.0, 0.75, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:07:49.332510: step 1204, loss 1.2207, accuracy 0.5, precision [0.5, 0.6666666666666666, 0.5, 0.4, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:07:49.486857: step 1205, loss 1.81845, accuracy 0.625, precision [0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T18:07:49.643258: step 1206, loss 1.3662, accuracy 0.5625, precision [0.5, 0.0, nan, 0.625, 1.0, nan, 1.0, nan, nan], recall [0.5, 0.0, nan, 0.625, 0.6666666666666666, nan, 1.0, 0.0, nan]
2019-02-19T18:07:49.801606: step 1207, loss 0.224927, accuracy 1, precision [1.0, 1.0, nan, 1.0, 1.0, nan, nan, 1.0, nan], recall [1.0, 1.0, nan, 1.0, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:49.957583: step 1208, loss 1.22113, accuracy 0.6875, precision [nan, 0.0, 0.5, 0.8, 0.6666666666666666, nan, 1.0, 0.75, nan], recall [0.0, nan, 1.0, 0.6666666666666666, 1.0, nan, 0.5, 0.75, nan]
2019-02-19T18:07:50.117217: step 1209, loss 2.0346, accuracy 0.3125, precision [0.6666666666666666, 0.0, 0.0, 0.4, 0.5, 0.0, 0.0, nan, nan], recall [1.0, 0.0, nan, 0.2857142857142857, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T18:07:50.268098: step 1210, loss 0.973009, accuracy 0.625, precision [nan, 0.0, nan, 0.8333333333333334, 0.8, nan, nan, 0.5, nan], recall [nan, 0.0, 0.0, 0.5555555555555556, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:50.427233: step 1211, loss 1.35522, accuracy 0.4375, precision [nan, 1.0, nan, 0.4, 0.6, nan, nan, 0.0, 0.0], recall [0.0, 0.5, 0.0, 0.2857142857142857, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:50.577682: step 1212, loss 0.599815, accuracy 0.75, precision [0.5, 0.3333333333333333, 0.0, 1.0, 1.0, nan, 1.0, 1.0, nan], recall [0.5, 1.0, 0.0, 0.8333333333333334, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:07:50.736183: step 1213, loss 1.74243, accuracy 0.5, precision [nan, 0.6666666666666666, 0.5, 0.6, 0.3333333333333333, 0.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.3333333333333333, 0.5, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:07:50.890391: step 1214, loss 1.89856, accuracy 0.5, precision [nan, 0.3333333333333333, 0.3333333333333333, 0.75, 1.0, 0.0, 0.0, 1.0, 0.0], recall [0.0, 1.0, 1.0, 0.42857142857142855, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:51.047725: step 1215, loss 1.52708, accuracy 0.6875, precision [nan, 1.0, nan, 1.0, 0.0, 0.3333333333333333, 0.5, 0.5, nan], recall [nan, 1.0, nan, 0.75, 0.0, 1.0, 1.0, 0.3333333333333333, nan]
2019-02-19T18:07:51.199444: step 1216, loss 0.863538, accuracy 0.625, precision [1.0, 0.0, nan, 0.8, 0.75, nan, nan, 0.5, 0.0], recall [0.6666666666666666, 0.0, nan, 0.5714285714285714, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:07:51.355776: step 1217, loss 0.752673, accuracy 0.6875, precision [0.6666666666666666, 0.3333333333333333, nan, 1.0, 1.0, 0.0, 0.0, 1.0, nan], recall [0.6666666666666666, 1.0, nan, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:07:51.510530: step 1218, loss 0.713278, accuracy 0.8125, precision [nan, 0.8333333333333334, 1.0, 0.75, 0.5, nan, nan, nan, nan], recall [0.0, 1.0, 1.0, 0.75, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:07:51.663637: step 1219, loss 0.910083, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.6, 1.0, nan, nan, 0.0, nan], recall [1.0, 1.0, 0.5, 0.75, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:07:51.813295: step 1220, loss 0.822313, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.14285714285714285, 1.0, nan, 1.0, nan, nan], recall [1.0, 0.6, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, nan]
2019-02-19T18:07:51.963341: step 1221, loss 1.43023, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 0.6666666666666666, 0.0, nan, nan], recall [0.0, 0.5, 0.0, 0.5, 1.0, 1.0, nan, 0.0, 0.0]
2019-02-19T18:07:52.116754: step 1222, loss 0.890097, accuracy 0.75, precision [nan, 0.5, 0.6666666666666666, 1.0, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.7777777777777778, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:07:52.268312: step 1223, loss 1.32088, accuracy 0.625, precision [nan, 0.6666666666666666, 0.5, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 0.8, 0.5, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:07:52.426704: step 1224, loss 1.77073, accuracy 0.4375, precision [nan, 0.0, 1.0, 0.14285714285714285, 1.0, 1.0, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.5, 0.0, 0.6666666666666666, nan]
2019-02-19T18:07:52.583890: step 1225, loss 2.42054, accuracy 0.4375, precision [0.25, 0.5, 0.0, 0.4, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:07:52.738215: step 1226, loss 2.52955, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.25, 0.5, 0.0, 1.0, nan, nan], recall [0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.25, 0.0, 0.5, nan, 0.0]
2019-02-19T18:07:52.894130: step 1227, loss 1.35943, accuracy 0.625, precision [nan, 0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, nan], recall [0.0, 1.0, 1.0, 1.0, 0.3333333333333333, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:07:53.045715: step 1228, loss 0.938333, accuracy 0.6875, precision [nan, 1.0, 0.5, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan], recall [nan, 0.3333333333333333, 1.0, 0.75, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:07:53.205017: step 1229, loss 0.659456, accuracy 0.75, precision [nan, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 1.0, nan, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:07:53.361420: step 1230, loss 1.44889, accuracy 0.625, precision [0.5, 1.0, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, 0.0], recall [1.0, 0.5, 1.0, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T18:07:53.522031: step 1231, loss 1.92263, accuracy 0.4375, precision [0.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, nan, 0.0], recall [0.0, 0.5714285714285714, 0.0, 0.4, nan, 1.0, nan, 0.0, nan]
2019-02-19T18:07:53.677480: step 1232, loss 1.44596, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [nan, 0.6666666666666666, nan, 0.2857142857142857, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:07:53.832738: step 1233, loss 1.38952, accuracy 0.4375, precision [0.5, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, nan, nan, 0.5, 0.0], recall [0.5, 0.5, nan, 0.25, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:07:53.989471: step 1234, loss 1.21882, accuracy 0.4375, precision [1.0, 0.0, nan, 0.6, 1.0, 0.0, 0.5, 0.0, nan], recall [0.5, 0.0, nan, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:07:54.142335: step 1235, loss 1.70941, accuracy 0.6875, precision [nan, 0.0, 1.0, 0.875, 1.0, 0.0, nan, 0.5, nan], recall [nan, 0.0, 1.0, 0.7, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:07:54.297369: step 1236, loss 0.973521, accuracy 0.625, precision [1.0, 0.42857142857142855, 0.0, 1.0, 1.0, nan, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.14285714285714285, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:07:54.453743: step 1237, loss 1.28203, accuracy 0.5, precision [0.0, 0.25, nan, 1.0, 1.0, 0.3333333333333333, nan, nan, 0.0], recall [0.0, 1.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T18:07:54.607361: step 1238, loss 1.31098, accuracy 0.625, precision [0.5, 0.0, 0.0, 1.0, 1.0, 0.5, nan, 0.5, nan], recall [0.5, 0.0, nan, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, nan]
2019-02-19T18:07:54.756585: step 1239, loss 1.89624, accuracy 0.625, precision [nan, 1.0, nan, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, nan, nan, nan]
2019-02-19T18:07:54.906454: step 1240, loss 1.19325, accuracy 0.625, precision [0.75, 0.75, nan, 0.5, 0.5, nan, 0.0, 1.0, nan], recall [1.0, 0.75, nan, 0.4, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:07:55.061273: step 1241, loss 0.881549, accuracy 0.75, precision [0.5, 0.75, nan, 0.8571428571428571, nan, 1.0, nan, 1.0, 0.0], recall [1.0, 0.75, 0.0, 0.8571428571428571, nan, 1.0, nan, 0.5, nan]
2019-02-19T18:07:55.211878: step 1242, loss 2.1047, accuracy 0.5, precision [0.3333333333333333, 0.5, 0.5, 0.75, 1.0, 0.5, 0.0, nan, 0.0], recall [1.0, 1.0, 0.25, 0.42857142857142855, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:07:55.367398: step 1243, loss 0.936356, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, nan, 0.5, 0.0, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:07:55.533473: step 1244, loss 1.24895, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.0, 0.8, 1.0, 0.6666666666666666, nan, nan], recall [nan, 0.3333333333333333, nan, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, nan, nan]
2019-02-19T18:07:55.685757: step 1245, loss 1.7035, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.75, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [0.0, 0.5, nan, 0.375, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:07:55.839940: step 1246, loss 1.1952, accuracy 0.625, precision [1.0, 0.5, nan, 0.7142857142857143, 0.25, nan, nan, nan, nan], recall [1.0, 1.0, nan, 0.7142857142857143, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T18:07:55.994159: step 1247, loss 1.22714, accuracy 0.625, precision [0.0, 1.0, 0.5, 0.5, 0.6666666666666666, 0.5, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.5, nan]
2019-02-19T18:07:56.145546: step 1248, loss 1.30775, accuracy 0.5625, precision [0.5, 1.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, nan, nan], recall [1.0, 0.16666666666666666, nan, 1.0, 1.0, 1.0, 1.0, 0.0, nan]
2019-02-19T18:07:56.299210: step 1249, loss 1.40589, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.6, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.5, 0.75, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T18:07:56.452698: step 1250, loss 1.19033, accuracy 0.625, precision [0.0, 1.0, 0.6666666666666666, 0.8, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [nan, 1.0, 0.5, 0.8, 1.0, 0.0, 0.0, nan, 0.0]

Evaluation:
[[ 47  11   1  11   1   4   0   6   1]
 [  9  87   6  39   3   3   2   7   0]
 [  1   6  65  13   1   2   3   3   0]
 [  5  34  29 193   4  10   7  18   0]
 [  1   6   5   6 144   4   4   2   1]
 [  0   5   1  26   0  20   3   2   3]
 [  1   3   2   6   2   5  10   1   0]
 [  3  10   1  23   3   3   2  59   1]
 [  1   4   0  12   1   1   1   1   4]]
2019-02-19T18:07:58.883000: step 1250, loss 1.22113, accuracy 0.613659, precision [0.573170731707317, 0.5576923076923077, 0.6914893617021277, 0.6433333333333333, 0.8323699421965318, 0.3333333333333333, 0.3333333333333333, 0.5619047619047619, 0.16], recall [0.6911764705882353, 0.5240963855421686, 0.5909090909090909, 0.5866261398176292, 0.9056603773584906, 0.38461538461538464, 0.3125, 0.5959595959595959, 0.4]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-1250

2019-02-19T18:07:59.185651: step 1251, loss 1.18676, accuracy 0.75, precision [1.0, 1.0, nan, 0.3333333333333333, 1.0, 0.5, 0.0, 1.0, nan], recall [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, nan, 1.0, nan]
2019-02-19T18:07:59.343583: step 1252, loss 1.38992, accuracy 0.5625, precision [0.0, 0.5, nan, 0.6666666666666666, 0.75, 1.0, nan, 0.0, nan], recall [0.0, 0.5, nan, 1.0, 1.0, 0.5, 0.0, 0.0, nan]
2019-02-19T18:07:59.504052: step 1253, loss 0.946105, accuracy 0.5625, precision [0.0, 0.75, 0.0, 0.5, 1.0, 1.0, nan, 1.0, 0.0], recall [nan, 0.6, 0.0, 0.4, 0.5, 1.0, nan, 1.0, nan]
2019-02-19T18:07:59.657850: step 1254, loss 1.09675, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.5, 0.5, 1.0, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:07:59.814380: step 1255, loss 1.74024, accuracy 0.5, precision [nan, 1.0, nan, 0.3333333333333333, 0.6, 1.0, nan, 0.0, nan], recall [nan, 0.5, nan, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, nan]
2019-02-19T18:07:59.968939: step 1256, loss 0.978592, accuracy 0.625, precision [1.0, 0.6666666666666666, 0.3333333333333333, 0.75, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.75, 0.5, 0.0, 0.0, 1.0, nan]
2019-02-19T18:08:00.124832: step 1257, loss 1.23312, accuracy 0.625, precision [1.0, 1.0, nan, 0.42857142857142855, 0.8, nan, nan, 0.5, nan], recall [1.0, 0.5, 0.0, 0.75, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:08:00.283083: step 1258, loss 1.74241, accuracy 0.625, precision [nan, 0.5, 0.5, 0.5, 1.0, 0.0, 0.3333333333333333, 1.0, nan], recall [nan, 0.3333333333333333, 1.0, 0.2, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:08:00.435331: step 1259, loss 1.09801, accuracy 0.625, precision [1.0, 0.5, 0.5, 0.6, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 0.5, 0.5, 0.6, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:08:00.587450: step 1260, loss 1.68671, accuracy 0.625, precision [nan, 1.0, 0.0, 0.6666666666666666, 0.8333333333333334, 0.0, nan, 1.0, nan], recall [0.0, 1.0, nan, 0.3333333333333333, 0.8333333333333334, nan, nan, 1.0, nan]
2019-02-19T18:08:00.746437: step 1261, loss 1.69785, accuracy 0.6875, precision [0.0, 0.0, nan, 1.0, 1.0, nan, 0.0, 1.0, nan], recall [nan, nan, nan, 0.4, 1.0, nan, nan, 0.6, nan]
2019-02-19T18:08:00.900697: step 1262, loss 1.2736, accuracy 0.625, precision [0.75, 0.0, 0.5, 0.6, 1.0, nan, nan, nan, nan], recall [0.6, 0.0, 1.0, 0.75, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T18:08:01.054853: step 1263, loss 0.623134, accuracy 0.75, precision [1.0, 0.3333333333333333, nan, 0.875, 0.6666666666666666, 1.0, nan, nan, nan], recall [0.5, 1.0, nan, 0.875, 1.0, 0.5, nan, 0.0, nan]
2019-02-19T18:08:01.211904: step 1264, loss 0.75658, accuracy 0.8125, precision [0.6666666666666666, 1.0, 0.5, 0.75, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.75, 1.0, 0.6, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:01.369051: step 1265, loss 1.15662, accuracy 0.625, precision [1.0, 1.0, 0.4, 0.5, 1.0, 0.3333333333333333, nan, 1.0, nan], recall [1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T18:08:01.525431: step 1266, loss 2.88821, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.6, 1.0, 0.0, nan, nan, 0.0], recall [0.0, 0.6666666666666666, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:01.682231: step 1267, loss 2.01195, accuracy 0.5625, precision [nan, 1.0, 0.5, 0.6666666666666666, 0.5, nan, nan, 1.0, 0.0], recall [nan, 1.0, 1.0, 0.4, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:08:01.838935: step 1268, loss 1.14439, accuracy 0.625, precision [nan, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [nan, nan, 0.5, 0.6666666666666666, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:08:01.990650: step 1269, loss 1.45888, accuracy 0.625, precision [0.0, 0.6666666666666666, nan, 0.875, nan, 0.0, nan, 1.0, nan], recall [0.0, 0.6666666666666666, nan, 0.7777777777777778, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:08:02.142383: step 1270, loss 1.3863, accuracy 0.75, precision [1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, nan, 1.0, 0.0], recall [1.0, 0.5, 0.5, 0.6666666666666666, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:08:02.296449: step 1271, loss 2.0456, accuracy 0.5, precision [0.25, 0.5, 1.0, 0.5, 0.5, nan, 1.0, 0.5, nan], recall [1.0, 1.0, 0.25, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0]
2019-02-19T18:08:02.450425: step 1272, loss 0.931505, accuracy 0.6875, precision [1.0, 0.5, nan, 0.75, 0.6666666666666666, nan, 1.0, 0.0, nan], recall [0.5, 0.5, nan, 0.8571428571428571, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:08:02.606013: step 1273, loss 1.70189, accuracy 0.625, precision [0.3333333333333333, 0.5, nan, 1.0, 0.8, 0.0, nan, 1.0, nan], recall [0.5, 0.5, nan, 0.6666666666666666, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:08:02.763076: step 1274, loss 2.79747, accuracy 0.375, precision [0.3333333333333333, 0.25, 0.3333333333333333, 1.0, nan, 1.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 0.0, 0.25, nan, nan, nan]
2019-02-19T18:08:02.916570: step 1275, loss 1.08789, accuracy 0.6875, precision [nan, 0.3333333333333333, 0.5, 1.0, 0.8, nan, nan, 1.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:08:03.071032: step 1276, loss 0.986362, accuracy 0.75, precision [0.0, 1.0, 1.0, 0.625, 1.0, nan, 1.0, nan, nan], recall [nan, 0.5, 0.3333333333333333, 1.0, 0.75, nan, 1.0, nan, nan]
2019-02-19T18:08:03.225084: step 1277, loss 1.22101, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.3333333333333333, 0.5714285714285714, 0.5, nan, nan, nan, nan], recall [0.3333333333333333, 0.6666666666666666, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:03.376845: step 1278, loss 1.22308, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.7142857142857143, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.6666666666666666, 0.5, 0.8333333333333334, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:08:03.527534: step 1279, loss 1.05911, accuracy 0.625, precision [0.0, 0.75, 1.0, 0.5, 1.0, 0.5, nan, 0.0, nan], recall [0.0, 0.75, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, nan, nan, nan]
2019-02-19T18:08:03.676597: step 1280, loss 1.17913, accuracy 0.6875, precision [nan, 1.0, 0.0, 0.5714285714285714, 1.0, 0.5, nan, 1.0, nan], recall [0.0, 1.0, 0.0, 0.8, 1.0, 0.5, nan, 1.0, nan]
2019-02-19T18:08:03.829743: step 1281, loss 0.665247, accuracy 0.875, precision [1.0, nan, 1.0, 0.8571428571428571, 1.0, nan, 1.0, 0.6666666666666666, nan], recall [1.0, nan, 1.0, 0.8571428571428571, 1.0, nan, 1.0, 0.6666666666666666, nan]
2019-02-19T18:08:03.987455: step 1282, loss 1.4489, accuracy 0.5625, precision [1.0, 1.0, 0.5, 0.6666666666666666, 0.5, nan, 0.0, 0.3333333333333333, nan], recall [0.5, 0.3333333333333333, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:08:04.147093: step 1283, loss 0.680304, accuracy 0.8125, precision [0.5, 1.0, 1.0, 1.0, 0.75, nan, 0.0, nan, nan], recall [1.0, 0.6666666666666666, 0.75, 1.0, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:08:04.300170: step 1284, loss 0.815217, accuracy 0.6875, precision [0.0, 0.6666666666666666, 1.0, 0.7142857142857143, 0.6666666666666666, nan, nan, nan, nan], recall [0.0, 0.5, 1.0, 0.8333333333333334, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:04.456178: step 1285, loss 0.967992, accuracy 0.6875, precision [1.0, 0.0, 1.0, 0.75, nan, 0.3333333333333333, 1.0, nan, nan], recall [0.3333333333333333, nan, 0.6666666666666666, 0.75, nan, 1.0, 1.0, nan, nan]
2019-02-19T18:08:04.609272: step 1286, loss 1.78655, accuracy 0.6875, precision [1.0, 0.6666666666666666, nan, 1.0, 0.6, nan, 0.0, 0.5, nan], recall [1.0, 0.4, nan, 0.75, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:08:04.759936: step 1287, loss 0.494353, accuracy 0.75, precision [0.5, nan, 0.5, 0.75, 1.0, 0.0, 1.0, nan, 1.0], recall [1.0, nan, 0.5, 0.5, 1.0, nan, 1.0, nan, 1.0]
2019-02-19T18:08:04.915420: step 1288, loss 1.22681, accuracy 0.5625, precision [0.0, 0.75, 0.0, 1.0, 0.75, nan, nan, nan, 0.0], recall [nan, 0.75, nan, 0.375, 0.75, nan, nan, nan, nan]
2019-02-19T18:08:05.070587: step 1289, loss 2.17231, accuracy 0.3125, precision [nan, 0.0, nan, 0.5, 0.5, 0.0, nan, 0.4, 0.0], recall [nan, 0.0, 0.0, 0.125, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:08:05.222192: step 1290, loss 2.08537, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 1.0, 0.5, 0.2, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:08:05.378667: step 1291, loss 1.5306, accuracy 0.6875, precision [0.25, 1.0, 1.0, 1.0, 1.0, 0.0, nan, 0.75, nan], recall [1.0, 1.0, 1.0, 0.375, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:05.535361: step 1292, loss 1.09126, accuracy 0.5625, precision [nan, 0.8, nan, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, nan, 0.2, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:05.688396: step 1293, loss 1.4124, accuracy 0.4375, precision [0.0, nan, 0.0, 0.6, 0.5, 0.0, 0.5, 1.0, nan], recall [0.0, nan, nan, 0.375, 0.6666666666666666, nan, 1.0, 0.5, nan]
2019-02-19T18:08:05.842496: step 1294, loss 2.29009, accuracy 0.5, precision [0.5, 0.6666666666666666, nan, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, nan], recall [1.0, 1.0, 0.0, 0.25, 0.6, 0.0, nan, 0.5, nan]
2019-02-19T18:08:05.994342: step 1295, loss 1.34247, accuracy 0.5625, precision [1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, nan, 0.25, nan], recall [0.75, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, nan, nan, 1.0, 0.0]
2019-02-19T18:08:06.151806: step 1296, loss 1.36228, accuracy 0.375, precision [1.0, 0.25, 1.0, 0.2, 0.0, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.0, nan, nan, 0.6666666666666666, 0.0]
2019-02-19T18:08:06.304441: step 1297, loss 1.58303, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.25, 1.0, 0.0, 1.0, 1.0, nan], recall [0.0, 1.0, 1.0, 0.25, 1.0, nan, 0.5, 1.0, 0.0]
2019-02-19T18:08:06.460425: step 1298, loss 1.72155, accuracy 0.5, precision [0.0, 1.0, 0.5, 0.5714285714285714, 0.0, nan, 0.0, 1.0, 0.0], recall [0.0, 0.5, 0.25, 0.6666666666666666, nan, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:08:06.614600: step 1299, loss 0.832854, accuracy 0.5625, precision [0.0, 0.6, nan, 0.625, 1.0, nan, 0.0, nan, nan], recall [0.0, 0.75, 0.0, 0.8333333333333334, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:08:06.768099: step 1300, loss 1.6169, accuracy 0.5625, precision [nan, 0.25, nan, 0.6, 1.0, 1.0, 0.0, 0.5, nan], recall [0.0, 0.3333333333333333, 0.0, 0.6, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:08:06.926439: step 1301, loss 1.70066, accuracy 0.5625, precision [0.5, 0.0, 0.0, 0.5, 1.0, nan, nan, 1.0, nan], recall [0.5, 0.0, nan, 0.75, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:08:07.084910: step 1302, loss 0.942823, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 0.5, 0.8, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T18:08:07.239104: step 1303, loss 1.92724, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.5, nan, 0.0, 0.0, 1.0, nan], recall [0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, nan, 0.5, nan]
2019-02-19T18:08:07.390965: step 1304, loss 1.22305, accuracy 0.625, precision [0.6666666666666666, 0.3333333333333333, 0.0, 0.6, 1.0, nan, nan, 1.0, nan], recall [1.0, 1.0, 0.0, 0.75, 0.75, nan, 0.0, 1.0, nan]
2019-02-19T18:08:07.544287: step 1305, loss 1.35224, accuracy 0.4375, precision [nan, 0.3333333333333333, nan, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.8, 0.6666666666666666, nan, 0.0, 0.0, 0.0]
2019-02-19T18:08:07.703721: step 1306, loss 1.26224, accuracy 0.625, precision [1.0, nan, 0.5, 0.75, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0], recall [0.5, 0.0, 1.0, 0.6, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T18:08:07.860056: step 1307, loss 1.16893, accuracy 0.5625, precision [0.0, nan, 0.0, 0.7142857142857143, 0.5, 0.6, nan, nan, nan], recall [0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T18:08:08.017580: step 1308, loss 0.785894, accuracy 0.6875, precision [1.0, 1.0, nan, 0.5, 0.0, nan, nan, 1.0, nan], recall [1.0, 0.75, 0.0, 0.8, nan, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:08:08.176245: step 1309, loss 1.11289, accuracy 0.5625, precision [0.75, 0.5, nan, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 1.0, nan, 0.4, 0.3333333333333333, nan, 0.0, 0.5, nan]
2019-02-19T18:08:08.330730: step 1310, loss 0.996634, accuracy 0.6875, precision [0.5, 0.3333333333333333, 0.5, 1.0, 0.75, 1.0, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:08:08.488989: step 1311, loss 1.75593, accuracy 0.5625, precision [0.5, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, nan, nan], recall [1.0, nan, nan, 0.6, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:08:08.645123: step 1312, loss 1.60202, accuracy 0.5625, precision [0.3333333333333333, 0.5, nan, 1.0, 0.5, nan, nan, 0.5, nan], recall [0.5, 0.6666666666666666, nan, 0.42857142857142855, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:08.802594: step 1313, loss 1.7128, accuracy 0.6875, precision [nan, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, nan, nan], recall [nan, nan, nan, 0.7, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:08:08.958388: step 1314, loss 1.72845, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.0, 0.6, 0.3333333333333333, nan, 1.0, 0.0, nan], recall [0.5, 1.0, 0.0, 0.5, 1.0, nan, 1.0, 0.0, 0.0]
2019-02-19T18:08:09.111252: step 1315, loss 2.34806, accuracy 0.5, precision [nan, 0.5, nan, 0.5, 1.0, 0.0, 0.0, 0.5, 0.0], recall [nan, 1.0, 0.0, 0.5, 0.75, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:08:09.266608: step 1316, loss 0.8948, accuracy 0.6875, precision [0.0, 0.6, nan, 1.0, 1.0, 1.0, 0.5, nan, nan], recall [nan, 0.6, nan, 0.4, 1.0, 1.0, 1.0, nan, nan]
2019-02-19T18:08:09.426664: step 1317, loss 1.86711, accuracy 0.5, precision [nan, 0.5, 0.0, 0.8, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.6666666666666666, nan, 0.5714285714285714, 0.5, 0.0, nan, 1.0, 0.0]
2019-02-19T18:08:09.587072: step 1318, loss 1.682, accuracy 0.5, precision [0.6666666666666666, 0.0, nan, 0.6, 1.0, 0.0, 0.0, 0.5, nan], recall [1.0, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:09.746852: step 1319, loss 2.16955, accuracy 0.375, precision [0.3333333333333333, 1.0, 0.0, 0.4, 1.0, nan, 0.5, 0.0, nan], recall [0.5, 0.2, nan, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, nan]
2019-02-19T18:08:09.898657: step 1320, loss 1.01475, accuracy 0.5625, precision [0.0, 1.0, nan, 0.4, 0.8, 0.0, nan, 0.5, nan], recall [nan, 0.5, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T18:08:10.050790: step 1321, loss 0.795062, accuracy 0.75, precision [1.0, 0.5, nan, 0.6666666666666666, 0.8571428571428571, 0.0, nan, 1.0, nan], recall [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.8571428571428571, nan, 0.0, 1.0, nan]
2019-02-19T18:08:10.203588: step 1322, loss 0.432344, accuracy 0.875, precision [nan, 1.0, 0.75, 1.0, 1.0, 0.6666666666666666, nan, nan, nan], recall [nan, 1.0, 1.0, 0.7777777777777778, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:08:10.353611: step 1323, loss 1.58236, accuracy 0.4375, precision [1.0, nan, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.3333333333333333, nan], recall [1.0, 0.0, 1.0, 0.6, nan, 0.0, 0.0, 0.5, nan]
2019-02-19T18:08:10.505715: step 1324, loss 1.94925, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.0, 1.0, 0.75, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:08:10.663916: step 1325, loss 1.70736, accuracy 0.375, precision [nan, 0.0, 1.0, 0.25, 0.6666666666666666, nan, nan, 1.0, nan], recall [0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T18:08:10.827165: step 1326, loss 0.883398, accuracy 0.5625, precision [0.0, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.5, nan], recall [nan, 0.0, 1.0, 0.7142857142857143, 0.6666666666666666, 0.0, 0.0, 1.0, nan]
2019-02-19T18:08:10.978954: step 1327, loss 1.31728, accuracy 0.625, precision [1.0, 0.0, 0.75, 0.75, 1.0, 0.0, 0.0, 0.5, nan], recall [0.3333333333333333, nan, 1.0, 0.6, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:08:11.132319: step 1328, loss 1.21787, accuracy 0.5625, precision [nan, 0.5, nan, 0.6666666666666666, 0.5, nan, nan, 0.5, nan], recall [0.0, 1.0, 0.0, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:11.285436: step 1329, loss 0.782905, accuracy 0.6875, precision [nan, 1.0, 0.5, 0.5, 1.0, nan, 1.0, nan, nan], recall [nan, 0.75, 0.6666666666666666, 0.75, 1.0, 0.0, 0.5, nan, nan]
2019-02-19T18:08:11.446283: step 1330, loss 0.900142, accuracy 0.75, precision [0.0, nan, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.8, nan], recall [0.0, nan, 0.6666666666666666, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:11.598788: step 1331, loss 1.82499, accuracy 0.5625, precision [0.5, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, nan], recall [1.0, 0.5, 0.5, 0.5, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:08:11.753182: step 1332, loss 1.75434, accuracy 0.5, precision [1.0, 0.0, nan, 0.7142857142857143, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, 0.0, 0.8333333333333334, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:11.912696: step 1333, loss 1.86915, accuracy 0.4375, precision [0.0, nan, 0.6666666666666666, 0.5555555555555556, 0.0, 0.0, nan, nan, nan], recall [nan, 0.0, 0.5, 0.7142857142857143, nan, nan, nan, 0.0, nan]
2019-02-19T18:08:12.070400: step 1334, loss 0.768324, accuracy 0.6875, precision [0.5, 0.5, nan, 0.8333333333333334, 0.6666666666666666, 1.0, nan, nan, nan], recall [1.0, 1.0, nan, 0.625, 1.0, 0.3333333333333333, nan, nan, nan]
2019-02-19T18:08:12.231419: step 1335, loss 1.43084, accuracy 0.375, precision [0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, nan], recall [0.0, nan, 1.0, 0.1111111111111111, 0.75, nan, 1.0, nan, nan]
2019-02-19T18:08:12.389021: step 1336, loss 1.11911, accuracy 0.5, precision [0.3333333333333333, nan, 0.3333333333333333, 0.6666666666666666, 0.75, 0.0, 1.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.2857142857142857, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:08:12.545328: step 1337, loss 2.15175, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, 0.0, nan, 0.4, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:08:12.699718: step 1338, loss 1.60122, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 0.25, nan], recall [1.0, 1.0, nan, 0.2222222222222222, 0.5, 1.0, nan, 1.0, nan]
2019-02-19T18:08:12.854006: step 1339, loss 1.47838, accuracy 0.5625, precision [0.0, 1.0, 0.5, 1.0, 0.4, nan, 0.0, 1.0, 0.0], recall [nan, 1.0, 0.3333333333333333, 0.5, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:08:13.013403: step 1340, loss 1.49045, accuracy 0.6875, precision [nan, 0.6, 1.0, 0.75, 0.6666666666666666, nan, nan, 0.6666666666666666, nan], recall [nan, 0.75, 1.0, 0.75, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:08:13.167315: step 1341, loss 1.9207, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.8333333333333334, 1.0, 0.0, 0.0, 0.5, 0.0], recall [nan, 0.5, 1.0, 0.5, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:08:13.321883: step 1342, loss 1.00222, accuracy 0.625, precision [0.5, 0.0, 0.5, 0.7142857142857143, 1.0, nan, 0.5, 1.0, nan], recall [0.5, nan, 1.0, 0.7142857142857143, 0.25, nan, 1.0, 1.0, nan]
2019-02-19T18:08:13.472565: step 1343, loss 1.52547, accuracy 0.75, precision [1.0, nan, 0.5, 0.7142857142857143, 1.0, 1.0, nan, 1.0, 0.0], recall [1.0, nan, 0.5, 1.0, 0.75, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T18:08:13.629606: step 1344, loss 0.674832, accuracy 0.6875, precision [0.5, 1.0, 1.0, 1.0, 1.0, nan, 1.0, 0.0, nan], recall [1.0, 0.5, 0.5, 0.4, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:08:13.788577: step 1345, loss 1.05939, accuracy 0.6875, precision [nan, 0.0, 1.0, 1.0, 0.3333333333333333, nan, 0.0, 0.6666666666666666, nan], recall [nan, nan, 0.8, 0.5714285714285714, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:08:13.939569: step 1346, loss 1.47904, accuracy 0.5625, precision [0.75, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, nan], recall [1.0, 0.0, nan, 0.4, 0.6666666666666666, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:08:14.096533: step 1347, loss 0.852179, accuracy 0.75, precision [1.0, 0.75, 1.0, 0.3333333333333333, nan, 0.5, nan, 1.0, nan], recall [0.75, 0.75, 0.6666666666666666, 1.0, 0.0, 1.0, nan, 1.0, nan]
2019-02-19T18:08:14.251726: step 1348, loss 1.06355, accuracy 0.5625, precision [0.0, 0.6666666666666666, nan, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.0, 0.5, 0.6, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:08:14.409334: step 1349, loss 2.08958, accuracy 0.5625, precision [1.0, 0.5, nan, 0.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [0.5, 0.6, 0.0, nan, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:08:14.562171: step 1350, loss 1.75887, accuracy 0.5, precision [nan, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, nan], recall [0.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, nan, 0.5, 0.0, nan]
2019-02-19T18:08:14.717151: step 1351, loss 1.25697, accuracy 0.625, precision [1.0, 0.0, 0.75, 0.6, 1.0, nan, nan, 1.0, nan], recall [0.25, 0.0, 1.0, 0.75, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:14.878779: step 1352, loss 1.35054, accuracy 0.5625, precision [0.6666666666666666, 0.5, nan, 0.75, 0.4, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.6, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T18:08:15.035634: step 1353, loss 2.07467, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [0.5, 0.6666666666666666, nan, 0.3333333333333333, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:08:15.194845: step 1354, loss 1.37703, accuracy 0.5625, precision [1.0, nan, 1.0, 0.5714285714285714, 1.0, 0.0, 1.0, 0.0, 0.0], recall [0.5, 0.0, 1.0, 0.8, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:08:15.354326: step 1355, loss 1.57466, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.6, 0.75, nan, nan, nan, nan], recall [nan, 0.0, 0.0, 0.8571428571428571, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:08:15.509673: step 1356, loss 0.844695, accuracy 0.625, precision [1.0, 0.0, 0.0, 0.6, 1.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, nan, nan, 0.6, 1.0, 0.0, nan, 0.75, nan]
2019-02-19T18:08:15.665145: step 1357, loss 1.94047, accuracy 0.5, precision [0.5, 0.0, 0.5, 1.0, 0.5, 1.0, 0.0, 0.5, nan], recall [0.5, 0.0, 1.0, 0.25, 0.6666666666666666, 0.5, nan, 1.0, nan]
2019-02-19T18:08:15.816541: step 1358, loss 1.39039, accuracy 0.5625, precision [0.6666666666666666, 0.2, 0.0, 1.0, 1.0, 0.5, nan, nan, nan], recall [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.5, 0.5, 0.0, 0.0, nan]
2019-02-19T18:08:15.968388: step 1359, loss 0.913263, accuracy 0.75, precision [0.0, 0.0, 1.0, 0.75, 1.0, 1.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.6, 0.75, 1.0, nan, 1.0, nan]
2019-02-19T18:08:16.122673: step 1360, loss 1.59508, accuracy 0.5, precision [nan, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, nan, nan, 1.0], recall [nan, 0.2, 0.0, 0.5, 0.8, nan, nan, nan, 1.0]
2019-02-19T18:08:16.280010: step 1361, loss 1.80101, accuracy 0.5, precision [1.0, 0.0, 0.5, 0.7142857142857143, 1.0, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, 1.0, 0.5555555555555556, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:16.437075: step 1362, loss 2.92625, accuracy 0.4375, precision [nan, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.4, 0.3333333333333333, 0.0, 1.0, 1.0, nan]
2019-02-19T18:08:16.588996: step 1363, loss 1.31771, accuracy 0.5625, precision [0.0, 0.3333333333333333, 0.0, 0.5, 1.0, nan, nan, nan, nan], recall [0.0, 0.3333333333333333, nan, 0.75, 0.8333333333333334, 0.0, nan, 0.0, nan]
2019-02-19T18:08:16.743866: step 1364, loss 1.52299, accuracy 0.625, precision [1.0, 1.0, nan, 0.75, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0], recall [1.0, 0.75, 0.0, 0.5, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:08:16.898100: step 1365, loss 1.35133, accuracy 0.5625, precision [1.0, nan, 0.5, 1.0, 0.6, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 1.0, 0.4444444444444444, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:17.050960: step 1366, loss 1.69551, accuracy 0.5625, precision [0.5, 0.6666666666666666, 0.5, 0.6, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.5, 0.6666666666666666, 0.5, 0.5, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:08:17.207629: step 1367, loss 2.05448, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.7777777777777778, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 0.0, nan, 0.7, 0.6666666666666666, 0.0, nan, nan, 0.0]
2019-02-19T18:08:17.367760: step 1368, loss 2.03985, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.7777777777777778, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.7, nan, nan, nan, 0.0, 0.0]
2019-02-19T18:08:17.520012: step 1369, loss 1.88008, accuracy 0.5, precision [nan, 0.75, 0.0, 0.5, 1.0, nan, 0.0, 0.5, nan], recall [nan, 0.6, nan, 0.5, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:08:17.676811: step 1370, loss 1.03971, accuracy 0.6875, precision [0.75, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [1.0, nan, 1.0, 0.42857142857142855, 0.75, nan, nan, nan, nan]
2019-02-19T18:08:17.837093: step 1371, loss 0.972859, accuracy 0.625, precision [0.5, 0.3333333333333333, 0.0, 1.0, 0.0, nan, nan, 0.5, nan], recall [1.0, 0.5, nan, 0.875, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:08:17.994220: step 1372, loss 0.656992, accuracy 0.8125, precision [1.0, 1.0, 0.6666666666666666, 1.0, 0.8, nan, 1.0, 0.0, nan], recall [1.0, 0.5, 1.0, 0.8, 1.0, nan, 1.0, nan, 0.0]
2019-02-19T18:08:18.146752: step 1373, loss 1.40216, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.4, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [1.0, 0.3333333333333333, nan, 0.25, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:08:18.304875: step 1374, loss 1.4, accuracy 0.5625, precision [0.0, 1.0, nan, 0.5714285714285714, 1.0, nan, nan, 0.0, nan], recall [nan, 0.6, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:08:18.459474: step 1375, loss 1.36312, accuracy 0.6875, precision [0.5, 0.75, nan, 0.8, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [1.0, 0.6, nan, 0.8, 0.5, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:08:18.613535: step 1376, loss 0.650379, accuracy 0.8125, precision [1.0, nan, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, nan], recall [1.0, nan, 0.5, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:18.766851: step 1377, loss 0.959091, accuracy 0.6875, precision [0.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5], recall [nan, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 1.0]
2019-02-19T18:08:18.926755: step 1378, loss 1.16519, accuracy 0.5625, precision [1.0, 1.0, 0.75, 0.25, 1.0, 0.0, 0.0, nan, 0.0], recall [1.0, 0.5, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:19.078192: step 1379, loss 0.917786, accuracy 0.6875, precision [0.5, nan, 0.6666666666666666, 0.8333333333333334, 1.0, nan, 0.0, 0.5, nan], recall [1.0, 0.0, 1.0, 0.625, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:08:19.231599: step 1380, loss 0.525897, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.25, 1.0, nan, nan, 0.5, nan], recall [0.5, 0.5, 0.3333333333333333, 1.0, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:19.391037: step 1381, loss 1.21599, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.5, 0.75, 0.0, nan, 0.0, 1.0, nan], recall [1.0, 1.0, 0.5, 0.375, nan, 0.0, nan, 1.0, nan]
2019-02-19T18:08:19.547218: step 1382, loss 1.9424, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:08:19.701124: step 1383, loss 0.725133, accuracy 0.75, precision [1.0, 0.5, 1.0, 0.6, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.6666666666666666, 1.0, 0.75, 0.8, nan, nan, 0.5, nan]
2019-02-19T18:08:19.857512: step 1384, loss 1.23895, accuracy 0.625, precision [0.5, 1.0, nan, 0.625, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.7142857142857143, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:08:20.013567: step 1385, loss 1.17896, accuracy 0.6875, precision [1.0, 0.6, 1.0, 1.0, 0.0, 0.0, nan, 0.0, nan], recall [1.0, 1.0, 1.0, 0.7142857142857143, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:08:20.168367: step 1386, loss 0.658393, accuracy 0.75, precision [nan, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.5, 0.6666666666666666, 0.8, nan, nan, 1.0, nan]
2019-02-19T18:08:20.323777: step 1387, loss 1.34787, accuracy 0.625, precision [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, nan, 0.5, nan], recall [0.0, 1.0, nan, 0.42857142857142855, 0.75, 1.0, nan, 1.0, nan]
2019-02-19T18:08:20.475258: step 1388, loss 1.11083, accuracy 0.625, precision [0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, nan, nan, nan], recall [0.5, 1.0, 0.5, 0.4, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:20.632613: step 1389, loss 1.54943, accuracy 0.4375, precision [0.5, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.5, 1.0, 0.5, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:08:20.785945: step 1390, loss 1.13677, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, nan], recall [nan, 0.75, 1.0, 0.5, 1.0, 0.0, 0.5, nan, nan]
2019-02-19T18:08:20.945182: step 1391, loss 0.855954, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.6666666666666666, 0.8333333333333334, nan, nan, 0.0, nan], recall [0.0, 0.5, 0.5, 0.8, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:08:21.099249: step 1392, loss 0.819704, accuracy 0.625, precision [1.0, 0.75, 1.0, 0.3333333333333333, 0.5, nan, 0.0, 0.6666666666666666, 1.0], recall [0.5, 0.75, 0.5, 1.0, 1.0, 0.0, nan, 0.5, 1.0]
2019-02-19T18:08:21.255071: step 1393, loss 0.971546, accuracy 0.75, precision [nan, nan, 0.6666666666666666, 0.8571428571428571, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:21.406721: step 1394, loss 1.65043, accuracy 0.5, precision [0.0, 0.5, 0.3333333333333333, 0.25, 1.0, nan, nan, 1.0, 0.0], recall [nan, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0, 0.0, 0.0, 0.75, nan]
2019-02-19T18:08:21.564095: step 1395, loss 1.2961, accuracy 0.625, precision [1.0, 1.0, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan], recall [0.6666666666666666, 1.0, 0.0, 1.0, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:08:21.723190: step 1396, loss 1.07141, accuracy 0.625, precision [0.5, 0.5, nan, 0.5, 0.8, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 0.0, 0.4, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:08:21.874286: step 1397, loss 1.14164, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 0.3333333333333333, 1.0, nan, 1.0, nan]
2019-02-19T18:08:22.031086: step 1398, loss 1.18517, accuracy 0.625, precision [0.3333333333333333, nan, 0.75, 0.5714285714285714, 1.0, nan, nan, 1.0, nan], recall [1.0, nan, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:08:22.185495: step 1399, loss 1.30459, accuracy 0.625, precision [1.0, 0.3333333333333333, 0.0, 1.0, 0.75, nan, 0.5, nan, 0.0], recall [0.5, 1.0, 0.0, 0.5714285714285714, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:08:22.344311: step 1400, loss 1.0601, accuracy 0.5625, precision [0.5, 1.0, 1.0, 0.5, 0.75, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.3333333333333333, 1.0, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:08:22.499050: step 1401, loss 1.80086, accuracy 0.5625, precision [1.0, 0.5, nan, 0.5, 1.0, 1.0, nan, 0.0, 0.0], recall [0.4, 0.5, nan, 0.4, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:08:22.657485: step 1402, loss 1.1898, accuracy 0.5625, precision [nan, 0.5, 0.0, 0.7142857142857143, 0.3333333333333333, nan, 0.0, 1.0, nan], recall [0.0, 1.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:08:22.810121: step 1403, loss 1.94671, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.75, 1.0, 0.5, 0.0, 0.0, nan], recall [0.5, 0.0, nan, 0.5, 0.4, 1.0, nan, 0.0, nan]
2019-02-19T18:08:22.967955: step 1404, loss 1.14403, accuracy 0.6875, precision [1.0, 0.5, 0.0, 0.8333333333333334, 0.5, nan, 0.0, 1.0, nan], recall [0.75, 1.0, nan, 0.7142857142857143, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:08:23.121371: step 1405, loss 0.640313, accuracy 0.875, precision [1.0, 1.0, 0.0, 0.8, 1.0, nan, nan, nan, 1.0], recall [1.0, 1.0, nan, 1.0, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:08:23.281029: step 1406, loss 1.44591, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.75, 0.5, nan, nan, 0.6, nan], recall [0.3333333333333333, 0.0, 1.0, 0.6, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:08:23.439141: step 1407, loss 1.08992, accuracy 0.625, precision [0.7142857142857143, 0.0, nan, 0.75, nan, nan, 1.0, 0.5, nan], recall [0.7142857142857143, nan, nan, 0.5, 0.0, nan, 1.0, 1.0, nan]
2019-02-19T18:08:23.595216: step 1408, loss 1.28575, accuracy 0.5625, precision [1.0, 0.5, 0.25, 1.0, 0.75, 0.0, nan, 0.0, nan], recall [0.5, 1.0, 1.0, 0.3333333333333333, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:23.751545: step 1409, loss 1.91819, accuracy 0.5625, precision [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:08:23.907466: step 1410, loss 1.60747, accuracy 0.6875, precision [nan, 0.6, 0.3333333333333333, 1.0, 0.5, nan, nan, 1.0, nan], recall [nan, 0.75, 1.0, 0.625, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:24.061993: step 1411, loss 1.33024, accuracy 0.3125, precision [nan, 0.0, 0.5, 0.4, 0.5, nan, nan, 0.5, 0.0], recall [nan, nan, 0.3333333333333333, 0.2222222222222222, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:08:24.219534: step 1412, loss 1.56451, accuracy 0.5, precision [1.0, 0.5, 0.3333333333333333, 0.75, 0.5, 0.0, nan, 0.5, nan], recall [1.0, 0.5, 0.3333333333333333, 0.5, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:08:24.374242: step 1413, loss 1.92123, accuracy 0.5625, precision [0.6666666666666666, nan, nan, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.4, nan], recall [0.6666666666666666, 0.0, nan, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, nan]
2019-02-19T18:08:24.530223: step 1414, loss 0.909679, accuracy 0.625, precision [0.25, 1.0, 0.5, 1.0, 0.6, nan, nan, nan, nan], recall [1.0, 1.0, 0.3333333333333333, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:24.684770: step 1415, loss 1.63095, accuracy 0.375, precision [1.0, 0.0, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 0.0, 0.42857142857142855, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:08:24.843496: step 1416, loss 1.21159, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.8, 0.6, 0.0, nan, 0.5, nan], recall [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:08:24.999231: step 1417, loss 0.976119, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.6666666666666666, 0.75, 0.6666666666666666, 0.0, 1.0, nan, nan], recall [1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:08:25.157177: step 1418, loss 1.17727, accuracy 0.5625, precision [1.0, 0.5, nan, 0.5714285714285714, 0.6666666666666666, nan, 0.0, nan, nan], recall [1.0, 1.0, nan, 0.5714285714285714, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:08:25.316412: step 1419, loss 1.42834, accuracy 0.75, precision [nan, 0.0, nan, 0.8333333333333334, 1.0, 1.0, nan, 0.6666666666666666, nan], recall [0.0, nan, nan, 0.8333333333333334, 0.75, 1.0, nan, 0.6666666666666666, nan]
2019-02-19T18:08:25.475245: step 1420, loss 1.31648, accuracy 0.625, precision [1.0, 0.6666666666666666, nan, 0.5, 1.0, nan, 1.0, 0.5, nan], recall [1.0, 0.6666666666666666, 0.0, 1.0, 0.5, nan, 0.5, 0.5, nan]
2019-02-19T18:08:25.629595: step 1421, loss 1.31843, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.2, nan, 0.5, nan, 0.5, nan], recall [1.0, 0.0, 0.5, 1.0, nan, 0.3333333333333333, 0.0, 0.6666666666666666, nan]
2019-02-19T18:08:25.784769: step 1422, loss 0.907997, accuracy 0.625, precision [0.25, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, 1.0, 0.4, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:08:25.939854: step 1423, loss 1.36854, accuracy 0.625, precision [nan, 0.5, 1.0, 0.6, 0.8, nan, 0.0, 0.0, nan], recall [nan, 1.0, 0.5, 0.6, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:08:26.094185: step 1424, loss 2.47261, accuracy 0.5, precision [nan, 0.0, 0.0, 0.7, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 0.0, 1.0, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:08:26.246258: step 1425, loss 1.05641, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.4, 0.8, 1.0, nan, 1.0, nan], recall [0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:08:26.396777: step 1426, loss 1.21115, accuracy 0.5625, precision [0.75, 0.75, 1.0, 0.0, 1.0, nan, nan, 0.0, nan], recall [0.75, 0.5, 1.0, 0.0, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:08:26.553314: step 1427, loss 2.15121, accuracy 0.5, precision [0.0, 1.0, nan, 0.6, 0.5, 0.3333333333333333, nan, nan, nan], recall [nan, 0.5, nan, 0.6, 0.75, 1.0, 0.0, 0.0, 0.0]
2019-02-19T18:08:26.709546: step 1428, loss 1.93024, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.5714285714285714, 1.0, 0.0, 0.3333333333333333, 0.0, nan], recall [nan, 0.0, 1.0, 0.5714285714285714, 0.5, 0.0, 1.0, 0.0, nan]
2019-02-19T18:08:26.865308: step 1429, loss 1.8418, accuracy 0.5625, precision [0.75, 1.0, 0.5, 1.0, 0.3333333333333333, nan, 0.0, nan, 0.0], recall [1.0, 0.5, 1.0, 0.375, 0.5, nan, nan, nan, nan]
2019-02-19T18:08:27.016172: step 1430, loss 0.906918, accuracy 0.75, precision [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.5, nan, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:27.169545: step 1431, loss 1.24251, accuracy 0.625, precision [nan, 0.6666666666666666, nan, 0.8333333333333334, 0.5, 0.0, 1.0, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.7142857142857143, 1.0, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:08:27.326341: step 1432, loss 1.52584, accuracy 0.625, precision [1.0, 1.0, nan, 0.5, 1.0, nan, 0.0, 1.0, 0.0], recall [1.0, 0.6, 0.0, 0.6, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:27.479696: step 1433, loss 1.33594, accuracy 0.625, precision [1.0, 0.6, nan, 0.6666666666666666, nan, 0.0, 1.0, 1.0, 0.0], recall [1.0, 1.0, 0.0, 0.4, 0.0, nan, 1.0, 0.5, nan]
2019-02-19T18:08:27.638556: step 1434, loss 1.00526, accuracy 0.6875, precision [0.5, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, nan, 0.5, nan], recall [1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.5, nan, 0.5, nan]
2019-02-19T18:08:27.793958: step 1435, loss 1.3966, accuracy 0.4375, precision [0.5, 0.6666666666666666, nan, 0.4, 0.5, nan, 0.0, 0.0, nan], recall [1.0, 1.0, 0.0, 0.4, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:08:27.950406: step 1436, loss 1.17017, accuracy 0.5625, precision [0.3333333333333333, nan, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, nan], recall [1.0, 0.0, nan, 0.5, 0.6666666666666666, nan, 1.0, 1.0, nan]
2019-02-19T18:08:28.107039: step 1437, loss 0.612343, accuracy 0.6875, precision [0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, nan, nan, 0.0, nan], recall [0.6666666666666666, 0.5, nan, 0.75, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:28.265627: step 1438, loss 1.5859, accuracy 0.625, precision [nan, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.5, nan], recall [0.0, 0.8, nan, 0.4, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:08:28.423931: step 1439, loss 0.991865, accuracy 0.625, precision [0.0, 0.6, 0.0, 1.0, nan, nan, 1.0, 0.0, 0.0], recall [0.0, 0.75, nan, 0.8571428571428571, 0.0, 0.0, 0.5, nan, nan]
2019-02-19T18:08:28.584610: step 1440, loss 1.06188, accuracy 0.6875, precision [0.5, 0.75, nan, 1.0, 1.0, 1.0, nan, 0.0, 0.0], recall [1.0, 0.75, nan, 0.5714285714285714, 1.0, 1.0, nan, nan, 0.0]
2019-02-19T18:08:28.740147: step 1441, loss 1.46842, accuracy 0.4375, precision [1.0, 0.0, nan, 0.5, 0.8, nan, nan, 0.0, nan], recall [0.5, nan, nan, 0.4, 0.8, nan, 0.0, 0.0, 0.0]
2019-02-19T18:08:28.895244: step 1442, loss 0.746327, accuracy 0.75, precision [1.0, 0.0, 1.0, 0.8333333333333334, 1.0, nan, 1.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.5, nan, nan]
2019-02-19T18:08:29.049779: step 1443, loss 0.901993, accuracy 0.5625, precision [1.0, 0.75, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, nan, nan, 1.0], recall [1.0, 1.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]
2019-02-19T18:08:29.207662: step 1444, loss 1.10256, accuracy 0.5, precision [0.6666666666666666, nan, nan, 0.5714285714285714, 0.0, 0.0, 0.5, 0.5, nan], recall [1.0, 0.0, nan, 0.5, nan, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T18:08:29.364693: step 1445, loss 1.33512, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.6666666666666666, nan, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T18:08:29.522867: step 1446, loss 1.78966, accuracy 0.625, precision [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, nan, nan, 0.5, nan], recall [0.5, 0.3333333333333333, nan, 0.6666666666666666, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:29.673458: step 1447, loss 1.42086, accuracy 0.625, precision [1.0, 0.5, 0.0, 1.0, 1.0, nan, 0.5, 0.0, nan], recall [1.0, 0.5, nan, 0.5714285714285714, 0.75, nan, 1.0, nan, 0.0]
2019-02-19T18:08:29.824290: step 1448, loss 1.05688, accuracy 0.625, precision [nan, 0.0, 0.5, 1.0, 0.75, 1.0, 0.0, 0.5, nan], recall [0.0, nan, 1.0, 0.6666666666666666, 0.75, 0.5, nan, 0.5, nan]
2019-02-19T18:08:29.976444: step 1449, loss 1.10065, accuracy 0.5, precision [0.8, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.5, 0.0], recall [1.0, 0.0, nan, 0.4, 0.5, nan, 0.0, 0.5, nan]
2019-02-19T18:08:30.126836: step 1450, loss 1.85236, accuracy 0.4375, precision [1.0, 0.4, 0.5, 0.3333333333333333, 0.5, nan, nan, 0.0, nan], recall [0.5, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:08:30.280577: step 1451, loss 1.95782, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.5, 0.0, nan, nan], recall [0.5, 1.0, nan, 0.5, 0.5, 0.3333333333333333, 0.0, nan, nan]
2019-02-19T18:08:30.433794: step 1452, loss 0.996411, accuracy 0.75, precision [nan, 0.75, nan, 1.0, 0.8, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, nan, 1.0, 0.8, nan, 0.0, 1.0, nan]
2019-02-19T18:08:30.586293: step 1453, loss 0.945107, accuracy 0.6875, precision [nan, 0.5, 0.5, 0.8571428571428571, 1.0, nan, nan, nan, nan], recall [nan, 1.0, 0.5, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T18:08:30.740843: step 1454, loss 1.16909, accuracy 0.5625, precision [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.5, 1.0, 0.75, nan, nan, 0.0, 0.0]
2019-02-19T18:08:30.897504: step 1455, loss 1.18326, accuracy 0.625, precision [0.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, 1.0, 0.6666666666666666, nan], recall [nan, 0.3333333333333333, 0.0, 0.8, 0.6666666666666666, 0.0, 1.0, 1.0, nan]
2019-02-19T18:08:31.052503: step 1456, loss 0.796475, accuracy 0.8125, precision [nan, 1.0, 1.0, 0.75, 0.8, 0.0, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.6, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:08:31.209530: step 1457, loss 1.15083, accuracy 0.75, precision [nan, 1.0, 0.0, 1.0, 1.0, nan, 1.0, 0.8, nan], recall [nan, 1.0, nan, 0.5, 1.0, nan, 1.0, 0.6666666666666666, nan]
2019-02-19T18:08:31.363768: step 1458, loss 1.03462, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.375, 1.0, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.6, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:08:31.516804: step 1459, loss 1.48939, accuracy 0.4375, precision [1.0, 1.0, 0.0, 0.3333333333333333, 0.75, nan, 0.0, 0.0, nan], recall [0.5, 0.5, nan, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:08:31.672662: step 1460, loss 1.99876, accuracy 0.5625, precision [1.0, 0.5, nan, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.0, 0.5, 0.75, nan, nan, 0.6666666666666666, 0.0]
2019-02-19T18:08:31.828491: step 1461, loss 1.60992, accuracy 0.5625, precision [0.6666666666666666, 0.0, 0.0, 0.0, 0.7142857142857143, nan, nan, 1.0, nan], recall [1.0, 0.0, nan, nan, 1.0, nan, 0.0, 0.4, 0.0]
2019-02-19T18:08:31.983591: step 1462, loss 1.11423, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 1.0, nan, nan, nan], recall [nan, 0.14285714285714285, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:08:32.136798: step 1463, loss 0.492073, accuracy 0.875, precision [1.0, 1.0, nan, 1.0, 1.0, 1.0, nan, 0.3333333333333333, nan], recall [1.0, 0.6666666666666666, nan, 0.6666666666666666, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:08:32.294536: step 1464, loss 1.75543, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, nan, 0.0], recall [nan, 0.0, 0.5, 0.2, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:08:32.449693: step 1465, loss 0.8535, accuracy 0.75, precision [nan, 0.75, 1.0, 0.75, 0.8, nan, nan, 0.5, nan], recall [nan, 0.75, 0.5, 0.6, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:08:32.603650: step 1466, loss 1.67796, accuracy 0.5625, precision [0.0, 0.25, nan, 0.8, 0.0, nan, 1.0, 0.5, 1.0], recall [nan, 0.3333333333333333, 0.0, 0.5, nan, nan, 1.0, 1.0, 1.0]
2019-02-19T18:08:32.757910: step 1467, loss 1.47587, accuracy 0.5, precision [1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.6666666666666666, 0.0, 0.42857142857142855, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:08:32.916032: step 1468, loss 1.67457, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.3333333333333333, 0.8, nan, nan, 1.0, nan], recall [nan, 0.0, 0.5, 0.5, 0.6666666666666666, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:08:33.067289: step 1469, loss 1.81774, accuracy 0.6875, precision [0.5, 1.0, 1.0, 0.75, 0.0, nan, 0.5, nan, nan], recall [0.5, 0.8, 0.6666666666666666, 0.75, nan, nan, 1.0, nan, 0.0]
2019-02-19T18:08:33.219822: step 1470, loss 1.69479, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, nan, 0.0], recall [1.0, 1.0, 0.5, 0.6666666666666666, 0.5, nan, 0.6666666666666666, nan, nan]
2019-02-19T18:08:33.378454: step 1471, loss 1.37619, accuracy 0.5625, precision [0.5, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, 0.3333333333333333, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:08:33.537889: step 1472, loss 1.55318, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.25, 1.0, nan, 0.5, 1.0, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.25, 0.75, 0.0, 1.0, 1.0, nan]
2019-02-19T18:08:33.694734: step 1473, loss 0.817165, accuracy 0.8125, precision [0.3333333333333333, 1.0, nan, 0.8571428571428571, 1.0, nan, nan, 1.0, 1.0], recall [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, nan, nan, 1.0, 1.0]
2019-02-19T18:08:33.851255: step 1474, loss 0.914008, accuracy 0.8125, precision [1.0, 1.0, 1.0, 0.75, 1.0, 0.0, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:08:34.007026: step 1475, loss 1.53889, accuracy 0.5, precision [0.0, nan, nan, 0.25, 0.75, 0.0, nan, 1.0, nan], recall [nan, 0.0, 0.0, 1.0, 0.8571428571428571, nan, nan, 1.0, 0.0]
2019-02-19T18:08:34.161887: step 1476, loss 1.19896, accuracy 0.6875, precision [0.0, 1.0, 0.5, 0.6, nan, nan, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.5, 1.0, 0.0, nan, nan, 0.75, nan]
2019-02-19T18:08:34.314494: step 1477, loss 1.12882, accuracy 0.625, precision [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 1.0, nan, 0.6363636363636364, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:08:34.465406: step 1478, loss 0.873158, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.0, 1.0, 0.5, 0.75, nan, 0.0, nan, nan]
2019-02-19T18:08:34.614639: step 1479, loss 1.8317, accuracy 0.5625, precision [0.75, 1.0, nan, 0.3333333333333333, 0.8, nan, 0.0, 0.0, nan], recall [0.6, 1.0, nan, 0.25, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T18:08:34.767389: step 1480, loss 0.841572, accuracy 0.75, precision [1.0, 0.5, 1.0, 0.8333333333333334, 1.0, nan, 1.0, 0.3333333333333333, nan], recall [1.0, 0.5, 1.0, 0.7142857142857143, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:08:34.922018: step 1481, loss 1.81588, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.25, nan], recall [0.0, 1.0, nan, 0.42857142857142855, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T18:08:35.079474: step 1482, loss 1.09632, accuracy 0.5625, precision [0.5, 0.4, 1.0, 0.5, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, nan, 0.4, nan]
2019-02-19T18:08:35.238159: step 1483, loss 1.06073, accuracy 0.6875, precision [0.5, 1.0, 1.0, 0.75, 0.8, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.5, 0.75, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:08:35.394911: step 1484, loss 1.25755, accuracy 0.75, precision [1.0, 0.0, 1.0, 1.0, 0.6666666666666666, nan, 1.0, 1.0, nan], recall [1.0, nan, 1.0, 0.625, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:08:35.552752: step 1485, loss 1.51617, accuracy 0.625, precision [nan, 0.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.0, 0.0], recall [0.0, nan, 1.0, 0.6, 0.8333333333333334, 0.5, nan, 0.0, nan]
2019-02-19T18:08:35.709727: step 1486, loss 1.26404, accuracy 0.625, precision [1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [0.5, nan, 0.3333333333333333, 0.8, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:08:35.863741: step 1487, loss 1.05897, accuracy 0.5625, precision [0.0, 0.3333333333333333, nan, 0.5714285714285714, 1.0, nan, 1.0, 1.0, nan], recall [0.0, 0.5, nan, 0.6666666666666666, 0.3333333333333333, nan, 1.0, 1.0, nan]
2019-02-19T18:08:36.012312: step 1488, loss 1.17588, accuracy 0.625, precision [0.0, 0.0, 0.0, 0.8, 1.0, 1.0, nan, 0.0, nan], recall [nan, nan, nan, 0.5714285714285714, 1.0, 0.6666666666666666, nan, 0.0, nan]
2019-02-19T18:08:36.166097: step 1489, loss 1.15534, accuracy 0.625, precision [1.0, 0.3333333333333333, 0.5, 0.6666666666666666, nan, nan, nan, 0.6666666666666666, nan], recall [0.5, 1.0, 0.5, 0.8, 0.0, nan, nan, 1.0, nan]
2019-02-19T18:08:36.326093: step 1490, loss 0.812304, accuracy 0.6875, precision [1.0, 1.0, nan, 0.3333333333333333, 0.8, nan, nan, 0.3333333333333333, nan], recall [1.0, 1.0, nan, 0.25, 0.8, 0.0, nan, 1.0, nan]
2019-02-19T18:08:36.479668: step 1491, loss 1.89097, accuracy 0.5625, precision [0.6666666666666666, 0.3333333333333333, nan, 0.8, 0.5, 0.0, 1.0, nan, nan], recall [1.0, 0.5, 0.0, 0.8, 0.3333333333333333, nan, 1.0, 0.0, nan]
2019-02-19T18:08:36.637186: step 1492, loss 0.77873, accuracy 0.875, precision [nan, 0.5, nan, 1.0, 1.0, 1.0, 0.0, 1.0, nan], recall [nan, 1.0, nan, 0.8, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:08:36.791859: step 1493, loss 0.927419, accuracy 0.75, precision [nan, 0.5, 0.0, 1.0, 0.5, nan, 0.0, 1.0, nan], recall [nan, 0.5, nan, 0.7777777777777778, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:08:36.944253: step 1494, loss 1.36936, accuracy 0.5, precision [1.0, 0.25, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0], recall [1.0, 0.25, nan, 0.4, 1.0, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T18:08:37.100571: step 1495, loss 0.944057, accuracy 0.625, precision [0.5, nan, 0.0, 0.8, 1.0, nan, nan, 0.0, nan], recall [1.0, nan, nan, 0.5714285714285714, 0.7142857142857143, nan, 0.0, nan, nan]
2019-02-19T18:08:37.258071: step 1496, loss 0.966313, accuracy 0.5625, precision [1.0, 0.5, nan, 0.2, 1.0, 0.0, 1.0, 0.0, nan], recall [1.0, 0.5, nan, 0.25, 0.6666666666666666, 0.0, 1.0, nan, nan]
2019-02-19T18:08:37.415057: step 1497, loss 0.963355, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.7142857142857143, nan, 0.0, 1.0, 1.0, 0.0], recall [0.5, 0.3333333333333333, 1.0, 0.625, nan, nan, 1.0, 1.0, nan]
2019-02-19T18:08:37.571566: step 1498, loss 0.858401, accuracy 0.6875, precision [1.0, 0.0, 0.5, 1.0, 1.0, nan, 0.5, nan, nan], recall [0.5, nan, 1.0, 0.5714285714285714, 0.8, nan, 1.0, nan, nan]
2019-02-19T18:08:37.727816: step 1499, loss 1.04499, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.6, 0.75, nan, 0.0, 0.5, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.42857142857142855, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:08:37.889033: step 1500, loss 1.66132, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 1.0, nan], recall [nan, 0.14285714285714285, nan, 0.8, 1.0, nan, 1.0, 0.5, nan]

Evaluation:
[[ 46  13   0  15   0   0   0   8   0]
 [  8  84   3  49   3   1   1   7   0]
 [  1   6  46  34   1   0   2   4   0]
 [  3  32  22 216   1   4   4  17   1]
 [  1   9   3  17 134   2   3   3   1]
 [  4   6   1  36   0   9   2   2   0]
 [  1   3   0  13   1   2   9   0   1]
 [  1  14   0  30   0   0   1  58   1]
 [  1   1   0  19   1   0   0   1   2]]
2019-02-19T18:08:40.320983: step 1500, loss 1.23442, accuracy 0.589268, precision [0.5609756097560976, 0.5384615384615384, 0.48936170212765956, 0.72, 0.7745664739884393, 0.15, 0.3, 0.5523809523809524, 0.08], recall [0.696969696969697, 0.5, 0.6133333333333333, 0.5034965034965035, 0.950354609929078, 0.5, 0.4090909090909091, 0.58, 0.3333333333333333]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599466/checkpoints/model-1500

