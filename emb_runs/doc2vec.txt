Loading data...
{'sympathy_and_emotional_support': 0, 'not_related_or_irrelevant': 1, 'infrastructure_and_utilities_damage': 2, 'other_useful_information': 3, 'injured_or_dead_people': 4, 'caution_and_advice': 5, 'displaced_people_and_evacuations': 6, 'donation_needs_or_offers_or_volunteering_services': 7, 'missing_trapped_or_found_people': 8}
Max Document length: 2407
Vocabulary Size: 24319
Train/Dev split: 9226/1025
Writing to /home/ubuntu/Project/runs/1550599006

2019-02-19T17:57:31.160829: step 1, loss 9.50099, accuracy 0.1875, precision [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, nan, 0.0, 0.0], recall [0.25, 0.0, 0.2, 0.0, 0.5, nan, nan, nan, nan]
2019-02-19T17:57:31.344696: step 2, loss 7.74123, accuracy 0.25, precision [0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, nan, nan], recall [nan, 0.3, 1.0, 0.0, nan, 0.0, nan, 0.0, nan]
2019-02-19T17:57:31.503884: step 3, loss 9.21715, accuracy 0.25, precision [0.0, 0.75, 0.0, 0.0, 0.0, 0.5, nan, 0.0, nan], recall [nan, 0.2727272727272727, nan, 0.0, 0.0, 0.3333333333333333, nan, nan, nan]
2019-02-19T17:57:31.656925: step 4, loss 10.471, accuracy 0.0625, precision [0.0, nan, 0.0, 0.125, 0.0, nan, 0.0, 0.0, nan], recall [nan, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, nan, nan, 0.0]
2019-02-19T17:57:31.816413: step 5, loss 14.8593, accuracy 0, precision [0.0, 0.0, nan, 0.0, 0.0, nan, nan, 0.0, 0.0], recall [nan, 0.0, nan, 0.0, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:57:31.968908: step 6, loss 10.2874, accuracy 0.25, precision [0.0, 0.0, 1.0, 0.6, 0.0, 0.0, nan, 0.0, nan], recall [nan, nan, 0.3333333333333333, 0.42857142857142855, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:32.127948: step 7, loss 12.062, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, nan, 0.0, nan], recall [nan, nan, 0.0, 0.2222222222222222, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:32.285300: step 8, loss 8.82025, accuracy 0.1875, precision [0.0, 0.2, nan, 0.16666666666666666, 0.5, nan, nan, 0.0, nan], recall [nan, 1.0, 0.0, 0.2, 0.25, nan, 0.0, 0.0, nan]
2019-02-19T17:57:32.435636: step 9, loss 10.7519, accuracy 0.125, precision [nan, 0.0, 0.0, 0.3333333333333333, 0.2, 0.0, 0.0, 0.0, nan], recall [nan, nan, 0.0, 0.16666666666666666, 0.25, 0.0, 0.0, nan, 0.0]
2019-02-19T17:57:32.592497: step 10, loss 11.9442, accuracy 0.1875, precision [nan, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, nan, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:32.749479: step 11, loss 13.1045, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.5, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.5, 0.0, nan, nan, 0.0, 0.0]
2019-02-19T17:57:32.906480: step 12, loss 10.3365, accuracy 0.125, precision [nan, 0.0, 0.0, 0.0, 0.5, nan, nan, 0.0, 0.0], recall [0.0, nan, 0.0, 0.0, 0.4, nan, nan, nan, nan]
2019-02-19T17:57:33.061696: step 13, loss 9.46256, accuracy 0.25, precision [nan, 0.0, 0.5, 0.5, 1.0, nan, 0.0, 0.0, 0.0], recall [0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, nan, nan, 0.0, 0.0]
2019-02-19T17:57:33.218432: step 14, loss 6.7108, accuracy 0.25, precision [0.0, 0.0, 1.0, 0.5, 0.25, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 0.0, 0.3333333333333333, 0.2, 0.3333333333333333, 0.0, nan, 0.5, nan]
2019-02-19T17:57:33.375182: step 15, loss 7.40676, accuracy 0.0625, precision [0.0, 0.0, 0.0, 0.0, 0.2, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:33.534441: step 16, loss 10.416, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.2, 0.25, 0.0, 0.0, nan, 0.0], recall [0.0, 0.0, 0.0, 1.0, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:57:33.684543: step 17, loss 9.05555, accuracy 0.375, precision [0.0, 0.8, 0.0, 0.25, nan, 0.0, nan, 1.0, 0.0], recall [nan, 1.0, 0.0, 1.0, nan, 0.0, nan, 0.125, nan]
2019-02-19T17:57:33.843648: step 18, loss 10.3214, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.5, 0.0, 0.0, nan, nan, nan], recall [0.0, 0.0, nan, 0.6666666666666666, nan, nan, 0.0, 0.0, nan]
2019-02-19T17:57:33.999039: step 19, loss 6.86681, accuracy 0.25, precision [0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 0.0, nan, nan, nan, nan], recall [0.5, 0.25, 0.25, 0.5, nan, nan, 0.0, 0.0, nan]
2019-02-19T17:57:34.151786: step 20, loss 6.98042, accuracy 0.1875, precision [0.0, 1.0, 0.0, 0.16666666666666666, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.4, 0.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:34.308226: step 21, loss 7.67685, accuracy 0.25, precision [nan, 1.0, 0.25, 0.4, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.14285714285714285, 0.6666666666666666, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:34.463652: step 22, loss 8.56204, accuracy 0.25, precision [0.0, 1.0, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, nan, nan, nan, nan]
2019-02-19T17:57:34.621111: step 23, loss 5.78529, accuracy 0.5, precision [1.0, 0.5, nan, 0.3333333333333333, 0.75, 0.0, nan, 0.5, nan], recall [0.5, 0.3333333333333333, 0.0, 1.0, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T17:57:34.778512: step 24, loss 10.0612, accuracy 0.3125, precision [nan, 0.0, nan, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [nan, nan, nan, 0.36363636363636365, 0.25, nan, nan, 0.0, nan]
2019-02-19T17:57:34.928648: step 25, loss 7.32555, accuracy 0.4375, precision [0.0, 0.6, 0.0, 0.5714285714285714, nan, nan, nan, nan, nan], recall [nan, 0.75, 0.0, 0.5714285714285714, 0.0, nan, nan, nan, nan]
2019-02-19T17:57:35.084618: step 26, loss 7.71199, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.25, 0.5, nan, 0.0, 0.0, nan], recall [nan, 0.5, 1.0, 0.2, 0.2, nan, nan, nan, 0.0]
2019-02-19T17:57:35.240419: step 27, loss 5.90272, accuracy 0.5625, precision [nan, 0.2, 0.5, 1.0, 1.0, nan, 0.0, 0.0, nan], recall [nan, 1.0, 1.0, 0.46153846153846156, 1.0, nan, nan, nan, nan]
2019-02-19T17:57:35.394455: step 28, loss 6.74529, accuracy 0.3125, precision [nan, nan, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0], recall [nan, nan, 0.0, 0.375, 0.6666666666666666, 0.0, 0.0, nan, 0.0]
2019-02-19T17:57:35.543531: step 29, loss 12.8262, accuracy 0.1875, precision [0.0, nan, nan, 0.75, 0.0, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:57:35.696867: step 30, loss 6.19416, accuracy 0.4375, precision [0.0, 0.0, 0.0, 1.0, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.0, nan, 0.6, 0.5, 0.0, nan, nan, 0.0]
2019-02-19T17:57:35.851740: step 31, loss 6.94446, accuracy 0.1875, precision [0.0, 0.4, 0.0, 0.3333333333333333, 0.0, nan, 0.0, nan, nan], recall [0.0, 0.6666666666666666, 0.0, 0.25, 0.0, 0.0, nan, nan, 0.0]
2019-02-19T17:57:36.005442: step 32, loss 7.24831, accuracy 0.3125, precision [0.0, 0.0, nan, 0.5714285714285714, 0.5, nan, 0.0, nan, nan], recall [0.0, 0.0, 0.0, 0.8, 0.5, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:36.159654: step 33, loss 6.47365, accuracy 0.125, precision [0.0, 0.0, nan, 0.4, 0.0, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.5, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:36.315009: step 34, loss 3.59053, accuracy 0.4375, precision [0.0, 0.6666666666666666, nan, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T17:57:36.474346: step 35, loss 7.27674, accuracy 0.25, precision [0.25, 0.0, 0.5, 0.5, 0.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.0, 0.25, 0.6666666666666666, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:36.630591: step 36, loss 7.58099, accuracy 0.1875, precision [0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, nan, nan], recall [0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 0.0, 0.0]
2019-02-19T17:57:36.786251: step 37, loss 6.7398, accuracy 0.0625, precision [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.0, nan, 0.0, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:57:36.941875: step 38, loss 8.11545, accuracy 0.25, precision [nan, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, nan, 0.0, 0.5, 0.0], recall [0.0, 0.3333333333333333, 1.0, 0.5, 0.0, 0.0, 0.0, 0.25, nan]
2019-02-19T17:57:37.101896: step 39, loss 7.26831, accuracy 0.125, precision [0.5, 0.0, 0.0, 0.2, 0.0, 0.0, nan, 0.0, nan], recall [0.2, 0.0, nan, 0.25, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:37.255947: step 40, loss 5.64671, accuracy 0.0625, precision [0.0, 0.2, 0.0, 0.0, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.0, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:37.408996: step 41, loss 7.22972, accuracy 0.3125, precision [0.5, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0], recall [0.2, 0.25, nan, 1.0, 0.0, nan, nan, 0.4, nan]
2019-02-19T17:57:37.564852: step 42, loss 5.29365, accuracy 0.375, precision [0.5, 0.0, 0.5, 0.2, 0.5, nan, nan, nan, nan], recall [1.0, 0.0, 0.5, 1.0, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:57:37.725314: step 43, loss 5.34188, accuracy 0.1875, precision [nan, 0.5, 0.0, 0.2, 0.0, 0.0, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:37.880701: step 44, loss 5.83309, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.4, 0.25, nan, nan, 1.0, nan], recall [0.0, 0.2, 0.0, 0.5, 1.0, nan, nan, 0.25, nan]
2019-02-19T17:57:38.031076: step 45, loss 7.11154, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.6, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6, 0.3333333333333333, nan, 0.0, nan, nan]
2019-02-19T17:57:38.182903: step 46, loss 3.71632, accuracy 0.4375, precision [nan, 1.0, 0.25, 0.6, 0.0, 0.0, nan, 0.5, nan], recall [nan, 1.0, 1.0, 0.42857142857142855, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T17:57:38.339112: step 47, loss 6.67675, accuracy 0.125, precision [0.0, 0.3333333333333333, 0.25, 0.0, 0.0, nan, 0.0, nan, nan], recall [nan, 0.5, 1.0, 0.0, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:38.488988: step 48, loss 5.09604, accuracy 0.375, precision [nan, 0.0, 0.5, 0.5, 0.5, nan, 0.5, 0.0, nan], recall [nan, 0.0, 0.3333333333333333, 0.5, 0.25, nan, 0.5, nan, nan]
2019-02-19T17:57:38.640653: step 49, loss 3.41098, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.375, 0.75, nan, 0.0, nan, nan], recall [nan, 1.0, 0.16666666666666666, 0.6, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:38.794072: step 50, loss 7.49862, accuracy 0.25, precision [0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [0.0, 0.2, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:38.951259: step 51, loss 4.12231, accuracy 0.5, precision [0.0, 1.0, 0.5, nan, 0.4, nan, 0.0, 0.0, nan], recall [nan, 0.8333333333333334, 0.3333333333333333, 0.0, 1.0, nan, nan, nan, nan]
2019-02-19T17:57:39.103086: step 52, loss 10.2698, accuracy 0.25, precision [nan, nan, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, 0.25, 0.6666666666666666, 0.3333333333333333, nan, 0.0, 0.0, nan]
2019-02-19T17:57:39.260321: step 53, loss 7.96675, accuracy 0.25, precision [0.0, 1.0, 0.0, 0.25, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.2, 0.4, nan, 0.0, nan, nan]
2019-02-19T17:57:39.419408: step 54, loss 7.91699, accuracy 0.1875, precision [0.0, 0.0, 1.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:57:39.574196: step 55, loss 4.73207, accuracy 0.5, precision [0.0, 0.3333333333333333, 0.6666666666666666, 0.5, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 1.0, 0.5, 1.0, 0.4, nan, nan, 0.0, 0.0]
2019-02-19T17:57:39.730741: step 56, loss 6.53957, accuracy 0.1875, precision [0.0, nan, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.25, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:57:39.882108: step 57, loss 5.94108, accuracy 0.25, precision [nan, 0.0, 0.0, 0.5714285714285714, 0.0, nan, nan, 0.0, 0.0], recall [0.0, nan, 0.0, 0.5, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:40.033448: step 58, loss 4.15488, accuracy 0.5, precision [0.5, 0.0, 0.5, 0.7142857142857143, 0.3333333333333333, 0.0, nan, nan, nan], recall [1.0, 0.0, 0.25, 0.625, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:40.187317: step 59, loss 3.63438, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.7142857142857143, 1.0, nan, 0.0, 0.3333333333333333, 0.0], recall [0.3333333333333333, 0.0, 0.0, 0.8333333333333334, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:57:40.346165: step 60, loss 6.70065, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 1.0, nan, 0.5714285714285714, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:57:40.501332: step 61, loss 8.01635, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.8, 0.0, nan, nan, nan, nan], recall [0.0, 0.0, nan, 0.36363636363636365, nan, nan, nan, 0.0, nan]
2019-02-19T17:57:40.651622: step 62, loss 6.66489, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.8, nan, 0.0, 0.0, nan, nan], recall [nan, 0.0, nan, 0.36363636363636365, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:40.808734: step 63, loss 4.86606, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.6, 0.0, 0.0, nan, 0.0, nan], recall [nan, nan, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:40.971608: step 64, loss 6.06756, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.0, 0.6, 0.25, nan, nan, 0.0, 0.0], recall [0.0, 1.0, nan, 0.5, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:41.126118: step 65, loss 4.75382, accuracy 0.375, precision [0.0, 0.5, 1.0, 0.5, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 0.5, 0.5, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:41.278389: step 66, loss 5.80487, accuracy 0.25, precision [nan, 0.6666666666666666, nan, 0.2, 0.25, nan, 0.0, 0.0, 0.0], recall [0.0, 0.3333333333333333, nan, 0.3333333333333333, 0.5, 0.0, 0.0, nan, 0.0]
2019-02-19T17:57:41.427125: step 67, loss 4.58091, accuracy 0.375, precision [1.0, 0.5, nan, 0.25, 0.5, nan, nan, 0.0, nan], recall [0.25, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:41.584315: step 68, loss 5.1262, accuracy 0.25, precision [0.0, 0.5, 0.3333333333333333, 0.0, 0.5, nan, 0.0, nan, nan], recall [0.0, 0.3333333333333333, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:41.737910: step 69, loss 5.75347, accuracy 0.1875, precision [0.0, 1.0, 0.0, 0.25, nan, 0.0, nan, 0.0, nan], recall [0.0, 0.5, nan, 0.3333333333333333, 0.0, 0.0, 0.0, nan, 0.0]
2019-02-19T17:57:41.888660: step 70, loss 4.16612, accuracy 0.375, precision [0.5, 1.0, 0.0, 0.2, 0.0, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 0.4, 0.0, 0.5, nan, 0.0, nan, 0.5, nan]
2019-02-19T17:57:42.049582: step 71, loss 5.14184, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.6666666666666666, 0.25, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.0, 0.5, 0.5, 0.5, nan, 0.0, 0.5, 0.0]
2019-02-19T17:57:42.205231: step 72, loss 7.62073, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, nan, 0.6666666666666666, 0.25, 0.0, 0.0, 0.0, 0.0]
2019-02-19T17:57:42.360135: step 73, loss 4.76444, accuracy 0.3125, precision [nan, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [0.0, 0.5, 0.0, 0.0, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T17:57:42.516658: step 74, loss 6.3291, accuracy 0.25, precision [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, nan], recall [0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:57:42.672002: step 75, loss 5.48558, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.0, 0.75, nan, nan, 0.3333333333333333, nan], recall [nan, 0.0, 1.0, 0.0, 0.75, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:57:42.823761: step 76, loss 5.9998, accuracy 0.5, precision [0.5, 0.6666666666666666, nan, 1.0, 1.0, nan, 0.0, 0.0, 0.0], recall [1.0, 1.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:42.981209: step 77, loss 2.8381, accuracy 0.625, precision [nan, 0.0, 1.0, 0.7777777777777778, 0.3333333333333333, nan, nan, nan, nan], recall [0.0, 0.0, 0.5, 0.875, 0.5, nan, nan, nan, nan]
2019-02-19T17:57:43.129686: step 78, loss 3.2383, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.5, 0.0], recall [0.0, nan, 0.5, 0.6666666666666666, 0.75, 0.0, nan, 0.5, nan]
2019-02-19T17:57:43.280708: step 79, loss 5.33671, accuracy 0.25, precision [0.0, 0.0, nan, 0.42857142857142855, 0.25, nan, 0.0, 0.0, nan], recall [0.0, 0.0, nan, 0.6, 0.2, 0.0, nan, 0.0, nan]
2019-02-19T17:57:43.430077: step 80, loss 3.6119, accuracy 0.5625, precision [0.0, 0.3333333333333333, 1.0, 0.4, 0.8, nan, nan, 1.0, nan], recall [0.0, 1.0, 0.5, 0.4, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:57:43.589009: step 81, loss 4.95474, accuracy 0.375, precision [0.5, nan, 0.0, 0.375, 0.0, nan, 0.0, 1.0, nan], recall [1.0, 0.0, 0.0, 0.75, 0.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:57:43.743238: step 82, loss 3.13456, accuracy 0.3125, precision [1.0, 0.0, 0.3333333333333333, 0.6, 0.0, nan, nan, 0.0, 0.0], recall [0.5, 0.0, 0.2, 0.75, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:43.901736: step 83, loss 4.43227, accuracy 0.4375, precision [0.0, nan, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.5, nan], recall [nan, 0.0, 0.0, 0.5, 0.4, nan, nan, 1.0, nan]
2019-02-19T17:57:44.053863: step 84, loss 5.04536, accuracy 0.25, precision [0.3333333333333333, 0.0, 0.0, 0.4, 0.0, nan, nan, 0.5, nan], recall [0.5, 0.0, nan, 0.25, 0.0, nan, 0.0, 0.5, 0.0]
2019-02-19T17:57:44.205545: step 85, loss 6.50723, accuracy 0.3125, precision [0.0, nan, 0.5, 0.8, nan, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.0, 1.0, 0.4, 0.0, nan, nan, nan, 0.0]
2019-02-19T17:57:44.361105: step 86, loss 4.75314, accuracy 0.25, precision [0.0, 0.0, 0.5, 0.2857142857142857, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.5, 0.3333333333333333, nan, 0.0, 0.0, 0.0]
2019-02-19T17:57:44.517259: step 87, loss 7.79132, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.6, nan, nan, 0.0, 0.0, nan], recall [0.0, 0.0, nan, 0.6, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:44.674176: step 88, loss 4.43496, accuracy 0.5, precision [0.0, 0.0, 0.6666666666666666, 0.7142857142857143, 1.0, 0.0, nan, nan, nan], recall [nan, 0.0, 1.0, 0.45454545454545453, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:44.828535: step 89, loss 6.32125, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.75, 0.3333333333333333, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.3, 0.3333333333333333, nan, nan, nan, nan]
2019-02-19T17:57:44.984181: step 90, loss 4.62318, accuracy 0.375, precision [0.25, 1.0, 0.0, 0.4, 0.5, 0.0, nan, 0.5, nan], recall [1.0, 0.2, nan, 0.2857142857142857, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:57:45.140696: step 91, loss 6.78296, accuracy 0.375, precision [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, nan, nan, 0.25, nan], recall [0.3333333333333333, nan, 0.0, 0.5, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T17:57:45.298554: step 92, loss 6.12746, accuracy 0.1875, precision [0.6666666666666666, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, nan], recall [1.0, nan, 0.0, 0.14285714285714285, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T17:57:45.456140: step 93, loss 10.2134, accuracy 0.1875, precision [nan, 0.5, nan, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.5, 0.0, 1.0, nan, nan, 0.0, 0.0, 0.0]
2019-02-19T17:57:45.605811: step 94, loss 6.23594, accuracy 0.125, precision [1.0, nan, nan, 0.14285714285714285, 0.0, 0.0, nan, 0.0, nan], recall [0.2, 0.0, 0.0, 0.5, 0.0, nan, 0.0, nan, nan]
2019-02-19T17:57:45.759675: step 95, loss 6.51653, accuracy 0.3125, precision [1.0, 0.5, 1.0, 0.0, 0.4, 0.0, nan, 0.0, 0.0], recall [0.25, 0.5, 0.2, 0.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:45.917355: step 96, loss 5.24439, accuracy 0.1875, precision [0.3333333333333333, 0.0, 0.0, 0.14285714285714285, 0.0, nan, nan, 0.0, 1.0], recall [0.14285714285714285, 0.0, nan, 0.5, nan, 0.0, nan, 0.0, 1.0]
2019-02-19T17:57:46.074652: step 97, loss 5.04755, accuracy 0.25, precision [0.0, 0.4, nan, 0.2857142857142857, 0.0, 0.0, 0.0, nan, nan], recall [0.0, 1.0, 0.0, 0.5, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:46.231634: step 98, loss 2.90772, accuracy 0.625, precision [1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, nan, nan, nan], recall [1.0, nan, 1.0, 0.75, 0.6666666666666666, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:46.382081: step 99, loss 6.28457, accuracy 0.1875, precision [0.0, 0.25, 0.0, 0.3333333333333333, 0.25, 0.0, 0.0, nan, 0.0], recall [0.0, 1.0, 0.0, 0.2, 0.5, 0.0, 0.0, 0.0, 0.0]
2019-02-19T17:57:46.536074: step 100, loss 6.0074, accuracy 0.3125, precision [nan, 1.0, 0.2, 0.5, 0.5, 0.0, 0.0, nan, 0.0], recall [0.0, 0.3333333333333333, 0.5, 0.5, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:57:46.687468: step 101, loss 4.00275, accuracy 0.5, precision [nan, 0.5, 0.0, 0.75, 0.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:46.838837: step 102, loss 3.24932, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.5, 0.5, nan, 0.0, nan, nan], recall [nan, 0.5, nan, 0.42857142857142855, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:46.991957: step 103, loss 2.99792, accuracy 0.375, precision [0.0, 1.0, nan, 0.4, 0.75, 0.0, 0.0, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.6666666666666666, 0.42857142857142855, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:47.144640: step 104, loss 3.10348, accuracy 0.3125, precision [0.0, 0.5, 0.5, 0.16666666666666666, 1.0, nan, 0.0, 0.0, 0.0], recall [0.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, nan, nan, nan]
2019-02-19T17:57:47.300624: step 105, loss 4.40667, accuracy 0.125, precision [0.0, 0.5, 0.0, 0.0, 0.5, nan, 0.0, 0.0, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.0, 0.2, 0.0, nan, nan, nan]
2019-02-19T17:57:47.458084: step 106, loss 4.69412, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, nan, nan, 0.25, nan], recall [0.0, 0.0, nan, 0.25, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T17:57:47.614262: step 107, loss 4.87078, accuracy 0.125, precision [0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [0.0, 0.2, 0.0, 0.0, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T17:57:47.768387: step 108, loss 4.42326, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.6, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [nan, 0.2, 0.0, 0.375, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:57:47.921885: step 109, loss 3.58436, accuracy 0.5, precision [1.0, 0.25, 0.0, 0.8, 0.5, 0.0, nan, 0.5, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 0.3333333333333333, nan, nan, 0.5, 0.0]
2019-02-19T17:57:48.074497: step 110, loss 6.35458, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.25, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.0, 0.4, 0.3333333333333333, 0.4, nan, nan, 0.0, nan]
2019-02-19T17:57:48.227264: step 111, loss 3.58888, accuracy 0.3125, precision [0.5, 0.5, 0.0, 0.25, 0.0, nan, nan, nan, nan], recall [0.6666666666666666, 1.0, 0.0, 0.5, 0.0, nan, nan, 0.0, 0.0]
2019-02-19T17:57:48.381509: step 112, loss 3.01664, accuracy 0.5625, precision [nan, 0.6666666666666666, 0.5, 0.7142857142857143, 0.5, nan, nan, 0.0, nan], recall [0.0, 1.0, 1.0, 0.5555555555555556, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:57:48.532038: step 113, loss 4.75519, accuracy 0.375, precision [nan, 0.6666666666666666, nan, 0.5, 0.5, nan, 0.0, 0.2, nan], recall [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.5, 0.0]
2019-02-19T17:57:48.687588: step 114, loss 4.99928, accuracy 0.25, precision [0.0, 0.0, 0.25, 0.5, 0.0, nan, 0.0, 1.0, nan], recall [0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, nan]
2019-02-19T17:57:48.841846: step 115, loss 4.10643, accuracy 0.375, precision [0.6666666666666666, nan, 0.0, 0.4, 0.5, nan, 0.5, nan, nan], recall [0.6666666666666666, 0.0, 0.0, 0.4, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:57:48.994410: step 116, loss 5.84792, accuracy 0.1875, precision [0.0, 0.0, nan, 0.2, nan, 0.0, 0.0, 0.5, nan], recall [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, nan, 0.0, 0.4, 0.0]
2019-02-19T17:57:49.147857: step 117, loss 5.96729, accuracy 0.125, precision [0.0, 0.0, 0.0, 0.25, 0.25, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.0, 0.16666666666666666, 0.5, nan, 0.0, 0.0, 0.0]
2019-02-19T17:57:49.301129: step 118, loss 2.75596, accuracy 0.4375, precision [0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, nan, 0.0, nan, 0.3333333333333333, nan], recall [0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, nan, 0.5, nan]
2019-02-19T17:57:49.462384: step 119, loss 4.13849, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.6666666666666666, 0.75, nan, nan, 0.0, nan], recall [0.6666666666666666, nan, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:57:49.617416: step 120, loss 4.09731, accuracy 0.25, precision [0.0, 0.16666666666666666, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.25, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:49.766852: step 121, loss 5.37527, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.42857142857142855, 0.0, nan, nan, nan, 0.0], recall [0.0, 0.0, nan, 0.5, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:49.923421: step 122, loss 4.47635, accuracy 0.375, precision [0.0, 0.0, 0.5, 0.4, 0.5, 0.3333333333333333, nan, 0.5, nan], recall [0.0, nan, 1.0, 0.5, 0.25, 1.0, 0.0, 0.3333333333333333, nan]
2019-02-19T17:57:50.078960: step 123, loss 5.9919, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.4, nan, nan, nan, 0.5, nan], recall [0.0, 0.0, 0.0, 0.4, nan, nan, 0.0, 0.5, nan]
2019-02-19T17:57:50.228421: step 124, loss 5.19419, accuracy 0.25, precision [0.5, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, nan], recall [0.3333333333333333, 0.3333333333333333, 0.0, 0.4, 0.0, nan, nan, 0.0, 0.0]
2019-02-19T17:57:50.382094: step 125, loss 5.18832, accuracy 0.5, precision [0.5, 0.3333333333333333, 1.0, 0.5, 1.0, 0.0, nan, 1.0, 0.0], recall [0.5, 1.0, 0.25, 0.4, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T17:57:50.532120: step 126, loss 2.98223, accuracy 0.375, precision [1.0, 0.0, 0.0, 0.42857142857142855, 0.5, nan, nan, 0.0, nan], recall [1.0, 0.0, nan, 0.5, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T17:57:50.684377: step 127, loss 4.90666, accuracy 0.1875, precision [0.3333333333333333, 0.0, nan, 0.14285714285714285, 0.5, nan, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:57:50.838228: step 128, loss 2.82004, accuracy 0.375, precision [1.0, 0.0, nan, 0.42857142857142855, 0.5, 0.0, nan, 0.5, nan], recall [0.3333333333333333, 0.0, 0.0, 0.75, 1.0, 0.0, 0.0, 1.0, 0.0]
2019-02-19T17:57:50.991426: step 129, loss 4.00274, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.4, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.5, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:51.144723: step 130, loss 5.32101, accuracy 0.3125, precision [0.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.5, nan, 0.0, nan, 0.0, nan]
2019-02-19T17:57:51.303758: step 131, loss 3.63317, accuracy 0.375, precision [nan, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.6, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:57:51.454700: step 132, loss 5.39532, accuracy 0.375, precision [nan, 0.5, 0.0, 0.4, 0.6, nan, 0.0, 0.0, nan], recall [0.0, 0.25, nan, 0.4, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:51.612965: step 133, loss 2.21576, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T17:57:51.768192: step 134, loss 4.05739, accuracy 0.25, precision [0.5, nan, 0.5, 0.5, 0.3333333333333333, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.0, nan, nan, nan]
2019-02-19T17:57:51.924061: step 135, loss 4.96045, accuracy 0.1875, precision [0.3333333333333333, 0.0, 0.0, 0.4, 0.0, 0.0, nan, nan, nan], recall [1.0, 0.0, 0.0, 0.25, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:52.076529: step 136, loss 3.87484, accuracy 0.375, precision [0.0, 1.0, 0.0, 0.75, 0.25, 0.0, nan, 0.25, nan], recall [0.0, 0.3333333333333333, nan, 0.5, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T17:57:52.230002: step 137, loss 5.72549, accuracy 0.1875, precision [0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, nan, 0.0, nan], recall [0.2, nan, nan, 0.2222222222222222, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:57:52.384078: step 138, loss 3.60146, accuracy 0.3125, precision [0.0, 0.0, nan, 0.75, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [0.0, 0.0, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:52.537186: step 139, loss 6.91665, accuracy 0.125, precision [0.0, 0.0, nan, 0.0, 1.0, 0.0, 0.0, 0.2, nan], recall [0.0, 0.0, nan, 0.0, 0.2, nan, nan, 0.5, nan]
2019-02-19T17:57:52.690411: step 140, loss 4.02681, accuracy 0.25, precision [0.0, 0.25, nan, 0.4, 0.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 0.5, nan, 0.6666666666666666, 0.0, 0.0, nan, 0.5, nan]
2019-02-19T17:57:52.842491: step 141, loss 3.76746, accuracy 0.3125, precision [0.0, 0.0, 0.0, 1.0, 0.75, nan, nan, 0.3333333333333333, nan], recall [nan, 0.0, nan, 0.2, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:57:52.996284: step 142, loss 4.6083, accuracy 0.375, precision [1.0, 0.0, 1.0, 0.4, 1.0, 1.0, nan, 0.0, nan], recall [0.25, nan, 0.5, 0.5, 0.3333333333333333, 1.0, nan, 0.0, nan]
2019-02-19T17:57:53.154275: step 143, loss 4.46928, accuracy 0.25, precision [0.0, 1.0, nan, 0.0, 0.25, 0.3333333333333333, nan, 0.0, 0.0], recall [0.0, 0.5, 0.0, nan, 0.16666666666666666, 0.3333333333333333, nan, 0.0, nan]
2019-02-19T17:57:53.303752: step 144, loss 3.97953, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, nan, 0.0, 0.0], recall [0.25, nan, nan, 0.0, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:57:53.458184: step 145, loss 3.40266, accuracy 0.5, precision [0.5, 1.0, 0.5, 0.6, 0.25, nan, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 1.0, 0.25, nan, nan, 0.16666666666666666, nan]
2019-02-19T17:57:53.609660: step 146, loss 2.47925, accuracy 0.375, precision [1.0, 0.0, 1.0, 0.3333333333333333, 0.0, nan, nan, 0.5, nan], recall [1.0, 0.0, 1.0, 0.75, 0.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T17:57:53.768588: step 147, loss 3.44328, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0, nan], recall [nan, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, nan, 0.0, 0.2, nan]
2019-02-19T17:57:53.918257: step 148, loss 3.75406, accuracy 0.375, precision [0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 0.5, nan, 0.5, 0.0], recall [0.0, 0.2, 0.0, 0.6666666666666666, 0.5, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T17:57:54.072728: step 149, loss 3.41803, accuracy 0.3125, precision [nan, 1.0, 0.3333333333333333, 0.16666666666666666, 0.3333333333333333, 0.0, nan, 0.5, nan], recall [nan, 0.25, 1.0, 0.5, 0.5, nan, nan, 0.14285714285714285, nan]
2019-02-19T17:57:54.227335: step 150, loss 3.89083, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.6666666666666666, 0.75, 0.0, 0.0, 0.0, 1.0, nan], recall [0.0, 0.3333333333333333, 0.6666666666666666, 0.6, nan, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T17:57:54.379440: step 151, loss 5.24631, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.16666666666666666, 1.0, 0.0, 0.0, 1.0, nan], recall [nan, 0.16666666666666666, 0.5, 0.25, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:57:54.528736: step 152, loss 2.80362, accuracy 0.4375, precision [0.2, 0.25, 1.0, 0.6666666666666666, 0.5, nan, nan, 1.0, nan], recall [0.5, 0.5, 0.3333333333333333, 0.5, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:57:54.685036: step 153, loss 4.33094, accuracy 0.1875, precision [nan, 0.16666666666666666, 0.0, 0.5, 0.25, 0.0, nan, nan, nan], recall [nan, 0.5, nan, 0.1, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:57:54.838822: step 154, loss 3.35784, accuracy 0.5625, precision [nan, 0.25, 0.5, 1.0, 1.0, 0.0, 0.0, nan, nan], recall [nan, 0.5, 1.0, 0.625, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:57:54.994581: step 155, loss 5.37984, accuracy 0.3125, precision [nan, 1.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.5, nan], recall [nan, 0.5, 0.5, 0.25, nan, 0.0, 0.0, 1.0, 0.0]
2019-02-19T17:57:55.146830: step 156, loss 6.11881, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.4, 0.4, nan, nan, nan, 0.0]
2019-02-19T17:57:55.301748: step 157, loss 2.93137, accuracy 0.5, precision [0.0, 0.0, 0.3333333333333333, 0.8571428571428571, 0.3333333333333333, nan, nan, nan, 0.0], recall [nan, nan, 0.3333333333333333, 0.5454545454545454, 1.0, nan, nan, nan, 0.0]
2019-02-19T17:57:55.456226: step 158, loss 3.82935, accuracy 0.375, precision [1.0, 0.25, nan, 0.42857142857142855, 0.5, 0.0, nan, 0.0, nan], recall [0.5, 0.25, 0.0, 0.42857142857142855, 0.5, nan, nan, nan, nan]
2019-02-19T17:57:55.616153: step 159, loss 4.05895, accuracy 0.375, precision [0.0, 0.5, nan, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.2857142857142857, 1.0, nan, nan, nan, nan]
2019-02-19T17:57:55.766968: step 160, loss 5.32615, accuracy 0.375, precision [0.5, 0.2, 0.5, 0.4, 1.0, nan, 0.0, nan, nan], recall [0.2, 0.5, 0.25, 0.6666666666666666, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:57:55.916478: step 161, loss 4.19131, accuracy 0.25, precision [0.0, 0.0, 0.2, 0.2, 1.0, nan, 0.0, nan, nan], recall [0.0, 0.0, 0.3333333333333333, 0.25, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T17:57:56.065757: step 162, loss 4.70362, accuracy 0.375, precision [0.0, 0.0, nan, 0.5, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.0, nan, 1.0, 0.3333333333333333, 0.0, nan, nan, 0.0]
2019-02-19T17:57:56.220461: step 163, loss 3.28066, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.4, 0.5, 0.0, nan, nan, nan], recall [nan, 0.4, 0.0, 0.5, 0.25, 0.0, nan, nan, nan]
2019-02-19T17:57:56.375710: step 164, loss 3.96041, accuracy 0.5, precision [0.0, 1.0, nan, 0.0, 1.0, 0.5, 0.0, 0.0, nan], recall [nan, 0.5, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, nan, nan, nan]
2019-02-19T17:57:56.528097: step 165, loss 2.73828, accuracy 0.375, precision [nan, 0.0, 0.0, 0.625, 0.3333333333333333, nan, nan, 0.0, nan], recall [nan, 0.0, nan, 0.8333333333333334, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:57:56.684651: step 166, loss 3.11683, accuracy 0.375, precision [nan, 0.3333333333333333, 1.0, 0.4, 0.5, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T17:57:56.835902: step 167, loss 2.91824, accuracy 0.4375, precision [0.0, 0.0, 0.6666666666666666, 0.75, 0.0, 1.0, 0.0, 0.5, nan], recall [0.0, 0.0, 1.0, 0.5, nan, 1.0, 0.0, 0.5, nan]
2019-02-19T17:57:56.994334: step 168, loss 3.49839, accuracy 0.25, precision [0.0, 0.0, 0.0, 0.5, 0.6, 0.0, 0.0, nan, nan], recall [0.0, 0.0, nan, 0.2, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T17:57:57.153594: step 169, loss 2.24097, accuracy 0.5, precision [0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, nan], recall [nan, 0.4, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T17:57:57.309538: step 170, loss 2.53263, accuracy 0.375, precision [0.5, 0.6666666666666666, 0.0, 0.4, 0.5, 0.0, nan, 0.0, nan], recall [0.25, 0.6666666666666666, 0.0, 0.3333333333333333, 0.5, nan, nan, nan, nan]
2019-02-19T17:57:57.462320: step 171, loss 2.13499, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.5, 0.6, 0.2, nan, nan, nan, nan], recall [0.0, 0.5, 0.5, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:57.619118: step 172, loss 3.18679, accuracy 0.5, precision [nan, 1.0, 1.0, 0.42857142857142855, nan, 0.0, nan, 0.4, nan], recall [0.0, 0.6666666666666666, 1.0, 0.6, 0.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:57:57.770578: step 173, loss 3.00373, accuracy 0.375, precision [0.0, 0.25, 0.0, 0.6666666666666666, 0.4, 1.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.4, 0.6666666666666666, 1.0, nan, 0.0, nan]
2019-02-19T17:57:57.926801: step 174, loss 3.08655, accuracy 0.375, precision [nan, 0.5, 0.0, 0.5, 0.4, nan, nan, 0.0, nan], recall [nan, 0.5, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:57:58.082310: step 175, loss 4.05574, accuracy 0.125, precision [0.0, 0.3333333333333333, nan, 0.25, 0.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.16666666666666666, 0.0, 0.3333333333333333, 0.0, nan, 0.0, nan, nan]
2019-02-19T17:57:58.237793: step 176, loss 3.6925, accuracy 0.3125, precision [0.5, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 0.3333333333333333, nan, 0.0, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:57:58.393929: step 177, loss 2.64706, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.0, 0.4, 1.0, nan, 0.0, 0.0, nan], recall [0.25, 0.25, nan, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:58.546693: step 178, loss 2.10649, accuracy 0.5625, precision [0.0, nan, 1.0, 0.4, 1.0, 1.0, nan, 0.0, 0.0], recall [nan, nan, 1.0, 0.5, 0.8, 0.5, nan, 0.0, nan]
2019-02-19T17:57:58.699395: step 179, loss 2.54699, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.5555555555555556, nan, nan, 0.0, 0.0, nan], recall [nan, 0.2, 0.5, 1.0, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:57:58.853144: step 180, loss 4.5317, accuracy 0.25, precision [0.0, 0.0, 0.3333333333333333, 0.4, 0.5, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 0.5, 0.3333333333333333, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:57:59.007927: step 181, loss 4.4195, accuracy 0.3125, precision [0.0, 0.0, 0.25, 0.6666666666666666, 1.0, nan, nan, 0.5, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.4, 0.25, nan, nan, 0.5, nan]
2019-02-19T17:57:59.166058: step 182, loss 2.4393, accuracy 0.6875, precision [nan, nan, nan, 0.7, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 0.0, 1.0, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:57:59.320126: step 183, loss 3.91671, accuracy 0.3125, precision [0.5, nan, 0.0, 0.5, 0.4, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.2222222222222222, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:57:59.473485: step 184, loss 2.77438, accuracy 0.625, precision [0.0, 0.5, 1.0, 0.75, 0.5, 1.0, 0.0, nan, nan], recall [nan, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T17:57:59.625543: step 185, loss 4.16482, accuracy 0.25, precision [0.0, 0.0, 1.0, 0.25, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, nan, 0.3333333333333333, 0.125, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T17:57:59.775332: step 186, loss 2.6885, accuracy 0.4375, precision [nan, nan, 0.5, 0.42857142857142855, 0.5, 0.0, nan, nan, nan], recall [0.0, 0.0, 0.6666666666666666, 0.75, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:57:59.928957: step 187, loss 3.21997, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan], recall [nan, nan, 0.0, 0.6666666666666666, 0.25, 0.0, nan, nan, nan]
2019-02-19T17:58:00.080478: step 188, loss 3.05406, accuracy 0.375, precision [nan, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.3333333333333333, 0.0], recall [nan, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.25, nan]
2019-02-19T17:58:00.239610: step 189, loss 2.04162, accuracy 0.6875, precision [nan, 0.0, nan, 0.8571428571428571, 0.5, 0.0, nan, 1.0, nan], recall [nan, nan, 0.0, 0.75, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:58:00.390221: step 190, loss 1.92207, accuracy 0.4375, precision [1.0, 0.2, 0.0, 0.4, 0.0, nan, nan, 1.0, 1.0], recall [1.0, 0.5, 0.0, 0.4, nan, nan, nan, 0.5, 1.0]
2019-02-19T17:58:00.548224: step 191, loss 2.43613, accuracy 0.5625, precision [nan, 0.0, 0.5, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, nan], recall [0.0, nan, 0.5, 0.75, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T17:58:00.707059: step 192, loss 4.45119, accuracy 0.3125, precision [1.0, 0.0, nan, 0.3333333333333333, 0.0, 0.0, nan, 1.0, 0.0], recall [0.5, nan, 0.0, 0.5, 0.0, nan, 0.0, 0.4, 0.0]
2019-02-19T17:58:00.859732: step 193, loss 3.28475, accuracy 0.375, precision [1.0, 0.25, 0.0, 0.75, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 1.0, 0.0, 0.375, 0.2, nan, nan, nan, nan]
2019-02-19T17:58:01.009193: step 194, loss 3.89311, accuracy 0.375, precision [0.0, 0.75, 0.0, 0.25, 1.0, 0.0, nan, nan, nan], recall [nan, 0.6, nan, 0.25, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:58:01.163675: step 195, loss 1.56048, accuracy 0.625, precision [1.0, nan, 0.5, 0.8333333333333334, 0.5, nan, nan, nan, 0.0], recall [1.0, nan, 1.0, 0.625, 0.6666666666666666, 0.0, nan, nan, 0.0]
2019-02-19T17:58:01.312022: step 196, loss 3.69943, accuracy 0.25, precision [nan, 0.0, 0.0, 0.375, 0.5, nan, 0.0, nan, 0.0], recall [0.0, 0.0, nan, 0.5, 0.3333333333333333, nan, nan, 0.0, 0.0]
2019-02-19T17:58:01.463287: step 197, loss 2.60959, accuracy 0.4375, precision [nan, 0.14285714285714285, 1.0, 0.5, nan, nan, 0.0, 1.0, nan], recall [0.0, 0.3333333333333333, 0.3333333333333333, 0.5, nan, nan, nan, 0.6, nan]
2019-02-19T17:58:01.614239: step 198, loss 2.62571, accuracy 0.3125, precision [0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.0, 1.0, 1.0, nan, 0.2, 0.0]
2019-02-19T17:58:01.767781: step 199, loss 2.79438, accuracy 0.4375, precision [0.0, nan, 0.5, 0.6666666666666666, 0.4, nan, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.4444444444444444, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T17:58:01.922616: step 200, loss 1.97533, accuracy 0.5, precision [nan, 0.5, nan, 0.25, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.4, 0.0, 1.0, 0.8333333333333334, nan, nan, 0.0, nan]
2019-02-19T17:58:02.081469: step 201, loss 2.80768, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 0.5, nan], recall [nan, nan, 0.0, 0.5714285714285714, 0.5, nan, 0.0, 0.3333333333333333, 0.0]
2019-02-19T17:58:02.234734: step 202, loss 2.62073, accuracy 0.375, precision [0.0, 0.25, 1.0, 0.6666666666666666, 0.5, nan, 0.0, 0.0, 0.0], recall [nan, 0.3333333333333333, 0.5, 0.4, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:58:02.388695: step 203, loss 2.70266, accuracy 0.375, precision [nan, 0.0, nan, 0.3333333333333333, 0.6, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 1.0, 0.6, 0.0, 0.0, nan, 0.0]
2019-02-19T17:58:02.544168: step 204, loss 4.05359, accuracy 0.1875, precision [1.0, 0.0, 0.5, 0.16666666666666666, 0.0, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.25, 0.3333333333333333, 0.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:02.696147: step 205, loss 2.9125, accuracy 0.5, precision [nan, 0.3333333333333333, 0.3333333333333333, 0.8, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 0.5, 0.5, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:58:02.849471: step 206, loss 2.67745, accuracy 0.5, precision [nan, 1.0, 0.0, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.625, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T17:58:03.007932: step 207, loss 0.999455, accuracy 0.6875, precision [1.0, nan, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.0, 1.0, 0.8333333333333334, 0.8, nan, nan, nan, nan]
2019-02-19T17:58:03.161220: step 208, loss 3.64266, accuracy 0.375, precision [0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 0.2, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.4, 0.3333333333333333, 0.25, 1.0, nan, nan, nan, nan]
2019-02-19T17:58:03.312689: step 209, loss 5.38498, accuracy 0.1875, precision [0.3333333333333333, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.5, 0.3333333333333333, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:03.471641: step 210, loss 5.5043, accuracy 0.1875, precision [0.0, 1.0, 0.0, 0.2, nan, nan, 0.0, 0.0, 0.0], recall [0.0, 0.4, nan, 0.2, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:03.626903: step 211, loss 2.5821, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.42857142857142855, 0.0, nan, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.6, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:58:03.781324: step 212, loss 3.74742, accuracy 0.4375, precision [1.0, 0.0, nan, 0.6, 0.75, 0.0, 0.0, 0.0, 0.0], recall [0.2, 0.0, 0.0, 0.6, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:03.934295: step 213, loss 2.15512, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.5, 0.5, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 0.0, 0.75, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:58:04.087438: step 214, loss 2.72326, accuracy 0.375, precision [nan, 0.0, 0.0, 0.16666666666666666, 1.0, nan, 0.0, 1.0, 0.0], recall [0.0, 0.0, 0.0, 0.5, 0.8, nan, 0.0, 0.25, nan]
2019-02-19T17:58:04.241702: step 215, loss 3.14487, accuracy 0.3125, precision [0.5, 0.5, 0.0, 0.375, nan, nan, 0.0, 0.0, nan], recall [1.0, 0.3333333333333333, nan, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T17:58:04.396866: step 216, loss 2.11615, accuracy 0.3125, precision [0.0, nan, 0.0, 0.5555555555555556, 0.0, nan, nan, 0.0, nan], recall [nan, 0.0, nan, 0.5555555555555556, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:04.546187: step 217, loss 3.25857, accuracy 0.5, precision [nan, 0.5, 0.0, 0.8, 0.5, 0.0, 1.0, 0.0, 0.0], recall [nan, 1.0, 0.0, 0.4, 0.6666666666666666, nan, 1.0, nan, nan]
2019-02-19T17:58:04.700340: step 218, loss 2.47361, accuracy 0.25, precision [0.0, 0.2, 0.0, 0.42857142857142855, 0.0, nan, nan, nan, nan], recall [0.0, 0.5, nan, 0.6, nan, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:04.857280: step 219, loss 2.95678, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.5, 0.75, nan, 0.0, 0.0, 0.0], recall [nan, 0.0, nan, 0.2222222222222222, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:58:05.014932: step 220, loss 3.94133, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.8, 0.0, nan, nan, 0.3333333333333333, nan], recall [nan, 0.3333333333333333, 0.0, 0.4444444444444444, nan, nan, 0.0, 1.0, nan]
2019-02-19T17:58:05.167461: step 221, loss 4.15192, accuracy 0.3125, precision [nan, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0], recall [nan, 0.5, nan, 0.2222222222222222, 0.3333333333333333, nan, 1.0, nan, 0.0]
2019-02-19T17:58:05.320397: step 222, loss 4.74249, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.0, 0.75, nan, 0.0, nan, 0.0], recall [nan, 0.0, 0.0, 0.0, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:58:05.475602: step 223, loss 2.05556, accuracy 0.625, precision [0.0, 0.0, nan, 0.6666666666666666, 0.8333333333333334, 0.0, nan, nan, 1.0], recall [nan, 0.0, 0.0, 1.0, 1.0, nan, nan, 0.0, 0.5]
2019-02-19T17:58:05.629521: step 224, loss 3.00843, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.6, nan, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:05.780198: step 225, loss 2.22151, accuracy 0.4375, precision [1.0, 0.0, nan, 0.5, 0.5, nan, nan, 0.0, nan], recall [0.5, 0.0, nan, 0.7142857142857143, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T17:58:05.933574: step 226, loss 1.96, accuracy 0.5, precision [1.0, 1.0, nan, 0.5, 0.5, 0.0, 0.0, 0.5, nan], recall [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, nan]
2019-02-19T17:58:06.088992: step 227, loss 4.67511, accuracy 0.1875, precision [0.0, 0.5, 0.0, 0.2857142857142857, 0.0, nan, 0.0, nan, nan], recall [nan, 0.5, nan, 0.6666666666666666, 0.0, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:06.238080: step 228, loss 3.52182, accuracy 0.4375, precision [nan, 0.5, 0.4, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 0.5, 1.0, 0.3333333333333333, 0.3333333333333333, nan, nan, 0.4, nan]
2019-02-19T17:58:06.393830: step 229, loss 2.65411, accuracy 0.375, precision [0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, nan, nan], recall [0.3333333333333333, 0.6666666666666666, nan, 0.0, 0.3333333333333333, nan, 1.0, 0.0, nan]
2019-02-19T17:58:06.546100: step 230, loss 3.0474, accuracy 0.375, precision [0.5, 0.4, nan, 0.0, 1.0, 0.0, nan, nan, nan], recall [0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:06.698825: step 231, loss 3.29335, accuracy 0.25, precision [0.0, 0.0, nan, 0.375, 0.5, 0.0, nan, nan, 0.0], recall [0.0, nan, 0.0, 0.6, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T17:58:06.848874: step 232, loss 3.13785, accuracy 0.3125, precision [nan, 0.0, 0.6666666666666666, 0.5, nan, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.42857142857142855, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:58:07.003243: step 233, loss 4.55368, accuracy 0.125, precision [nan, 0.0, 1.0, 0.0, 0.25, nan, nan, 0.0, 0.0], recall [0.0, 0.0, 1.0, 0.0, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:58:07.154044: step 234, loss 1.91948, accuracy 0.375, precision [0.5, 1.0, 0.5, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0], recall [0.5, 0.5, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, nan, 1.0]
2019-02-19T17:58:07.313442: step 235, loss 2.34445, accuracy 0.4375, precision [0.3333333333333333, 1.0, 0.3333333333333333, 0.4, 1.0, nan, 0.0, nan, 0.0], recall [0.3333333333333333, 0.5, 1.0, 0.4, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:58:07.473252: step 236, loss 2.83732, accuracy 0.4375, precision [1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5, nan, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 0.3333333333333333, 0.5, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T17:58:07.626296: step 237, loss 3.22127, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.0, 0.5, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:58:07.781846: step 238, loss 2.59063, accuracy 0.375, precision [0.3333333333333333, 1.0, 1.0, 0.0, 0.5, nan, 0.3333333333333333, nan, nan], recall [1.0, 0.3333333333333333, 1.0, 0.0, 0.25, nan, 1.0, nan, nan]
2019-02-19T17:58:07.939514: step 239, loss 3.29789, accuracy 0.375, precision [0.0, 0.5, 0.5, 0.2, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.4, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T17:58:08.093038: step 240, loss 2.61626, accuracy 0.1875, precision [0.0, 0.0, nan, 0.25, 0.3333333333333333, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, nan, 0.0]
2019-02-19T17:58:08.245526: step 241, loss 2.96697, accuracy 0.3125, precision [0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.4, 0.5, 0.0, nan, nan, 0.0]
2019-02-19T17:58:08.397330: step 242, loss 2.28847, accuracy 0.5, precision [0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5, 0.0, nan, 1.0, nan], recall [0.5, 0.3333333333333333, 1.0, 0.25, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:58:08.555131: step 243, loss 1.81698, accuracy 0.375, precision [0.3333333333333333, 0.0, nan, 0.25, 1.0, nan, 0.0, 0.5, nan], recall [0.5, 0.0, nan, 0.25, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:58:08.708265: step 244, loss 2.81873, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.375, 0.75, nan, nan, nan, 0.0], recall [nan, 0.0, nan, 0.6, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:08.861028: step 245, loss 2.56605, accuracy 0.4375, precision [1.0, 0.0, nan, 0.6666666666666666, 0.4, nan, nan, 0.0, nan], recall [0.5, nan, nan, 0.5, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T17:58:09.010740: step 246, loss 3.57664, accuracy 0.25, precision [0.0, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.1111111111111111, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T17:58:09.164104: step 247, loss 2.3363, accuracy 0.4375, precision [0.25, 0.0, 0.5, 0.5, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [0.5, nan, 0.5, 0.4, 0.5, nan, 0.0, 0.5, nan]
2019-02-19T17:58:09.319383: step 248, loss 1.8255, accuracy 0.625, precision [0.6666666666666666, 0.3333333333333333, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.0, nan], recall [0.6666666666666666, 1.0, 0.5, 0.7142857142857143, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T17:58:09.472310: step 249, loss 3.17391, accuracy 0.375, precision [0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0], recall [0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T17:58:09.623490: step 250, loss 0.72526, accuracy 0.75, precision [1.0, nan, 0.5, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, nan], recall [0.5, nan, 0.5, 0.6666666666666666, 0.8333333333333334, nan, 1.0, 1.0, nan]

Evaluation:
[[ 52   8   1  23   1   0   0   6   0]
 [ 38  34   3  71   6   0   0   8   0]
 [  3   0  44  42   2   0   0   5   0]
 [ 36   4  27 208   8   0   1  29   0]
 [  6   0   3  30 113   1   0   6   0]
 [  9   0   2  40   1   0   0   3   0]
 [  2   0   4  16   3   0   5   3   0]
 [  9   1   2  45   2   0   0  42   0]
 [  1   0   1  10   0   0   0   5   0]]
2019-02-19T17:58:15.760314: step 250, loss 1.9754, accuracy 0.485854, precision [0.5714285714285714, 0.2125, 0.4583333333333333, 0.6645367412140575, 0.710691823899371, 0.0, 0.15151515151515152, 0.4158415841584158, 0.0], recall [0.3333333333333333, 0.723404255319149, 0.5057471264367817, 0.4288659793814433, 0.8308823529411765, 0.0, 0.8333333333333334, 0.3925233644859813, nan]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-250

2019-02-19T17:58:16.075790: step 251, loss 2.31977, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.4444444444444444, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 0.0, nan, 0.6666666666666666, 0.25, nan, 0.0, 0.5, nan]
2019-02-19T17:58:16.232323: step 252, loss 1.53281, accuracy 0.8125, precision [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 1.0, 0.8, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T17:58:16.389150: step 253, loss 2.7114, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.42857142857142855, 0.6666666666666666, 0.0, nan, nan, nan], recall [0.3333333333333333, 0.0, 0.0, 0.75, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:58:16.542817: step 254, loss 3.7994, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.6, 1.0, 0.0, nan, 0.25, 0.0], recall [nan, 0.0, 1.0, 0.375, 0.5, nan, 0.0, 0.5, 0.0]
2019-02-19T17:58:16.697050: step 255, loss 3.52231, accuracy 0.3125, precision [nan, 0.0, 0.2, 0.3333333333333333, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [nan, nan, 1.0, 0.1111111111111111, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:58:16.851561: step 256, loss 1.29578, accuracy 0.5625, precision [0.6666666666666666, nan, nan, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan], recall [0.4, nan, nan, 0.75, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:17.005782: step 257, loss 2.88079, accuracy 0.4375, precision [nan, 0.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, nan, 0.5, 0.5, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T17:58:17.157323: step 258, loss 2.19288, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.8333333333333334, 0.5, 0.0, nan, 0.5, nan], recall [0.0, nan, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:17.313981: step 259, loss 2.81147, accuracy 0.5625, precision [0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, nan, 0.375, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:17.468441: step 260, loss 3.55251, accuracy 0.375, precision [nan, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [0.0, nan, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T17:58:17.622570: step 261, loss 1.93017, accuracy 0.5, precision [nan, 0.6666666666666666, 0.5, 0.5, 0.5, nan, 0.0, 0.5, nan], recall [0.0, 0.6666666666666666, 1.0, 0.2, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:58:17.773700: step 262, loss 2.38386, accuracy 0.375, precision [0.5, 0.0, nan, 1.0, 0.0, 0.0, nan, nan, nan], recall [0.5, nan, 0.0, 0.5, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:17.927411: step 263, loss 2.56545, accuracy 0.625, precision [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan], recall [nan, 0.0, 0.5, 1.0, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:18.076522: step 264, loss 2.4923, accuracy 0.3125, precision [nan, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, nan], recall [0.0, nan, 0.5, 0.25, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:58:18.228302: step 265, loss 2.78994, accuracy 0.5, precision [nan, 0.3333333333333333, nan, 0.6, 0.75, nan, 0.0, 0.3333333333333333, nan], recall [nan, 0.3333333333333333, 0.0, 0.75, 0.75, 0.0, nan, 0.5, nan]
2019-02-19T17:58:18.386822: step 266, loss 0.857377, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 1.0, 1.0, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:58:18.537921: step 267, loss 2.7696, accuracy 0.25, precision [0.0, 0.3333333333333333, 0.3333333333333333, 0.2, 0.5, nan, nan, 0.0, 0.0], recall [0.0, 0.5, 0.5, 0.2, 0.3333333333333333, nan, nan, 0.0, 0.0]
2019-02-19T17:58:18.691557: step 268, loss 2.01307, accuracy 0.4375, precision [nan, 0.3333333333333333, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:58:18.845645: step 269, loss 2.59253, accuracy 0.4375, precision [0.5, 0.6666666666666666, 0.0, 0.25, 0.6666666666666666, 0.0, 1.0, 0.0, nan], recall [0.5, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, nan]
2019-02-19T17:58:18.999292: step 270, loss 3.12352, accuracy 0.4375, precision [0.0, 0.0, 0.5, 0.8, 0.0, nan, 0.0, 0.5, 0.0], recall [nan, 0.0, 0.5, 0.8, 0.0, nan, nan, 0.5, nan]
2019-02-19T17:58:19.150614: step 271, loss 3.36098, accuracy 0.5, precision [0.0, 0.6666666666666666, 1.0, 0.6, nan, 0.0, 0.5, 0.5, nan], recall [nan, 0.6666666666666666, 0.5, 0.6, 0.0, 0.0, 1.0, 0.5, nan]
2019-02-19T17:58:19.306031: step 272, loss 3.38533, accuracy 0.25, precision [nan, nan, 0.0, 0.125, 1.0, nan, 0.0, 0.0, 0.0], recall [0.0, nan, nan, 0.2, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:19.456136: step 273, loss 3.07576, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.25, 1.0, 0.5, nan, nan, nan], recall [1.0, 0.0, nan, 0.3333333333333333, 0.75, 0.5, nan, 0.0, nan]
2019-02-19T17:58:19.611931: step 274, loss 3.21341, accuracy 0.4375, precision [0.0, 0.6666666666666666, 1.0, 0.4, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.2857142857142857, 0.2, 1.0, 1.0, nan, nan, nan, nan]
2019-02-19T17:58:19.768416: step 275, loss 2.31137, accuracy 0.25, precision [0.0, 0.6666666666666666, nan, 0.4, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.2857142857142857, 0.0, 0.3333333333333333, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:58:19.919288: step 276, loss 3.11246, accuracy 0.3125, precision [0.5, nan, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, nan], recall [1.0, 0.0, nan, 0.3333333333333333, 0.0, 0.0, 1.0, nan, nan]
2019-02-19T17:58:20.075505: step 277, loss 2.44995, accuracy 0.5, precision [nan, 1.0, nan, 0.3, 0.75, 1.0, nan, nan, nan], recall [0.0, 0.5, nan, 0.75, 1.0, 0.5, 0.0, 0.0, nan]
2019-02-19T17:58:20.229356: step 278, loss 2.07693, accuracy 0.375, precision [0.3333333333333333, 1.0, nan, 0.5, 0.0, 0.0, 0.5, 0.0, nan], recall [0.5, 0.6, nan, 0.25, nan, 0.0, 0.5, nan, nan]
2019-02-19T17:58:20.381520: step 279, loss 3.0347, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.5, 0.6, nan, 1.0, nan, nan], recall [nan, nan, 0.0, 0.16666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0]
2019-02-19T17:58:20.535839: step 280, loss 1.6481, accuracy 0.375, precision [0.5, 0.0, 0.5, 0.25, 0.75, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.5, 0.25, 0.75, 0.0, 0.0, nan, nan]
2019-02-19T17:58:20.693270: step 281, loss 2.33284, accuracy 0.375, precision [nan, 0.3333333333333333, nan, 0.6, 0.5, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.6, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T17:58:20.845153: step 282, loss 2.20635, accuracy 0.3125, precision [0.0, 0.16666666666666666, 0.0, 0.8, 0.0, 0.0, nan, 0.0, nan], recall [nan, 1.0, nan, 0.4, nan, 0.0, 0.0, nan, 0.0]
2019-02-19T17:58:20.999321: step 283, loss 3.11521, accuracy 0.4375, precision [0.3333333333333333, 0.0, nan, 0.7142857142857143, 0.5, nan, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, nan, 0.7142857142857143, 0.5, nan, 0.0, nan, nan]
2019-02-19T17:58:21.155990: step 284, loss 1.66963, accuracy 0.625, precision [nan, 1.0, 0.6666666666666666, 0.625, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 1.0, 1.0, 0.8333333333333334, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:58:21.307234: step 285, loss 1.91519, accuracy 0.5, precision [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [0.5, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, nan, nan, 0.0]
2019-02-19T17:58:21.461054: step 286, loss 0.700951, accuracy 0.6875, precision [nan, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.0, nan, 1.0, nan], recall [nan, 0.5, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T17:58:21.617542: step 287, loss 1.95869, accuracy 0.5625, precision [0.0, 0.0, 0.0, 0.875, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [0.0, 0.0, nan, 0.7777777777777778, 0.6666666666666666, nan, 0.0, nan, nan]
2019-02-19T17:58:21.771968: step 288, loss 3.27191, accuracy 0.25, precision [0.0, 0.4, 0.5, 0.0, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.5, 1.0, 0.0, 0.5, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:21.923077: step 289, loss 2.87234, accuracy 0.3125, precision [1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 0.0, nan, 1.0, 0.0], recall [0.5, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:22.075828: step 290, loss 2.10384, accuracy 0.5625, precision [1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.0, nan, nan, nan], recall [0.5, 0.0, 0.5, 0.6, 0.8, nan, nan, nan, nan]
2019-02-19T17:58:22.232094: step 291, loss 3.23075, accuracy 0.3125, precision [0.0, 0.3333333333333333, nan, 0.6, 0.3333333333333333, nan, 0.0, 0.0, 0.0], recall [0.0, 1.0, 0.0, 0.5, 0.25, nan, nan, 0.0, nan]
2019-02-19T17:58:22.382398: step 292, loss 1.90462, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, nan, 1.0, nan], recall [nan, nan, 0.6666666666666666, 0.0, 0.75, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:22.534106: step 293, loss 2.91367, accuracy 0.25, precision [0.0, 0.0, nan, 0.6, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0], recall [0.0, nan, 0.0, 0.3333333333333333, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T17:58:22.690297: step 294, loss 3.30344, accuracy 0.375, precision [0.0, 0.4, 1.0, 0.25, 1.0, 0.0, nan, nan, 0.0], recall [0.0, 1.0, 0.3333333333333333, 0.25, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:58:22.846099: step 295, loss 3.11372, accuracy 0.3125, precision [0.0, 0.25, 0.0, 0.0, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.25, 0.0, 0.0, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T17:58:22.998585: step 296, loss 2.59304, accuracy 0.5625, precision [1.0, 0.25, 1.0, 0.75, 0.75, 0.0, nan, nan, 0.0], recall [1.0, 1.0, 0.5, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:58:23.150644: step 297, loss 1.68955, accuracy 0.5, precision [nan, 0.0, 1.0, 0.5714285714285714, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.5714285714285714, 0.5, nan, nan, 1.0, nan]
2019-02-19T17:58:23.301936: step 298, loss 1.78791, accuracy 0.375, precision [nan, nan, 1.0, 0.125, 0.8, nan, nan, 0.0, 0.0], recall [0.0, 0.0, 0.5, 1.0, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:23.455096: step 299, loss 2.31498, accuracy 0.5, precision [nan, 0.6, nan, 0.8, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.75, 0.0, 0.6666666666666666, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T17:58:23.611746: step 300, loss 2.37657, accuracy 0.5, precision [0.5, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, nan, nan, 0.0], recall [1.0, 0.6666666666666666, 1.0, 0.5, 0.0, nan, nan, nan, 0.0]
2019-02-19T17:58:23.767641: step 301, loss 1.99517, accuracy 0.4375, precision [1.0, 0.0, nan, 0.4, 0.8, 0.0, nan, 0.0, nan], recall [0.5, 0.0, 0.0, 0.4, 0.8, nan, nan, nan, nan]
2019-02-19T17:58:23.922497: step 302, loss 1.41494, accuracy 0.5, precision [0.0, nan, 1.0, 0.3333333333333333, 0.8, 0.0, nan, 1.0, nan], recall [0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:24.073657: step 303, loss 3.03784, accuracy 0.3125, precision [0.5, 0.0, 0.0, 0.75, 0.5, 0.0, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.6, 0.2, 0.0, nan, nan, nan]
2019-02-19T17:58:24.229233: step 304, loss 2.33515, accuracy 0.25, precision [0.0, 0.3333333333333333, nan, 0.25, 1.0, nan, nan, 0.0, nan], recall [nan, 0.25, 0.0, 0.4, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:58:24.384479: step 305, loss 1.59413, accuracy 0.625, precision [0.5, 0.5, 1.0, 0.8, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [1.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T17:58:24.542162: step 306, loss 3.07314, accuracy 0.375, precision [0.0, 0.0, 0.5, 0.3333333333333333, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.0, 1.0, 0.3333333333333333, 0.8, nan, nan, 0.0, 0.0]
2019-02-19T17:58:24.697394: step 307, loss 1.64816, accuracy 0.5, precision [nan, 0.0, 0.6666666666666666, 0.625, nan, 0.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.625, nan, nan, nan, 0.5, 0.0]
2019-02-19T17:58:24.850777: step 308, loss 2.16781, accuracy 0.5, precision [0.5, nan, 0.0, 0.6, 0.5, nan, 0.0, nan, nan], recall [1.0, 0.0, nan, 0.8571428571428571, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:25.005753: step 309, loss 3.17585, accuracy 0.3125, precision [0.3333333333333333, 0.0, 0.0, 0.4, 0.3333333333333333, nan, nan, 1.0, 0.0], recall [1.0, 0.0, nan, 0.3333333333333333, 0.3333333333333333, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:25.160363: step 310, loss 2.40579, accuracy 0.5, precision [0.5, 0.6666666666666666, 1.0, 0.6, nan, 0.0, nan, 0.5, 0.0], recall [1.0, 0.6666666666666666, 0.5, 0.5, 0.0, 0.0, nan, 1.0, nan]
2019-02-19T17:58:25.314395: step 311, loss 2.98055, accuracy 0.5, precision [0.5, nan, 0.6, 0.6666666666666666, 0.5, 0.0, nan, nan, nan], recall [0.6666666666666666, 0.0, 0.75, 0.4, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:58:25.471644: step 312, loss 3.33686, accuracy 0.25, precision [nan, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.2, nan], recall [0.0, 0.0, 0.0, 0.2, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:25.627866: step 313, loss 1.71372, accuracy 0.4375, precision [nan, 1.0, 0.0, 0.625, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.5555555555555556, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:58:25.782208: step 314, loss 2.17754, accuracy 0.625, precision [0.5, 0.0, 1.0, 1.0, 1.0, nan, nan, 0.5, 0.0], recall [0.5, nan, 1.0, 0.5555555555555556, 0.5, nan, nan, 1.0, nan]
2019-02-19T17:58:25.939848: step 315, loss 2.07036, accuracy 0.625, precision [0.6666666666666666, 0.2, 1.0, 1.0, 0.0, nan, nan, 1.0, nan], recall [0.5, 0.5, 1.0, 0.4, nan, nan, nan, 1.0, nan]
2019-02-19T17:58:26.095516: step 316, loss 2.02554, accuracy 0.375, precision [1.0, 0.0, nan, 0.5, 0.6666666666666666, nan, 0.0, 0.25, 0.0], recall [1.0, 0.0, 0.0, 0.2857142857142857, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T17:58:26.252510: step 317, loss 1.24652, accuracy 0.6875, precision [1.0, 0.0, 0.0, 0.75, 0.5, nan, nan, 1.0, nan], recall [1.0, 0.0, 0.0, 0.75, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:26.402316: step 318, loss 2.91585, accuracy 0.3125, precision [0.0, 0.5, 0.0, 0.25, 0.6, 0.0, nan, 0.0, nan], recall [nan, 0.5, 0.0, 0.16666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:26.556334: step 319, loss 1.79683, accuracy 0.4375, precision [0.0, nan, nan, 0.5, 0.5714285714285714, 0.5, 0.0, 1.0, nan], recall [0.0, 0.0, nan, 0.25, 1.0, 0.5, nan, 0.5, nan]
2019-02-19T17:58:26.708200: step 320, loss 2.04276, accuracy 0.3125, precision [nan, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [0.0, nan, 0.5, 0.25, 1.0, nan, nan, nan, 0.0]
2019-02-19T17:58:26.860801: step 321, loss 1.46766, accuracy 0.5625, precision [1.0, 0.5, nan, 0.5, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.3333333333333333, nan, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:58:27.012965: step 322, loss 2.8906, accuracy 0.25, precision [0.0, 0.0, 0.2, 1.0, 1.0, 0.0, nan, 0.0, 0.0], recall [0.0, 0.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:27.169871: step 323, loss 2.69552, accuracy 0.25, precision [nan, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.5, nan], recall [0.0, 0.0, 0.0, 0.25, 0.5, 0.0, nan, 0.5, 0.0]
2019-02-19T17:58:27.322006: step 324, loss 2.72228, accuracy 0.375, precision [nan, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0], recall [0.0, nan, 1.0, 0.16666666666666666, 0.0, nan, 1.0, 0.6666666666666666, 0.0]
2019-02-19T17:58:27.474442: step 325, loss 2.76363, accuracy 0.375, precision [nan, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:27.624513: step 326, loss 2.1003, accuracy 0.375, precision [0.5, 0.5, nan, 0.16666666666666666, 0.3333333333333333, nan, nan, 1.0, 0.0], recall [1.0, 0.25, nan, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:58:27.778687: step 327, loss 2.72027, accuracy 0.375, precision [1.0, 0.25, 0.5, 0.25, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [0.5, 1.0, 0.5, 0.3333333333333333, 0.3333333333333333, nan, nan, 0.25, 0.0]
2019-02-19T17:58:27.931999: step 328, loss 1.41348, accuracy 0.5625, precision [0.5, 0.3333333333333333, nan, 0.6666666666666666, 0.75, 0.0, nan, nan, nan], recall [0.5, 1.0, nan, 0.5, 0.75, nan, nan, 0.0, nan]
2019-02-19T17:58:28.088479: step 329, loss 2.43259, accuracy 0.4375, precision [0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.5, 0.0, nan, 1.0, nan], recall [0.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, nan, nan, 0.2, 0.0]
2019-02-19T17:58:28.246751: step 330, loss 2.19683, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.5, 0.75, 0.0, nan, 0.5, nan], recall [nan, 1.0, nan, 0.6666666666666666, 0.6, 0.0, 0.0, 0.5, 0.0]
2019-02-19T17:58:28.398663: step 331, loss 2.6266, accuracy 0.5625, precision [1.0, 1.0, nan, 0.4, 0.5, nan, 0.5, nan, 0.0], recall [0.6666666666666666, 0.6666666666666666, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, nan]
2019-02-19T17:58:28.554489: step 332, loss 2.20134, accuracy 0.5, precision [0.3333333333333333, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, nan], recall [1.0, 0.0, 1.0, 0.4, 0.0, 0.5, nan, 0.6, nan]
2019-02-19T17:58:28.705487: step 333, loss 2.26942, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.25, 0.75, 0.0, nan, 0.0, nan], recall [nan, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:58:28.859032: step 334, loss 2.80304, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.0, 0.8, 1.0, 0.3333333333333333, nan, 1.0, nan], recall [1.0, 0.3333333333333333, nan, 0.8, 0.2, 1.0, nan, 1.0, nan]
2019-02-19T17:58:29.016185: step 335, loss 2.66843, accuracy 0.375, precision [0.0, 0.25, nan, 0.5, 1.0, 0.0, 0.5, 0.0, nan], recall [nan, 1.0, 0.0, 0.5, 0.25, 0.0, 1.0, 0.0, 0.0]
2019-02-19T17:58:29.169242: step 336, loss 3.11318, accuracy 0.4375, precision [0.0, 0.5, 1.0, 0.5, 0.75, 0.0, nan, 0.0, 0.0], recall [nan, 0.5, 0.25, 0.5, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:29.322377: step 337, loss 2.1946, accuracy 0.375, precision [0.3333333333333333, 0.5, nan, 0.42857142857142855, 0.5, 0.0, nan, 0.0, nan], recall [1.0, 0.2, nan, 0.375, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:29.476175: step 338, loss 2.25487, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.375, 0.5, 1.0, nan, nan, nan]
2019-02-19T17:58:29.627408: step 339, loss 3.0663, accuracy 0.375, precision [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, nan, 0.5, 0.0], recall [0.2857142857142857, nan, 0.5, nan, 0.4, nan, 0.0, 1.0, nan]
2019-02-19T17:58:29.787369: step 340, loss 1.75897, accuracy 0.5, precision [nan, 0.25, 0.0, 0.8, 1.0, nan, nan, 0.0, nan], recall [nan, 0.25, nan, 0.5714285714285714, 0.6, nan, nan, nan, nan]
2019-02-19T17:58:29.943307: step 341, loss 2.30964, accuracy 0.5, precision [1.0, 0.75, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.5, 0.75, 0.5, 0.25, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T17:58:30.098662: step 342, loss 1.44826, accuracy 0.5625, precision [nan, 0.5, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, 0.5, 0.0], recall [0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:58:30.255742: step 343, loss 2.31525, accuracy 0.5, precision [0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, nan], recall [0.5, 0.0, nan, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:58:30.415768: step 344, loss 2.09368, accuracy 0.625, precision [0.0, 1.0, 0.0, 0.75, 0.5, 0.0, nan, nan, nan], recall [0.0, 0.6, nan, 0.75, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:58:30.568185: step 345, loss 1.42435, accuracy 0.4375, precision [nan, 0.2, 0.5, 0.75, 0.5, nan, 0.0, 0.5, nan], recall [0.0, 0.5, 0.5, 0.42857142857142855, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:58:30.722521: step 346, loss 3.40683, accuracy 0.25, precision [0.0, 0.0, 1.0, 0.6666666666666666, 0.25, nan, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:30.877030: step 347, loss 2.1772, accuracy 0.3125, precision [0.0, 0.5, nan, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.2857142857142857, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:58:31.030451: step 348, loss 3.09276, accuracy 0.375, precision [0.0, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0], recall [0.0, nan, 1.0, 0.25, 1.0, 0.0, 0.5, nan, nan]
2019-02-19T17:58:31.186695: step 349, loss 1.62315, accuracy 0.5, precision [1.0, 0.14285714285714285, 0.0, 1.0, 1.0, nan, nan, nan, 0.0], recall [0.5, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:31.337034: step 350, loss 2.97498, accuracy 0.375, precision [nan, 0.0, 1.0, 0.5, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.0, 0.3333333333333333, 0.4, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:31.490732: step 351, loss 2.10502, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.4, 0.3333333333333333, nan, nan, 0.0, nan], recall [nan, 0.0, nan, 0.3333333333333333, 0.25, 0.0, nan, 0.0, nan]
2019-02-19T17:58:31.639818: step 352, loss 2.68587, accuracy 0.4375, precision [1.0, 0.5, 0.5, 0.42857142857142855, nan, nan, 0.0, 0.0, nan], recall [0.2, 1.0, 1.0, 0.6, nan, 0.0, nan, 0.0, nan]
2019-02-19T17:58:31.795004: step 353, loss 2.11003, accuracy 0.375, precision [0.0, 0.2, 0.0, 0.6, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 0.3333333333333333, nan, 0.75, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:58:31.955222: step 354, loss 1.80551, accuracy 0.5625, precision [nan, 0.5, 0.6666666666666666, 0.6, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.5, 0.6666666666666666, 0.75, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:32.106295: step 355, loss 2.84479, accuracy 0.25, precision [nan, 0.0, 0.3333333333333333, 0.75, 0.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.375, nan, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:32.263281: step 356, loss 2.37627, accuracy 0.4375, precision [0.0, 1.0, 1.0, 0.5, 0.2, nan, 0.0, 0.5, nan], recall [0.0, 0.5, 0.3333333333333333, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:32.420206: step 357, loss 1.66783, accuracy 0.625, precision [nan, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0, nan, 1.0, 0.0, 1.0], recall [nan, 0.4, 0.25, 1.0, 1.0, nan, 1.0, nan, 1.0]
2019-02-19T17:58:32.577043: step 358, loss 2.12722, accuracy 0.5, precision [1.0, nan, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, nan, nan], recall [1.0, 0.0, 0.0, 0.8, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T17:58:32.733531: step 359, loss 2.9625, accuracy 0.3125, precision [1.0, 0.0, 0.5, 0.2, 1.0, nan, nan, 0.0, 0.0], recall [1.0, 0.0, 0.14285714285714285, 1.0, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:32.883675: step 360, loss 1.61432, accuracy 0.625, precision [0.0, 0.3333333333333333, 1.0, 0.7142857142857143, 1.0, nan, nan, 0.0, nan], recall [nan, 0.3333333333333333, 1.0, 0.7142857142857143, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T17:58:33.036272: step 361, loss 1.83786, accuracy 0.5, precision [nan, 0.5, nan, 0.25, 1.0, nan, nan, 0.4, nan], recall [0.0, 0.5, 0.0, 1.0, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:58:33.194424: step 362, loss 2.51097, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.75, 1.0, 0.0, nan, 1.0, nan], recall [nan, 0.0, 0.0, 0.75, 0.3333333333333333, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:33.351003: step 363, loss 2.13165, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.75, 0.5, 0.0, nan, 0.5, nan], recall [0.0, 0.3333333333333333, nan, 0.375, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:33.508376: step 364, loss 1.76526, accuracy 0.375, precision [nan, 0.6666666666666666, 0.0, 0.2857142857142857, 0.5, nan, 0.0, 1.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.4, 0.3333333333333333, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:33.666218: step 365, loss 1.92572, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, nan, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:33.820062: step 366, loss 2.28268, accuracy 0.375, precision [0.5, 1.0, nan, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [1.0, 0.2, 0.0, 0.5, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:58:33.978431: step 367, loss 2.07416, accuracy 0.4375, precision [0.0, nan, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.5, 0.0], recall [nan, 0.0, 0.0, 0.5714285714285714, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:58:34.138478: step 368, loss 2.19146, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.6, 1.0, 0.0, 0.0, nan, 0.0], recall [0.5, 0.0, 1.0, 0.42857142857142855, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:58:34.292099: step 369, loss 3.28158, accuracy 0.3125, precision [0.0, nan, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.0, nan, 0.0, 0.4444444444444444, 0.3333333333333333, nan, 0.0, nan, nan]
2019-02-19T17:58:34.445585: step 370, loss 1.89814, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.75, 0.5, 0.0, nan, nan, nan], recall [0.0, nan, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:58:34.604802: step 371, loss 1.89466, accuracy 0.5, precision [nan, 0.5, 1.0, 0.8, nan, 0.0, nan, 0.25, 0.0], recall [0.0, 0.6666666666666666, 0.5, 0.5, nan, nan, nan, 0.5, nan]
2019-02-19T17:58:34.759385: step 372, loss 3.14248, accuracy 0.375, precision [0.5, 1.0, 0.0, 0.6666666666666666, nan, 0.0, nan, 0.25, nan], recall [0.5, 0.6666666666666666, nan, 0.3333333333333333, 0.0, nan, 0.0, 0.5, nan]
2019-02-19T17:58:34.916360: step 373, loss 2.21835, accuracy 0.5, precision [0.3333333333333333, 0.0, 1.0, 0.8333333333333334, 1.0, nan, nan, nan, 0.0], recall [1.0, nan, 0.5, 0.625, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:35.069908: step 374, loss 2.55512, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.5714285714285714, 0.5, nan, nan, nan, nan], recall [0.0, nan, 1.0, 0.5714285714285714, 0.25, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:35.224122: step 375, loss 2.20064, accuracy 0.4375, precision [0.0, 0.3333333333333333, nan, 0.75, 0.6666666666666666, nan, 0.5, 0.0, nan], recall [0.0, 0.3333333333333333, nan, 0.5, 1.0, 0.0, 1.0, nan, 0.0]
2019-02-19T17:58:35.379058: step 376, loss 2.76493, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [0.0, nan, 1.0, 0.5, 0.5, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T17:58:35.534857: step 377, loss 1.49123, accuracy 0.5, precision [0.5, nan, 0.0, 0.7142857142857143, 1.0, nan, 0.0, 0.0, nan], recall [0.5, nan, nan, 0.5555555555555556, 0.5, nan, 0.0, nan, nan]
2019-02-19T17:58:35.692759: step 378, loss 1.62207, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.5714285714285714, 0.6666666666666666, 0.0, nan, nan, 0.0]
2019-02-19T17:58:35.850370: step 379, loss 2.17088, accuracy 0.5, precision [nan, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, nan, nan, nan, 0.0], recall [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:36.001300: step 380, loss 2.18586, accuracy 0.5, precision [0.5, 0.0, nan, 0.75, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, nan], recall [0.3333333333333333, nan, 0.0, 0.6, 1.0, 0.0, 1.0, 0.5, nan]
2019-02-19T17:58:36.158394: step 381, loss 1.9992, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.6, 1.0, nan, nan, 1.0, nan], recall [nan, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T17:58:36.316259: step 382, loss 2.00117, accuracy 0.4375, precision [0.5, 0.0, nan, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.6666666666666666, nan, nan, 0.3333333333333333, 1.0, 0.0, nan, 0.4, 0.0]
2019-02-19T17:58:36.474162: step 383, loss 2.57172, accuracy 0.5, precision [0.6666666666666666, 0.0, 0.5, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [0.4, nan, 1.0, 0.4, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T17:58:36.630534: step 384, loss 1.43303, accuracy 0.5625, precision [1.0, 1.0, 0.0, 0.5, 0.5, 0.0, nan, 0.0, nan], recall [1.0, 0.5714285714285714, nan, 0.6, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:58:36.781004: step 385, loss 1.63922, accuracy 0.5, precision [1.0, 1.0, nan, 0.5714285714285714, 0.25, 0.0, nan, 0.0, nan], recall [1.0, 0.3333333333333333, nan, 0.6666666666666666, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:58:36.934441: step 386, loss 1.89822, accuracy 0.4375, precision [nan, 0.8, nan, 0.4, 0.5, 0.0, 0.0, 0.0, nan], recall [nan, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:37.088153: step 387, loss 1.30087, accuracy 0.625, precision [0.25, 0.5, 1.0, 1.0, 0.8, nan, 1.0, nan, nan], recall [0.5, 0.5, 1.0, 0.25, 1.0, nan, 1.0, nan, nan]
2019-02-19T17:58:37.242351: step 388, loss 1.562, accuracy 0.625, precision [0.5, 0.5, 1.0, 0.8, 1.0, nan, 0.0, 0.0, nan], recall [0.5, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:37.396723: step 389, loss 2.64264, accuracy 0.1875, precision [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.5, 0.0], recall [0.0, 0.5, 0.0, 0.25, nan, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T17:58:37.549751: step 390, loss 1.88402, accuracy 0.375, precision [1.0, 0.0, 0.0, 0.5714285714285714, 0.5, 0.0, 0.0, nan, 0.0], recall [0.5, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:58:37.700855: step 391, loss 2.34568, accuracy 0.375, precision [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.5, nan], recall [0.3333333333333333, 0.0, nan, 0.42857142857142855, nan, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T17:58:37.854828: step 392, loss 2.42742, accuracy 0.375, precision [0.0, 0.5, 0.6666666666666666, 0.6, 0.0, nan, 0.0, 0.0, nan], recall [nan, 0.25, 0.6666666666666666, 0.6, 0.0, 0.0, nan, nan, 0.0]
2019-02-19T17:58:38.008040: step 393, loss 1.62848, accuracy 0.5, precision [0.5, 1.0, 1.0, 0.0, 0.5, 0.0, nan, 1.0, nan], recall [0.3333333333333333, 0.5714285714285714, 0.5, nan, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T17:58:38.165912: step 394, loss 2.35954, accuracy 0.3125, precision [0.0, nan, 1.0, 0.5, 0.25, 0.0, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.3333333333333333, 0.25, nan, nan, 0.0, nan]
2019-02-19T17:58:38.323658: step 395, loss 1.59564, accuracy 0.625, precision [0.75, 0.6666666666666666, 0.5, 0.75, 1.0, 0.0, nan, nan, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:38.477004: step 396, loss 2.37306, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.0, 0.4, 1.0, nan, nan, 0.5, nan], recall [nan, 0.5, nan, 0.4, 0.5, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:38.628585: step 397, loss 1.44487, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.2, 1.0, nan, 1.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T17:58:38.782130: step 398, loss 2.30495, accuracy 0.375, precision [nan, 0.0, 0.0, 0.0, 0.8571428571428571, nan, nan, 0.0, nan], recall [0.0, nan, nan, 0.0, 0.8571428571428571, nan, 0.0, nan, nan]
2019-02-19T17:58:38.934381: step 399, loss 2.40054, accuracy 0.5625, precision [1.0, 0.5, 0.5, 1.0, 1.0, nan, nan, 0.0, 0.0], recall [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.2857142857142857, nan, nan, nan, nan]
2019-02-19T17:58:39.086848: step 400, loss 1.67607, accuracy 0.5625, precision [0.0, 0.5, 0.0, 0.7142857142857143, 1.0, nan, nan, nan, nan], recall [0.0, 1.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, nan, nan]
2019-02-19T17:58:39.243644: step 401, loss 1.55453, accuracy 0.4375, precision [1.0, nan, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.5, nan, 1.0, 0.4, 0.5, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:39.397809: step 402, loss 3.3243, accuracy 0.3125, precision [0.5, 0.5, 0.5, 0.25, 0.5, 0.0, 0.0, 0.0, nan], recall [0.5, 0.5, 0.3333333333333333, 0.25, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T17:58:39.552777: step 403, loss 1.97876, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan], recall [0.25, 0.0, nan, 0.4, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T17:58:39.702821: step 404, loss 1.72736, accuracy 0.375, precision [0.5, 0.25, 1.0, 0.25, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 0.5, 0.25, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:58:39.861236: step 405, loss 1.63622, accuracy 0.6875, precision [0.3333333333333333, 0.5, nan, 0.8571428571428571, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:40.012788: step 406, loss 2.22609, accuracy 0.4375, precision [0.0, 0.0, nan, 0.8, 0.6666666666666666, nan, 0.0, 1.0, 0.0], recall [0.0, nan, nan, 0.4444444444444444, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T17:58:40.168647: step 407, loss 1.66004, accuracy 0.6875, precision [0.0, 1.0, 0.5, 0.625, 1.0, nan, 1.0, 1.0, nan], recall [nan, 1.0, 0.5, 1.0, 0.5, 0.0, 0.5, 0.6666666666666666, nan]
2019-02-19T17:58:40.327350: step 408, loss 2.03913, accuracy 0.375, precision [nan, 0.4, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.6666666666666666, nan, 0.2, 1.0, 0.0, 0.0, 0.3333333333333333, nan]
2019-02-19T17:58:40.479748: step 409, loss 2.13202, accuracy 0.375, precision [1.0, 0.25, nan, 0.42857142857142855, nan, nan, nan, 0.3333333333333333, 0.0], recall [0.3333333333333333, 0.5, 0.0, 0.42857142857142855, nan, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:40.634221: step 410, loss 2.97645, accuracy 0.4375, precision [1.0, 0.0, nan, 0.5, 0.75, 0.0, 0.0, nan, nan], recall [0.25, nan, 0.0, 0.75, 0.6, nan, nan, 0.0, nan]
2019-02-19T17:58:40.791096: step 411, loss 1.4354, accuracy 0.5625, precision [0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 1.0, 0.0], recall [nan, 0.5, nan, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:40.947059: step 412, loss 2.09428, accuracy 0.3125, precision [0.0, 0.0, nan, 0.4, 1.0, nan, 1.0, 0.25, nan], recall [0.0, 0.0, nan, 0.4, 0.5, 0.0, 1.0, 0.3333333333333333, nan]
2019-02-19T17:58:41.107689: step 413, loss 2.22228, accuracy 0.5, precision [0.0, 0.5, 1.0, 0.6666666666666666, nan, nan, 0.5, 0.5, nan], recall [nan, 1.0, 0.3333333333333333, 0.4, 0.0, nan, 1.0, 0.5, nan]
2019-02-19T17:58:41.260632: step 414, loss 1.39112, accuracy 0.4375, precision [0.0, 0.5, 1.0, 0.6, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.5, 0.3333333333333333, 0.42857142857142855, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:58:41.414752: step 415, loss 1.69017, accuracy 0.5, precision [nan, 0.0, 0.5, 0.75, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.0, 0.0, 1.0, 0.6, 0.5, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:58:41.565010: step 416, loss 0.976341, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 1.0, 0.6666666666666666, 1.0, nan, nan, nan, nan]
2019-02-19T17:58:41.713229: step 417, loss 1.61951, accuracy 0.625, precision [0.0, 1.0, nan, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [0.0, 0.5, 0.0, 0.8333333333333334, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:41.862000: step 418, loss 2.23741, accuracy 0.4375, precision [0.0, 0.5, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, nan, nan], recall [nan, 0.16666666666666666, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:42.019757: step 419, loss 1.73001, accuracy 0.625, precision [nan, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 0.4, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:58:42.171786: step 420, loss 2.57747, accuracy 0.4375, precision [0.0, 1.0, nan, 0.5, 0.6666666666666666, nan, 0.0, 1.0, 0.0], recall [nan, 0.6666666666666666, 0.0, 0.4, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T17:58:42.327063: step 421, loss 2.0527, accuracy 0.4375, precision [0.0, 0.3333333333333333, nan, 0.5, 0.6666666666666666, nan, 0.5, nan, nan], recall [0.0, 1.0, nan, 0.6, 1.0, 0.0, 0.5, 0.0, nan]
2019-02-19T17:58:42.480640: step 422, loss 2.05048, accuracy 0.375, precision [nan, 1.0, 0.0, 0.4, 0.5, nan, nan, 0.0, nan], recall [nan, 0.25, nan, 0.4, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:42.637351: step 423, loss 2.4538, accuracy 0.4375, precision [0.0, 0.6, nan, 0.4, 0.5, nan, 0.0, 1.0, 0.0], recall [0.0, 0.75, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T17:58:42.794090: step 424, loss 1.91211, accuracy 0.5, precision [0.0, 1.0, 0.5, 0.5, 0.5, nan, nan, 0.3333333333333333, nan], recall [0.0, 0.5, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:58:42.945510: step 425, loss 0.585513, accuracy 0.8125, precision [0.6666666666666666, 0.0, nan, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.6666666666666666, 0.0, nan, 1.0, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:58:43.107858: step 426, loss 1.74364, accuracy 0.5, precision [0.0, 0.6666666666666666, 0.0, 0.0, 1.0, nan, 0.5, 0.5, nan], recall [0.0, 0.6666666666666666, nan, 0.0, 0.6, 0.0, 1.0, 1.0, nan]
2019-02-19T17:58:43.265762: step 427, loss 1.23042, accuracy 0.5625, precision [0.0, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [nan, 0.6666666666666666, nan, 0.3333333333333333, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:43.419501: step 428, loss 1.82448, accuracy 0.4375, precision [nan, 0.0, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [0.0, nan, nan, 0.3333333333333333, 0.8333333333333334, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:43.573992: step 429, loss 1.70333, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, nan], recall [0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 0.0, 0.5, 1.0, nan]
2019-02-19T17:58:43.725538: step 430, loss 0.885375, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.4, 0.75, nan, nan, 0.6666666666666666, nan], recall [0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:58:43.878041: step 431, loss 1.92672, accuracy 0.5625, precision [0.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, nan, nan, 0.0, nan], recall [nan, 0.6666666666666666, nan, 0.5555555555555556, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:44.032183: step 432, loss 2.08073, accuracy 0.5, precision [1.0, 0.0, 0.5, 0.5, 0.6666666666666666, 0.0, 0.5, 1.0, nan], recall [1.0, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan, 1.0, 0.5, nan]
2019-02-19T17:58:44.184117: step 433, loss 1.99003, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.75, 0.0, 0.0, nan, 0.6666666666666666, nan], recall [0.0, 0.3333333333333333, 1.0, 0.6, nan, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T17:58:44.338700: step 434, loss 1.29133, accuracy 0.625, precision [0.5, 0.0, 1.0, 0.8571428571428571, 1.0, nan, nan, nan, nan], recall [0.5, nan, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:58:44.498363: step 435, loss 1.58444, accuracy 0.5, precision [0.0, 1.0, 0.3333333333333333, 0.5, 1.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.5, 0.6, 1.0, 0.0, 0.0, 0.5, 0.0]
2019-02-19T17:58:44.647334: step 436, loss 1.80532, accuracy 0.4375, precision [0.0, 0.25, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 0.5, 0.5, 0.42857142857142855, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:58:44.799901: step 437, loss 2.53715, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.4, 1.0, 0.0, nan, 0.5, 0.0], recall [nan, 0.0, 0.5, 0.3333333333333333, 0.5, nan, 0.0, 0.25, nan]
2019-02-19T17:58:44.954677: step 438, loss 1.85808, accuracy 0.5625, precision [1.0, 0.4, 1.0, 0.5, 0.75, nan, nan, 0.5, 0.0], recall [0.5, 0.5, 1.0, 0.5, 0.75, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:45.111483: step 439, loss 2.1093, accuracy 0.5, precision [nan, 0.5, 0.0, 0.6666666666666666, 0.8, nan, 1.0, 0.0, 0.0], recall [0.0, 0.5, nan, 0.4, 1.0, 0.0, 0.5, 0.0, nan]
2019-02-19T17:58:45.263657: step 440, loss 2.27449, accuracy 0.3125, precision [0.0, 0.25, nan, 0.0, 1.0, 1.0, nan, 0.5, nan], recall [0.0, 0.3333333333333333, 0.0, 0.0, 0.25, 1.0, nan, 1.0, nan]
2019-02-19T17:58:45.420046: step 441, loss 1.63055, accuracy 0.4375, precision [nan, 0.0, 0.25, 0.6666666666666666, 1.0, 0.0, nan, 0.5, 0.0], recall [nan, 0.0, 1.0, 0.5714285714285714, 0.25, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:45.574956: step 442, loss 1.966, accuracy 0.5625, precision [0.5, 1.0, 0.6666666666666666, 0.5, 0.6, 0.0, nan, 1.0, 0.0], recall [0.3333333333333333, 0.5, 0.5, 0.5, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:58:45.728331: step 443, loss 1.59118, accuracy 0.5625, precision [0.5, 0.0, 0.6666666666666666, 0.0, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 0.0, 0.6666666666666666, nan, 0.6666666666666666, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:45.881584: step 444, loss 1.44501, accuracy 0.625, precision [1.0, 0.0, 0.6666666666666666, 0.7142857142857143, 0.6666666666666666, 0.0, nan, nan, nan], recall [1.0, 0.0, 0.5, 0.8333333333333334, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:46.035106: step 445, loss 1.76067, accuracy 0.25, precision [nan, 0.5, 0.0, 0.0, 0.75, 0.0, nan, 0.0, nan], recall [0.0, 0.2, 0.0, nan, 0.75, nan, nan, 0.0, nan]
2019-02-19T17:58:46.185668: step 446, loss 1.99542, accuracy 0.5625, precision [1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0], recall [0.5, 1.0, 0.5, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, nan, nan]
2019-02-19T17:58:46.343516: step 447, loss 1.51332, accuracy 0.6875, precision [1.0, 0.6666666666666666, nan, 0.625, 1.0, 1.0, 0.0, nan, nan], recall [0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T17:58:46.496791: step 448, loss 2.00449, accuracy 0.375, precision [1.0, 0.0, nan, 0.5, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.5, 0.0, 0.0, 0.2, 0.8, nan, nan, nan, nan]
2019-02-19T17:58:46.650211: step 449, loss 1.37912, accuracy 0.625, precision [0.6666666666666666, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, nan, nan], recall [1.0, 0.3333333333333333, nan, 0.6666666666666666, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:58:46.802687: step 450, loss 1.8523, accuracy 0.5, precision [0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, nan, nan, 0.6666666666666666, nan], recall [0.0, 0.0, 1.0, 0.6, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T17:58:46.963058: step 451, loss 1.19048, accuracy 0.5625, precision [0.3333333333333333, 1.0, 0.0, 0.8333333333333334, 0.0, 0.0, nan, 0.5, nan], recall [1.0, 0.5, nan, 0.5555555555555556, nan, 0.0, nan, 1.0, nan]
2019-02-19T17:58:47.115419: step 452, loss 2.15603, accuracy 0.375, precision [0.0, 0.0, 0.5, 0.5, 0.6, 0.0, nan, 0.5, 0.0], recall [nan, nan, 1.0, 0.1111111111111111, 0.6, nan, nan, 1.0, nan]
2019-02-19T17:58:47.270568: step 453, loss 1.00047, accuracy 0.625, precision [0.25, nan, nan, 0.7142857142857143, 1.0, nan, nan, 0.5, nan], recall [1.0, 0.0, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:47.426807: step 454, loss 2.19418, accuracy 0.375, precision [0.5, 0.0, 0.0, 0.3333333333333333, 0.75, 0.0, nan, nan, nan], recall [0.4, 0.0, nan, 0.25, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:58:47.584247: step 455, loss 1.86675, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.6, 0.6666666666666666, 0.0, nan, nan, 1.0], recall [0.5, 0.5, 0.0, 0.375, 1.0, nan, nan, nan, 1.0]
2019-02-19T17:58:47.733838: step 456, loss 2.85736, accuracy 0.25, precision [0.0, nan, nan, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, nan, 0.5, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:58:47.886888: step 457, loss 2.42237, accuracy 0.3125, precision [nan, 0.0, nan, 0.375, 0.6666666666666666, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.0, 0.75, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:58:48.034637: step 458, loss 3.20528, accuracy 0.25, precision [1.0, 0.25, 0.0, 0.5, nan, nan, 0.0, 0.0, 0.0], recall [0.25, 0.6666666666666666, nan, 0.2, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:48.187415: step 459, loss 1.6851, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.25, 0.5, nan, 0.0, 0.5, nan], recall [0.0, 0.0, 1.0, 0.2, 0.6666666666666666, nan, nan, 1.0, 0.0]
2019-02-19T17:58:48.345608: step 460, loss 1.6007, accuracy 0.3125, precision [0.3333333333333333, 0.0, nan, 0.6, 0.2, nan, 0.0, nan, nan], recall [1.0, 0.0, nan, 0.375, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:58:48.500678: step 461, loss 2.07603, accuracy 0.5, precision [0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, nan], recall [nan, 0.8, 0.3333333333333333, 0.4, nan, 0.0, 1.0, 0.0, nan]
2019-02-19T17:58:48.653056: step 462, loss 2.95777, accuracy 0.3125, precision [0.0, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [0.0, 1.0, nan, 0.2857142857142857, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:58:48.811792: step 463, loss 2.24287, accuracy 0.5625, precision [0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 1.0, nan, 0.0], recall [nan, 0.6666666666666666, 1.0, 0.42857142857142855, 1.0, nan, 1.0, nan, 0.0]
2019-02-19T17:58:48.962868: step 464, loss 2.37037, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.5714285714285714, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, 0.5, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:58:49.117895: step 465, loss 0.986362, accuracy 0.75, precision [nan, 0.8571428571428571, nan, 0.75, 0.6666666666666666, nan, 0.0, 1.0, nan], recall [nan, 0.8571428571428571, nan, 1.0, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T17:58:49.271648: step 466, loss 2.45082, accuracy 0.4375, precision [nan, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.5, 1.0, 1.0, 0.0, nan, 0.0, 0.5, 0.0]
2019-02-19T17:58:49.425332: step 467, loss 2.3668, accuracy 0.3125, precision [0.0, nan, 0.5, 0.5, 1.0, nan, nan, 0.0, 0.0], recall [nan, 0.0, 0.25, 1.0, 0.3333333333333333, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:49.586223: step 468, loss 1.52414, accuracy 0.5, precision [0.5, 1.0, nan, 0.5, 0.5, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.0, 0.5, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T17:58:49.744475: step 469, loss 1.67736, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.6666666666666666, 0.75, 0.0, nan, 0.3333333333333333, nan], recall [0.0, nan, 0.5, 0.4, 0.6, 0.0, nan, 0.5, nan]
2019-02-19T17:58:49.901327: step 470, loss 1.87681, accuracy 0.4375, precision [nan, 0.75, 0.5, 0.25, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.0, 0.75, 0.5, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:50.054487: step 471, loss 1.77421, accuracy 0.375, precision [0.5, nan, 0.25, 0.2857142857142857, 1.0, nan, nan, 1.0, 0.0], recall [0.5, nan, 1.0, 0.4, 0.5, 0.0, nan, 0.25, nan]
2019-02-19T17:58:50.208923: step 472, loss 2.52566, accuracy 0.4375, precision [0.3333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:58:50.365687: step 473, loss 1.75883, accuracy 0.5, precision [0.5, 0.0, nan, 0.5, 1.0, 1.0, 1.0, 0.0, nan], recall [0.3333333333333333, 0.0, 0.0, 0.6, 0.6666666666666666, 1.0, 1.0, nan, nan]
2019-02-19T17:58:50.514408: step 474, loss 1.50969, accuracy 0.5, precision [0.0, 0.25, nan, 0.8333333333333334, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 1.0, nan, 0.625, 0.5, 0.0, 0.0, 1.0, nan]
2019-02-19T17:58:50.667062: step 475, loss 1.84096, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.75, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0], recall [0.0, 0.5, nan, 0.6, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T17:58:50.825754: step 476, loss 1.6779, accuracy 0.5, precision [nan, 0.5, 0.0, 0.5, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [0.0, 0.6666666666666666, 0.0, 0.5, 0.75, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:50.980805: step 477, loss 2.00924, accuracy 0.625, precision [0.0, 1.0, 0.6666666666666666, 0.8, 0.75, 0.0, nan, nan, nan], recall [nan, 0.3333333333333333, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:51.134595: step 478, loss 1.70823, accuracy 0.5625, precision [nan, 1.0, 0.6, 0.8, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.25, 0.75, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:51.290428: step 479, loss 1.56872, accuracy 0.5625, precision [0.5, 0.5, 1.0, 0.3333333333333333, 0.75, nan, nan, 1.0, nan], recall [0.5, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:51.442462: step 480, loss 2.50663, accuracy 0.5, precision [nan, 1.0, 1.0, 0.25, 0.5, nan, 0.0, 0.3333333333333333, 0.5], recall [nan, 0.25, 1.0, 0.2, 0.5, nan, nan, 1.0, 1.0]
2019-02-19T17:58:51.600011: step 481, loss 1.6373, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.75, 1.0, 0.0, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:58:51.757390: step 482, loss 1.6377, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.375, 0.5, nan, nan, 0.0, 1.0], recall [0.0, 0.25, 0.0, 0.6, 1.0, nan, 0.0, 0.0, 1.0]
2019-02-19T17:58:51.914898: step 483, loss 2.55991, accuracy 0.375, precision [0.3333333333333333, nan, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, nan], recall [1.0, 0.0, 0.3333333333333333, 0.3333333333333333, nan, nan, 1.0, 0.5, 0.0]
2019-02-19T17:58:52.072669: step 484, loss 1.51763, accuracy 0.5625, precision [1.0, 0.4, 0.0, 0.8, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.5, 0.6666666666666666, 0.0, 0.5714285714285714, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:58:52.229111: step 485, loss 1.74823, accuracy 0.5, precision [0.3333333333333333, 0.75, 1.0, 0.5, 0.5, nan, 0.0, 0.0, nan], recall [0.3333333333333333, 0.75, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0]
2019-02-19T17:58:52.380078: step 486, loss 1.94004, accuracy 0.5, precision [0.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, 0.0], recall [0.0, 1.0, 1.0, 0.6, 0.6666666666666666, 0.0, 0.0, 0.5, nan]
2019-02-19T17:58:52.533543: step 487, loss 1.78325, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.0, 0.5, 0.75, 0.0, nan, 0.3333333333333333, nan], recall [1.0, 0.5, 0.0, 0.16666666666666666, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:52.683500: step 488, loss 1.42128, accuracy 0.5625, precision [nan, 1.0, nan, 0.5, 0.3333333333333333, nan, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.8, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:52.837261: step 489, loss 1.8911, accuracy 0.5, precision [1.0, 1.0, 0.3333333333333333, 0.6, 0.5, 0.0, 0.0, 0.0, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:58:52.994223: step 490, loss 1.0788, accuracy 0.4375, precision [0.0, 0.5, 1.0, 0.2, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.25, 1.0, 0.3333333333333333, 0.8, nan, 0.0, 0.0, nan]
2019-02-19T17:58:53.150185: step 491, loss 1.06007, accuracy 0.625, precision [0.0, 1.0, 0.0, 0.8333333333333334, 0.5, nan, 1.0, 0.6666666666666666, 0.0], recall [nan, 0.5, 0.0, 0.7142857142857143, 0.3333333333333333, nan, 1.0, 1.0, nan]
2019-02-19T17:58:53.301681: step 492, loss 2.17224, accuracy 0.4375, precision [0.5, 0.0, 0.3333333333333333, 1.0, 1.0, nan, nan, 0.0, 0.0], recall [1.0, 0.0, 0.5, 0.2, 0.75, nan, nan, nan, nan]
2019-02-19T17:58:53.459224: step 493, loss 1.25366, accuracy 0.5625, precision [nan, 0.5, 0.3333333333333333, 0.5, 1.0, nan, nan, 1.0, nan], recall [nan, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, nan, nan, 1.0, nan]
2019-02-19T17:58:53.615582: step 494, loss 0.692043, accuracy 0.8125, precision [nan, nan, 0.3333333333333333, 1.0, 1.0, nan, 1.0, 0.0, nan], recall [nan, 0.0, 1.0, 0.7142857142857143, 1.0, nan, 1.0, nan, nan]
2019-02-19T17:58:53.766679: step 495, loss 2.24201, accuracy 0.4375, precision [0.0, 0.0, nan, 1.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0], recall [nan, 0.0, 0.0, 0.5, 0.3333333333333333, 1.0, nan, 0.5, nan]
2019-02-19T17:58:53.921241: step 496, loss 1.39531, accuracy 0.625, precision [0.25, 0.5, 1.0, 0.8333333333333334, 0.5, nan, nan, 1.0, nan], recall [1.0, 0.3333333333333333, 0.5, 0.625, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:54.074228: step 497, loss 1.54517, accuracy 0.5625, precision [0.0, 0.0, nan, 0.6666666666666666, 0.8333333333333334, nan, nan, 0.0, nan], recall [nan, nan, 0.0, 0.8, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:54.235222: step 498, loss 1.20617, accuracy 0.6875, precision [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [nan, 1.0, 1.0, 0.4444444444444444, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:54.390018: step 499, loss 1.19166, accuracy 0.5, precision [1.0, 0.25, 0.5, nan, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 1.0, 0.0, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T17:58:54.544890: step 500, loss 2.06525, accuracy 0.3125, precision [0.0, 0.0, 0.6666666666666666, 0.4, 0.5, 0.0, nan, nan, 0.0], recall [0.0, 0.0, 0.5, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]

Evaluation:
[[ 43  13   0  23   2   0   0   8   2]
 [  8  59   3  73   4   0   0  12   1]
 [  0   2  35  52   2   0   1   4   0]
 [  5  13  21 249   7   0   1  13   4]
 [  0   1   6  27 121   0   1   3   0]
 [  2   1   0  47   1   2   0   2   0]
 [  0   0   1  18   3   0  10   0   1]
 [  2   1   0  44   3   0   0  50   1]
 [  1   1   0  10   1   0   0   2   2]]
2019-02-19T17:58:56.953545: step 500, loss 1.43029, accuracy 0.557073, precision [0.4725274725274725, 0.36875, 0.3645833333333333, 0.7955271565495208, 0.7610062893081762, 0.03636363636363636, 0.30303030303030304, 0.49504950495049505, 0.11764705882352941], recall [0.7049180327868853, 0.6483516483516484, 0.5303030303030303, 0.4585635359116022, 0.8402777777777778, 1.0, 0.7692307692307693, 0.5319148936170213, 0.18181818181818182]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-500

2019-02-19T17:58:57.261617: step 501, loss 1.40862, accuracy 0.625, precision [nan, 0.5, nan, 1.0, 0.8333333333333334, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, 1.0, nan, 0.42857142857142855, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:57.411623: step 502, loss 1.93701, accuracy 0.5, precision [0.0, 0.3333333333333333, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, nan, 0.5555555555555556, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:58:57.569918: step 503, loss 1.09239, accuracy 0.6875, precision [0.75, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 0.8, 1.0, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T17:58:57.726993: step 504, loss 1.26572, accuracy 0.625, precision [1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.6666666666666666, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:57.883252: step 505, loss 1.71133, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.6666666666666666, 0.75, 0.0, 0.0, nan, nan], recall [0.5, nan, 1.0, 0.5714285714285714, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T17:58:58.035672: step 506, loss 1.19635, accuracy 0.625, precision [0.3333333333333333, 0.6666666666666666, nan, 0.6666666666666666, 1.0, nan, nan, nan, 0.0], recall [1.0, 0.6666666666666666, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:58:58.189151: step 507, loss 2.44468, accuracy 0.375, precision [nan, 0.2, nan, 1.0, 0.4, 0.0, 0.0, 1.0, nan], recall [0.0, 1.0, 0.0, 0.2857142857142857, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T17:58:58.348240: step 508, loss 2.08598, accuracy 0.5, precision [0.5, 0.0, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.5, 0.0], recall [1.0, 0.0, 1.0, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T17:58:58.503280: step 509, loss 1.27741, accuracy 0.6875, precision [0.3333333333333333, 0.0, 0.5, 0.8333333333333334, 1.0, nan, nan, 1.0, nan], recall [0.5, 0.0, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:58:58.657453: step 510, loss 2.51347, accuracy 0.3125, precision [1.0, 0.3333333333333333, 0.0, 0.0, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.0, 0.0, 0.75, nan, nan, 0.0, nan]
2019-02-19T17:58:58.809906: step 511, loss 2.54998, accuracy 0.375, precision [0.5, 0.5, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666], recall [0.3333333333333333, 1.0, nan, 0.14285714285714285, 0.5, 0.0, nan, nan, 1.0]
2019-02-19T17:58:58.965864: step 512, loss 1.91226, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.4444444444444444, 1.0, nan, nan, 1.0, 0.0], recall [0.5, 0.0, 0.0, 0.8, 0.5, 0.0, nan, 0.5, 0.0]
2019-02-19T17:58:59.120183: step 513, loss 1.65576, accuracy 0.625, precision [nan, 0.6666666666666666, 0.5, 0.8, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 0.8, 1.0, 0.5714285714285714, 0.5, nan, nan, nan, nan]
2019-02-19T17:58:59.273123: step 514, loss 1.67222, accuracy 0.4375, precision [0.5, 0.5, 0.0, 0.5, 0.6666666666666666, 0.0, nan, nan, 0.0], recall [0.3333333333333333, 1.0, 0.0, 0.4, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:58:59.427366: step 515, loss 1.61108, accuracy 0.5, precision [0.6666666666666666, 0.5, nan, 0.6666666666666666, 0.5, 0.0, nan, 0.3333333333333333, nan], recall [0.6666666666666666, 0.6666666666666666, 0.0, 0.2857142857142857, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:58:59.584793: step 516, loss 1.62822, accuracy 0.375, precision [0.6666666666666666, 0.5, 0.0, 0.14285714285714285, 1.0, nan, nan, nan, nan], recall [0.6666666666666666, 0.16666666666666666, nan, 0.5, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:58:59.738384: step 517, loss 2.52957, accuracy 0.375, precision [0.5, nan, 0.0, 0.5, 1.0, nan, 0.0, 0.5, 0.0], recall [0.5, 0.0, nan, 0.2857142857142857, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:58:59.901160: step 518, loss 1.89075, accuracy 0.4375, precision [0.0, 1.0, 0.0, 0.6, 1.0, 0.0, nan, 0.5, 0.0], recall [nan, 0.5, nan, 0.42857142857142855, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T17:59:00.059423: step 519, loss 1.56298, accuracy 0.6875, precision [0.75, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 1.0, 0.6, 0.6666666666666666, nan, nan, nan, 0.0]
2019-02-19T17:59:00.214266: step 520, loss 1.55731, accuracy 0.5, precision [1.0, 0.25, 1.0, 0.625, 0.0, nan, 0.0, nan, nan], recall [1.0, 0.5, 0.5, 0.625, 0.0, nan, nan, 0.0, 0.0]
2019-02-19T17:59:00.366879: step 521, loss 1.94382, accuracy 0.375, precision [0.6666666666666666, 0.0, 0.0, 0.75, 0.5, 0.0, 0.0, 0.0, nan], recall [0.6666666666666666, 0.0, 0.0, 0.75, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:59:00.525414: step 522, loss 2.10942, accuracy 0.375, precision [0.0, 0.3333333333333333, 0.0, 0.4, 0.6666666666666666, 0.0, nan, nan, 0.5], recall [0.0, 0.2, nan, 0.6666666666666666, 0.5, nan, nan, 0.0, 0.5]
2019-02-19T17:59:00.686213: step 523, loss 2.05493, accuracy 0.375, precision [0.0, 0.6666666666666666, nan, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.4, 0.5, 0.0, nan, nan, 0.0]
2019-02-19T17:59:00.842889: step 524, loss 1.58313, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.4, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:00.997180: step 525, loss 1.08652, accuracy 0.5625, precision [0.6666666666666666, 0.5, 0.5, 0.42857142857142855, 1.0, nan, nan, nan, nan], recall [0.6666666666666666, 0.2, 1.0, 1.0, 0.5, nan, nan, nan, nan]
2019-02-19T17:59:01.153396: step 526, loss 1.36314, accuracy 0.5, precision [nan, 0.75, nan, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.75, 0.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:59:01.307568: step 527, loss 1.66896, accuracy 0.5, precision [1.0, nan, 0.5, 0.625, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 0.0, 0.3333333333333333, 0.7142857142857143, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:01.465151: step 528, loss 1.46386, accuracy 0.625, precision [1.0, 0.6, 0.0, 0.6, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.3333333333333333, 0.75, nan, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:01.619124: step 529, loss 1.44568, accuracy 0.625, precision [1.0, 0.0, 0.3333333333333333, 0.7142857142857143, 1.0, nan, nan, 1.0, nan], recall [0.5, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:59:01.780980: step 530, loss 1.07967, accuracy 0.625, precision [nan, nan, 1.0, 0.6, 0.5, nan, 1.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.6, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:01.938360: step 531, loss 2.10125, accuracy 0.5, precision [0.3333333333333333, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.0, nan], recall [0.5, 1.0, 0.5, 0.4, 1.0, 0.3333333333333333, 1.0, nan, 0.0]
2019-02-19T17:59:02.095228: step 532, loss 1.901, accuracy 0.4375, precision [0.0, 0.6666666666666666, nan, 1.0, 0.0, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.5555555555555556, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:59:02.248766: step 533, loss 2.89878, accuracy 0.25, precision [0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.5, 0.0, 0.0, nan], recall [nan, 0.25, nan, 0.2, 0.5, 1.0, 0.0, 0.0, nan]
2019-02-19T17:59:02.406714: step 534, loss 2.21125, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.5, 0.5, 0.0, 0.5, nan, nan], recall [1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, nan, 1.0, 0.0, nan]
2019-02-19T17:59:02.558622: step 535, loss 0.880584, accuracy 0.625, precision [0.0, 1.0, 0.5, 0.5, 1.0, nan, 0.5, 1.0, 0.0], recall [nan, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T17:59:02.717125: step 536, loss 0.999798, accuracy 0.6875, precision [1.0, 0.0, 0.6666666666666666, 1.0, 0.8333333333333334, nan, nan, nan, nan], recall [1.0, 0.0, 1.0, 0.3333333333333333, 0.7142857142857143, nan, nan, nan, nan]
2019-02-19T17:59:02.883699: step 537, loss 1.72361, accuracy 0.5, precision [0.0, nan, 0.5, 1.0, 0.3333333333333333, 0.0, 0.0, nan, nan], recall [nan, 0.0, 0.6666666666666666, 0.7142857142857143, 0.5, 0.0, nan, nan, nan]
2019-02-19T17:59:03.040802: step 538, loss 3.10644, accuracy 0.4375, precision [0.0, 0.6666666666666666, 0.0, 0.75, 0.25, nan, nan, 1.0, 0.0], recall [0.0, 0.6666666666666666, 0.0, 0.75, 0.5, nan, 0.0, 0.25, nan]
2019-02-19T17:59:03.200919: step 539, loss 1.10417, accuracy 0.6875, precision [0.0, 0.0, 1.0, 1.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [nan, nan, 0.5, 0.7777777777777778, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T17:59:03.356112: step 540, loss 1.06253, accuracy 0.625, precision [nan, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.75, 1.0, 0.4, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:59:03.512922: step 541, loss 2.21246, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T17:59:03.662345: step 542, loss 1.81551, accuracy 0.5625, precision [nan, 1.0, 1.0, 0.25, 0.6666666666666666, nan, 1.0, 0.3333333333333333, nan], recall [0.0, 0.5, 1.0, 0.5, 0.6666666666666666, nan, 0.5, 1.0, 0.0]
2019-02-19T17:59:03.815216: step 543, loss 1.24672, accuracy 0.5625, precision [0.8, 0.0, 0.0, 0.5, 0.5, nan, 1.0, 0.5, nan], recall [0.6666666666666666, nan, nan, 0.4, 0.5, 0.0, 1.0, 1.0, nan]
2019-02-19T17:59:03.973161: step 544, loss 1.62391, accuracy 0.5625, precision [0.0, 1.0, nan, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, 1.0, nan], recall [0.0, 0.3333333333333333, nan, 0.8333333333333334, 0.6666666666666666, nan, 0.0, 0.5, nan]
2019-02-19T17:59:04.125321: step 545, loss 1.55683, accuracy 0.5625, precision [0.0, 0.5, 0.5, 0.6, 1.0, 0.0, nan, nan, nan], recall [nan, 0.3333333333333333, 0.5, 0.75, 1.0, nan, 0.0, nan, 0.0]
2019-02-19T17:59:04.283824: step 546, loss 1.66174, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, nan, nan, 0.3333333333333333, 1.0], recall [0.0, 0.0, 0.0, 0.4444444444444444, nan, 0.0, nan, 0.5, 1.0]
2019-02-19T17:59:04.439496: step 547, loss 1.55694, accuracy 0.5625, precision [0.5, 1.0, 0.5, 0.6666666666666666, 0.6, nan, nan, 0.5, 0.0], recall [1.0, 1.0, 1.0, 0.5, 0.6, nan, 0.0, 0.5, nan]
2019-02-19T17:59:04.593523: step 548, loss 1.43825, accuracy 0.5625, precision [0.0, 1.0, 0.5, 0.5, 0.75, 0.0, nan, nan, nan], recall [0.0, 0.6666666666666666, 1.0, 0.5, 0.75, 0.0, nan, nan, nan]
2019-02-19T17:59:04.748538: step 549, loss 1.53382, accuracy 0.4375, precision [0.6666666666666666, 0.5, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.5, 0.5, 0.42857142857142855, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:59:04.904194: step 550, loss 1.67581, accuracy 0.625, precision [nan, 0.4, 1.0, 0.75, 1.0, nan, 0.0, nan, nan], recall [0.0, 1.0, 1.0, 0.42857142857142855, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:05.061601: step 551, loss 1.92145, accuracy 0.4375, precision [1.0, 0.5, 1.0, 0.5, 0.0, nan, 0.3333333333333333, nan, nan], recall [0.5, 0.5, 0.25, 0.75, nan, 0.0, 1.0, 0.0, nan]
2019-02-19T17:59:05.215967: step 552, loss 2.11011, accuracy 0.5, precision [nan, 0.0, 0.3333333333333333, 0.8, 0.3333333333333333, 0.0, nan, 0.6666666666666666, nan], recall [0.0, nan, 1.0, 0.5714285714285714, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T17:59:05.372219: step 553, loss 0.966097, accuracy 0.6875, precision [nan, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, nan, nan, nan], recall [0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, nan, nan, nan]
2019-02-19T17:59:05.528085: step 554, loss 1.11295, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.5, 1.0, nan, nan], recall [1.0, 1.0, nan, 0.25, 1.0, 1.0, 0.6666666666666666, 0.0, nan]
2019-02-19T17:59:05.681839: step 555, loss 1.12313, accuracy 0.625, precision [nan, 0.5, 0.6666666666666666, 0.75, nan, 0.0, nan, nan, nan], recall [nan, 1.0, 1.0, 0.75, 0.0, nan, 0.0, 0.0, nan]
2019-02-19T17:59:05.838036: step 556, loss 2.89532, accuracy 0.125, precision [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 0.0, nan, 0.0, 0.25, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:05.991615: step 557, loss 2.4084, accuracy 0.375, precision [0.5, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, nan, nan], recall [1.0, 0.0, 0.3333333333333333, 0.2222222222222222, nan, nan, 1.0, nan, nan]
2019-02-19T17:59:06.147998: step 558, loss 2.08581, accuracy 0.375, precision [0.5, 0.2, 0.3333333333333333, 1.0, 0.0, 0.5, nan, nan, nan], recall [0.6666666666666666, 0.5, 0.5, 0.125, nan, 1.0, nan, nan, nan]
2019-02-19T17:59:06.299366: step 559, loss 1.1402, accuracy 0.625, precision [1.0, 0.0, nan, 0.2, 1.0, 0.0, nan, 1.0, nan], recall [0.5, nan, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:06.452496: step 560, loss 1.51728, accuracy 0.5625, precision [0.0, 0.3333333333333333, 0.0, 0.75, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 0.5, 0.0, 0.5, 0.8, nan, nan, 1.0, nan]
2019-02-19T17:59:06.603998: step 561, loss 1.04941, accuracy 0.5625, precision [0.5, 1.0, 0.5, 0.6666666666666666, 0.6, nan, nan, 0.0, nan], recall [0.5, 1.0, 0.6666666666666666, 0.5, 0.6, nan, nan, 0.0, nan]
2019-02-19T17:59:06.759931: step 562, loss 1.46109, accuracy 0.375, precision [0.0, 0.4, 1.0, 0.3333333333333333, 1.0, 1.0, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.2, 0.3333333333333333, 0.25, nan, 0.0, nan]
2019-02-19T17:59:06.912258: step 563, loss 1.81321, accuracy 0.4375, precision [0.0, 0.0, 1.0, 0.8333333333333334, 0.0, nan, nan, nan, 0.0], recall [nan, 0.0, 0.6666666666666666, 0.7142857142857143, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:59:07.072412: step 564, loss 1.46244, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.2, 1.0, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, 0.0, 0.16666666666666666, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:07.225581: step 565, loss 0.855087, accuracy 0.625, precision [nan, 0.3333333333333333, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.5, 1.0, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:07.382187: step 566, loss 1.43269, accuracy 0.4375, precision [nan, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.2, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:07.538055: step 567, loss 2.093, accuracy 0.375, precision [nan, 1.0, nan, 0.3333333333333333, 0.5, 0.0, nan, nan, nan], recall [0.0, 1.0, 0.0, 0.4, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T17:59:07.690414: step 568, loss 2.25106, accuracy 0.5, precision [0.3333333333333333, 1.0, 0.0, 0.8, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, nan, nan, nan, nan]
2019-02-19T17:59:07.847726: step 569, loss 1.11326, accuracy 0.75, precision [nan, nan, 0.5, 1.0, 1.0, nan, 1.0, 0.4, nan], recall [nan, 0.0, 1.0, 0.8, 0.8, nan, 1.0, 1.0, nan]
2019-02-19T17:59:08.003020: step 570, loss 1.29296, accuracy 0.5625, precision [1.0, 0.5, 1.0, 0.7142857142857143, 0.0, nan, nan, nan, nan], recall [1.0, 0.6666666666666666, 0.5, 0.5555555555555556, nan, nan, 0.0, nan, nan]
2019-02-19T17:59:08.162097: step 571, loss 2.24374, accuracy 0.4375, precision [1.0, 1.0, 0.5, 0.2, 1.0, nan, 0.0, nan, 0.0], recall [1.0, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:08.318542: step 572, loss 1.53667, accuracy 0.5625, precision [nan, 0.5, 0.5, 1.0, 0.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 1.0, 0.5, 0.0, nan, nan, 1.0, nan]
2019-02-19T17:59:08.477447: step 573, loss 2.17437, accuracy 0.3125, precision [0.0, 0.0, 0.0, 0.6666666666666666, nan, nan, nan, 0.3333333333333333, nan], recall [0.0, 0.0, nan, 0.5, 0.0, nan, nan, 0.5, nan]
2019-02-19T17:59:08.631764: step 574, loss 1.85849, accuracy 0.375, precision [0.0, 0.0, 0.0, 0.7142857142857143, nan, nan, 1.0, 0.0, nan], recall [nan, 0.0, nan, 0.45454545454545453, 0.0, 0.0, 1.0, 0.0, nan]
2019-02-19T17:59:08.787207: step 575, loss 1.97479, accuracy 0.625, precision [nan, 0.0, 0.5, 1.0, 0.8, nan, 0.0, 0.5, 0.0], recall [nan, nan, 1.0, 0.4, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:08.942567: step 576, loss 1.11182, accuracy 0.6875, precision [nan, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T17:59:09.188222: step 577, loss 1.1162, accuracy 0.6, precision [0.5, 0.0, nan, 1.0, 0.5, nan, 1.0, 1.0, 0.0], recall [0.5, 0.0, nan, 0.6666666666666666, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T17:59:09.345668: step 578, loss 1.52724, accuracy 0.6875, precision [0.0, 0.6666666666666666, nan, 0.75, 1.0, nan, nan, nan, 0.0], recall [0.0, 1.0, 0.0, 0.75, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:09.496394: step 579, loss 1.7776, accuracy 0.4375, precision [1.0, 0.0, 0.0, 1.0, 0.4, 0.0, nan, nan, 0.0], recall [1.0, nan, nan, 0.2727272727272727, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:59:09.650342: step 580, loss 1.51081, accuracy 0.5625, precision [1.0, 0.3333333333333333, nan, 0.7142857142857143, 0.5, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.0, 0.625, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T17:59:09.807313: step 581, loss 1.10542, accuracy 0.5625, precision [0.0, 0.75, 0.0, 0.6, 1.0, nan, nan, 0.5, 0.0], recall [0.0, 1.0, nan, 0.5, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:59:09.963581: step 582, loss 0.836373, accuracy 0.8125, precision [1.0, 0.5, 0.0, 1.0, 1.0, nan, 0.0, nan, nan], recall [1.0, 1.0, nan, 0.7142857142857143, 0.8571428571428571, nan, nan, nan, nan]
2019-02-19T17:59:10.115421: step 583, loss 1.9942, accuracy 0.4375, precision [0.3333333333333333, nan, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.25, nan], recall [0.5, 0.0, nan, 0.5714285714285714, 0.3333333333333333, 0.0, nan, 0.5, nan]
2019-02-19T17:59:10.275229: step 584, loss 1.98927, accuracy 0.5625, precision [0.5, 0.3333333333333333, 0.0, 0.5, 1.0, nan, nan, 0.5, nan], recall [0.5, 0.25, nan, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:10.430406: step 585, loss 1.535, accuracy 0.5625, precision [1.0, 0.3333333333333333, nan, 0.6, 0.5, 1.0, nan, 0.5, 0.5], recall [0.5, 0.5, nan, 0.5, 0.3333333333333333, 1.0, nan, 1.0, 1.0]
2019-02-19T17:59:10.584566: step 586, loss 1.26319, accuracy 0.625, precision [0.0, 0.5, 0.5, 1.0, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 1.0, 0.625, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T17:59:10.741962: step 587, loss 0.926, accuracy 0.6875, precision [0.0, 0.75, 0.0, 0.0, 1.0, nan, nan, 1.0, nan], recall [nan, 0.75, 0.0, 0.0, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:10.898800: step 588, loss 1.49169, accuracy 0.5625, precision [nan, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan], recall [nan, nan, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T17:59:11.049719: step 589, loss 1.1756, accuracy 0.6875, precision [0.0, 0.0, 0.5, 1.0, 1.0, nan, nan, 0.0, nan], recall [nan, 0.0, 1.0, 0.625, 0.8333333333333334, nan, nan, nan, nan]
2019-02-19T17:59:11.204560: step 590, loss 1.00582, accuracy 0.625, precision [0.0, 0.0, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [0.0, 0.0, 1.0, 0.8333333333333334, 0.3333333333333333, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:59:11.362343: step 591, loss 1.49943, accuracy 0.5, precision [nan, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 0.0, nan, 0.6666666666666666, 0.5], recall [0.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 0.6666666666666666, 1.0]
2019-02-19T17:59:11.512462: step 592, loss 0.981166, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.5714285714285714, 0.6666666666666666, nan, nan, nan, 0.0], recall [1.0, 0.3333333333333333, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:11.664900: step 593, loss 1.74126, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.75, nan, 0.0, 1.0, 0.0, nan], recall [nan, 1.0, 0.0, 0.5, 0.0, nan, 0.5, 0.0, nan]
2019-02-19T17:59:11.822102: step 594, loss 1.01925, accuracy 0.75, precision [1.0, nan, 0.3333333333333333, 0.8571428571428571, 1.0, 1.0, nan, 0.0, nan], recall [1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, nan, 0.0, nan]
2019-02-19T17:59:11.973806: step 595, loss 1.3631, accuracy 0.5625, precision [0.0, nan, 0.6666666666666666, 0.7142857142857143, 0.0, nan, nan, 0.6666666666666666, nan], recall [0.0, nan, 0.5, 0.8333333333333334, 0.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:59:12.128544: step 596, loss 1.70202, accuracy 0.5625, precision [0.25, nan, 1.0, 0.5, 0.8, nan, nan, 0.5, 0.0], recall [0.5, 0.0, 0.6666666666666666, 0.2, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:12.280893: step 597, loss 1.36624, accuracy 0.625, precision [0.5, 1.0, nan, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0], recall [1.0, 1.0, nan, 0.4444444444444444, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:12.439933: step 598, loss 1.05345, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.5, nan, 0.0, 0.0], recall [1.0, 0.5, 0.3333333333333333, 0.8333333333333334, 0.5, 1.0, nan, 0.0, nan]
2019-02-19T17:59:12.590642: step 599, loss 1.47229, accuracy 0.4375, precision [nan, 0.25, nan, 0.75, 0.5, nan, nan, 0.4, 0.0], recall [0.0, 0.3333333333333333, nan, 0.5, 0.5, nan, nan, 1.0, nan]
2019-02-19T17:59:12.743534: step 600, loss 1.07926, accuracy 0.625, precision [1.0, 0.25, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.0, nan], recall [1.0, 1.0, 0.6666666666666666, 0.8, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T17:59:12.897982: step 601, loss 1.28379, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.6, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.42857142857142855, 0.4, 0.0, nan, 0.0, nan]
2019-02-19T17:59:13.054513: step 602, loss 1.49176, accuracy 0.5, precision [0.5, 0.0, 0.0, 1.0, 1.0, nan, 0.0, 0.3333333333333333, 0.0], recall [1.0, nan, 0.0, 0.25, 0.8333333333333334, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:13.207868: step 603, loss 1.5089, accuracy 0.5625, precision [0.25, 0.5, 1.0, 1.0, 0.4, nan, nan, nan, nan], recall [0.3333333333333333, 1.0, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:13.364330: step 604, loss 1.64441, accuracy 0.5625, precision [1.0, 1.0, 0.0, 0.8333333333333334, 1.0, nan, 0.5, 0.0, nan], recall [1.0, 1.0, nan, 0.5555555555555556, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T17:59:13.516480: step 605, loss 1.71007, accuracy 0.375, precision [0.5, 0.5, 0.0, 0.6, 0.0, 0.0, nan, 1.0, nan], recall [0.25, 0.5, nan, 0.5, 0.0, nan, nan, 0.5, 0.0]
2019-02-19T17:59:13.672989: step 606, loss 1.41629, accuracy 0.4375, precision [0.0, 0.0, nan, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [nan, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:59:13.828357: step 607, loss 1.15866, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.4, 1.0, nan, 0.5, nan, nan], recall [0.0, 0.0, 0.25, 1.0, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:13.982222: step 608, loss 0.349133, accuracy 0.875, precision [1.0, 1.0, 1.0, 1.0, 1.0, nan, nan, 0.6, nan], recall [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:14.138330: step 609, loss 1.34914, accuracy 0.5, precision [1.0, 0.0, nan, 0.375, 1.0, 0.0, 0.0, 1.0, nan], recall [0.5, nan, 0.0, 1.0, 0.6666666666666666, nan, nan, 0.4, 0.0]
2019-02-19T17:59:14.294017: step 610, loss 1.25155, accuracy 0.5, precision [1.0, 0.5, 0.5, 0.4, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 0.5, 0.4, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T17:59:14.447069: step 611, loss 0.806674, accuracy 0.75, precision [1.0, 0.5, nan, 1.0, 0.5, 0.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 0.6, 0.5, nan, nan, 1.0, nan]
2019-02-19T17:59:14.602842: step 612, loss 1.50296, accuracy 0.4375, precision [0.0, 0.0, nan, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0], recall [0.0, 0.0, 0.0, 0.4, 1.0, nan, nan, 0.5, 1.0]
2019-02-19T17:59:14.752957: step 613, loss 1.18044, accuracy 0.625, precision [0.0, 1.0, nan, 0.8333333333333334, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [nan, 0.5, nan, 1.0, 0.8, nan, nan, 0.0, 0.0]
2019-02-19T17:59:14.907024: step 614, loss 0.813524, accuracy 0.6875, precision [0.0, 0.6666666666666666, 1.0, 0.8333333333333334, 1.0, nan, nan, 1.0, 0.0], recall [0.0, 0.6666666666666666, 1.0, 1.0, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:59:15.058903: step 615, loss 1.409, accuracy 0.5625, precision [0.5, 0.75, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [1.0, 0.75, nan, 0.3333333333333333, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:15.216626: step 616, loss 1.97927, accuracy 0.5, precision [nan, 0.6666666666666666, 0.0, 0.625, nan, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, nan, 0.625, nan, nan, nan, 0.2, nan]
2019-02-19T17:59:15.375021: step 617, loss 1.76486, accuracy 0.375, precision [1.0, 0.0, 1.0, 0.25, 0.5, nan, 0.0, 1.0, 0.0], recall [0.5, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.5, nan]
2019-02-19T17:59:15.532445: step 618, loss 1.51896, accuracy 0.4375, precision [0.5, 0.0, nan, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0], recall [0.25, 0.0, nan, 0.6666666666666666, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:15.683585: step 619, loss 1.51562, accuracy 0.5, precision [0.5, 0.6666666666666666, nan, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [0.5, 1.0, 0.0, 0.6, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:59:15.837250: step 620, loss 1.2753, accuracy 0.5625, precision [0.75, 0.0, nan, 0.75, 0.0, 0.3333333333333333, 1.0, 0.5, nan], recall [1.0, 0.0, 0.0, 0.42857142857142855, nan, 1.0, 1.0, 1.0, nan]
2019-02-19T17:59:15.990354: step 621, loss 1.80842, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.5, 1.0, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.5, 1.0, 0.25, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:16.145646: step 622, loss 0.555315, accuracy 0.875, precision [nan, 1.0, nan, 0.8, 1.0, 0.0, nan, 1.0, nan], recall [nan, 0.8333333333333334, nan, 1.0, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:16.300144: step 623, loss 1.84801, accuracy 0.6875, precision [1.0, 1.0, 0.6666666666666666, 0.5714285714285714, 1.0, nan, 1.0, 0.0, nan], recall [1.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, nan]
2019-02-19T17:59:16.458276: step 624, loss 1.86281, accuracy 0.375, precision [0.0, nan, 0.0, 0.6, 1.0, nan, 0.0, 0.5, 0.0], recall [0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:59:16.607594: step 625, loss 1.6243, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, nan, 0.0]
2019-02-19T17:59:16.765504: step 626, loss 1.85689, accuracy 0.4375, precision [1.0, 1.0, 0.25, 0.0, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T17:59:16.916784: step 627, loss 1.26571, accuracy 0.5625, precision [0.75, 0.5, 1.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [0.6, 1.0, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:59:17.072207: step 628, loss 1.04764, accuracy 0.625, precision [1.0, 0.5, 0.5, 0.8333333333333334, 1.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.6666666666666666, 1.0, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:17.225053: step 629, loss 1.19083, accuracy 0.625, precision [0.5, 1.0, nan, 0.8571428571428571, 0.5, 0.0, nan, 0.0, nan], recall [0.5, 1.0, nan, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:59:17.378783: step 630, loss 1.39523, accuracy 0.5, precision [1.0, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.0, 1.0, nan, nan], recall [1.0, 0.5, 1.0, 0.3333333333333333, 0.5, nan, 0.3333333333333333, nan, nan]
2019-02-19T17:59:17.535077: step 631, loss 0.968124, accuracy 0.625, precision [0.6666666666666666, 0.0, nan, 0.6666666666666666, 1.0, 0.0, nan, nan, nan], recall [1.0, 0.0, nan, 0.75, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:17.689104: step 632, loss 1.207, accuracy 0.5, precision [0.5, 0.3333333333333333, 0.0, 0.5, 1.0, nan, 1.0, 0.0, 0.0], recall [0.5, 1.0, nan, 0.4, 0.75, nan, 0.5, 0.0, 0.0]
2019-02-19T17:59:17.846581: step 633, loss 1.20445, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, nan, nan, 0.0], recall [1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:59:18.003993: step 634, loss 1.15908, accuracy 0.6875, precision [0.5, 1.0, 1.0, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.5, 1.0, 0.6666666666666666, 1.0, nan, nan, nan, 0.0]
2019-02-19T17:59:18.161417: step 635, loss 1.11984, accuracy 0.625, precision [0.0, 0.25, nan, 0.8888888888888888, 0.5, nan, nan, nan, nan], recall [0.0, 1.0, 0.0, 0.8, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:18.316935: step 636, loss 1.69027, accuracy 0.375, precision [0.0, 0.25, nan, 0.5, 0.75, nan, nan, 0.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.4, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T17:59:18.471937: step 637, loss 1.29418, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.3333333333333333, 0.75, 0.0, nan, 0.5, nan], recall [nan, 0.5, 1.0, 0.16666666666666666, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:18.627038: step 638, loss 1.60364, accuracy 0.375, precision [0.0, 0.25, nan, 0.5, nan, 0.0, nan, 1.0, nan], recall [nan, 0.5, 0.0, 0.3333333333333333, nan, 0.0, nan, 0.6, nan]
2019-02-19T17:59:18.782471: step 639, loss 0.947647, accuracy 0.625, precision [nan, 0.3333333333333333, 1.0, 0.625, 1.0, nan, 1.0, 0.0, nan], recall [nan, 1.0, 1.0, 0.7142857142857143, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T17:59:18.937304: step 640, loss 1.68796, accuracy 0.5, precision [0.3333333333333333, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.0, 0.3333333333333333, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T17:59:19.089897: step 641, loss 1.45943, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.7142857142857143, 0.5, 0.0, nan, 0.5, nan], recall [0.0, 0.0, 1.0, 0.8333333333333334, 1.0, nan, 0.0, 0.25, nan]
2019-02-19T17:59:19.243740: step 642, loss 1.29787, accuracy 0.5625, precision [0.0, 0.6, 0.0, 1.0, 0.5, nan, 0.0, 0.6666666666666666, 1.0], recall [nan, 0.6, nan, 0.5, 0.5, nan, 0.0, 0.6666666666666666, 1.0]
2019-02-19T17:59:19.395512: step 643, loss 1.55471, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.0, 0.5, 1.0, nan, nan, 0.75, 0.0], recall [0.5, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:59:19.553409: step 644, loss 1.7091, accuracy 0.625, precision [nan, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, nan, nan, 0.0, 0.0], recall [0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8, nan, 0.0, 0.0, nan]
2019-02-19T17:59:19.708835: step 645, loss 1.01032, accuracy 0.6875, precision [1.0, nan, 0.5, 0.5, 1.0, 0.5, nan, 1.0, nan], recall [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T17:59:19.863492: step 646, loss 1.74362, accuracy 0.5, precision [0.5, nan, 0.3333333333333333, 0.5714285714285714, 0.5, 1.0, nan, nan, 0.0], recall [0.5, 0.0, 0.5, 0.8, 0.5, 1.0, 0.0, 0.0, nan]
2019-02-19T17:59:20.016347: step 647, loss 1.672, accuracy 0.5625, precision [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0], recall [0.6666666666666666, 0.0, 1.0, 0.8, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T17:59:20.175036: step 648, loss 1.62102, accuracy 0.5, precision [1.0, 0.3333333333333333, 1.0, 0.4, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.2, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T17:59:20.331034: step 649, loss 0.871127, accuracy 0.8125, precision [nan, 1.0, 1.0, 0.7, 1.0, nan, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.5, 1.0, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T17:59:20.484078: step 650, loss 1.40799, accuracy 0.5, precision [0.0, 0.6666666666666666, nan, 0.8, nan, 0.0, 0.0, 0.4, nan], recall [0.0, 0.6666666666666666, nan, 0.5, nan, 0.0, nan, 1.0, nan]
2019-02-19T17:59:20.638684: step 651, loss 1.39538, accuracy 0.5625, precision [nan, 0.5, 0.0, 0.8888888888888888, 0.0, nan, nan, 0.0, nan], recall [0.0, 0.5, 0.0, 0.6666666666666666, nan, nan, nan, nan, nan]
2019-02-19T17:59:20.792108: step 652, loss 0.67546, accuracy 0.875, precision [nan, 0.5, 0.75, 1.0, 1.0, nan, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:20.951097: step 653, loss 1.55904, accuracy 0.375, precision [1.0, nan, nan, 0.3333333333333333, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.0, 0.5, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:59:21.105268: step 654, loss 1.10583, accuracy 0.625, precision [0.75, 0.5, 0.5, 0.75, 1.0, 0.0, 1.0, 0.0, nan], recall [1.0, 0.5, 1.0, 0.42857142857142855, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:21.259501: step 655, loss 2.17271, accuracy 0.3125, precision [0.0, 0.5, 0.0, 1.0, 0.3333333333333333, nan, nan, 0.0, nan], recall [nan, 1.0, nan, 0.3, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T17:59:21.410560: step 656, loss 1.80903, accuracy 0.5625, precision [0.6666666666666666, 1.0, 0.0, 0.7142857142857143, nan, 0.0, 0.0, 0.5, nan], recall [0.6666666666666666, 0.5, 0.0, 0.7142857142857143, nan, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:21.561971: step 657, loss 1.23141, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.3333333333333333, 0.8571428571428571, nan, 0.0, 1.0, nan], recall [0.5, 0.3333333333333333, nan, 0.25, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:21.715648: step 658, loss 0.892715, accuracy 0.6875, precision [1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, nan, 1.0, 0.5, 0.0], recall [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T17:59:21.873281: step 659, loss 1.23945, accuracy 0.75, precision [nan, 0.5, 1.0, 0.6, 0.75, 1.0, 1.0, 1.0, nan], recall [nan, 1.0, 0.5, 0.75, 1.0, 1.0, 1.0, 0.5, nan]
2019-02-19T17:59:22.034121: step 660, loss 1.06301, accuracy 0.6875, precision [1.0, 0.5, 0.0, 0.75, 1.0, nan, nan, 1.0, nan], recall [0.5, 0.75, nan, 0.75, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:22.192976: step 661, loss 1.01376, accuracy 0.625, precision [0.0, 0.0, nan, 0.6, 0.8, 0.0, nan, 1.0, nan], recall [nan, 0.0, nan, 0.75, 1.0, 0.0, nan, 0.75, nan]
2019-02-19T17:59:22.348931: step 662, loss 2.94276, accuracy 0.375, precision [0.5, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 0.0, 0.5, 0.0], recall [0.5, nan, 1.0, 0.2, nan, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:59:22.506612: step 663, loss 1.89666, accuracy 0.4375, precision [0.6666666666666666, nan, 0.6666666666666666, 0.6, 0.0, 0.0, nan, 0.0, nan], recall [1.0, nan, 0.4, 0.5, nan, 0.0, nan, 0.0, 0.0]
2019-02-19T17:59:22.662854: step 664, loss 1.03885, accuracy 0.6875, precision [0.5, 0.5, 0.5, 0.8333333333333334, 1.0, nan, 0.0, 1.0, nan], recall [0.5, 1.0, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.25, nan]
2019-02-19T17:59:22.814742: step 665, loss 1.4789, accuracy 0.4375, precision [0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, nan, nan, 0.0], recall [nan, 0.5, 1.0, 0.5, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:59:22.971719: step 666, loss 1.41733, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.6, 0.75, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.5, 0.375, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:59:23.122972: step 667, loss 2.16432, accuracy 0.5625, precision [0.6666666666666666, 0.5, 0.3333333333333333, 0.8, nan, nan, nan, 1.0, 0.0], recall [1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, nan, nan, 0.5, nan]
2019-02-19T17:59:23.281797: step 668, loss 1.70018, accuracy 0.4375, precision [nan, 0.3333333333333333, 1.0, 0.5714285714285714, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 1.0, 1.0, 0.4444444444444444, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:59:23.437657: step 669, loss 0.751985, accuracy 0.6875, precision [1.0, 0.5, 0.6666666666666666, 0.6, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.3333333333333333, 1.0, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:23.590217: step 670, loss 1.04777, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [nan, nan, 0.0, 0.75, 0.6666666666666666, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:23.742526: step 671, loss 0.948527, accuracy 0.6875, precision [0.0, 0.3333333333333333, nan, 0.75, 1.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.0, 0.75, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T17:59:23.894486: step 672, loss 0.629566, accuracy 0.75, precision [nan, 0.5, 1.0, 0.7142857142857143, 0.75, nan, nan, 1.0, nan], recall [nan, 0.5, 1.0, 0.7142857142857143, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:59:24.047525: step 673, loss 1.84203, accuracy 0.5, precision [1.0, 0.0, 0.5, 0.4, 0.75, nan, 0.0, 1.0, nan], recall [1.0, nan, 0.2, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T17:59:24.200907: step 674, loss 1.76001, accuracy 0.5, precision [nan, 0.6666666666666666, 0.3333333333333333, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0], recall [0.0, 0.5, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T17:59:24.361637: step 675, loss 1.7947, accuracy 0.5, precision [0.0, nan, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0], recall [nan, nan, 0.3333333333333333, 0.6666666666666666, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T17:59:24.518989: step 676, loss 1.15347, accuracy 0.625, precision [0.5, 0.75, 1.0, 1.0, 0.5, nan, 0.0, 0.3333333333333333, nan], recall [1.0, 0.75, 0.5, 0.75, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T17:59:24.672049: step 677, loss 1.42074, accuracy 0.4375, precision [nan, 0.3333333333333333, 1.0, 0.5, 0.5, nan, 0.0, 0.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.4, 0.4, nan, nan, 0.0, nan]
2019-02-19T17:59:24.825278: step 678, loss 1.56572, accuracy 0.5, precision [0.5, 0.0, 0.5, 0.8333333333333334, 0.5, 0.0, 0.0, 0.0, nan], recall [0.5, nan, 0.3333333333333333, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:24.976969: step 679, loss 1.23342, accuracy 0.5625, precision [0.5, 0.3333333333333333, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, nan], recall [1.0, 0.5, 0.0, 0.5, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T17:59:25.130816: step 680, loss 1.72938, accuracy 0.375, precision [0.3333333333333333, nan, 1.0, 0.375, 0.0, 0.0, nan, 0.5, nan], recall [0.3333333333333333, nan, 0.25, 1.0, 0.0, nan, nan, 0.2, nan]
2019-02-19T17:59:25.283056: step 681, loss 2.16801, accuracy 0.25, precision [0.5, 0.0, 0.0, 0.6, 0.0, nan, 0.0, nan, 0.0], recall [1.0, 0.0, 0.0, 0.375, nan, nan, 0.0, nan, 0.0]
2019-02-19T17:59:25.436893: step 682, loss 1.21299, accuracy 0.5625, precision [nan, 1.0, 1.0, 0.5555555555555556, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 1.0, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, nan, nan]
2019-02-19T17:59:25.588712: step 683, loss 2.18655, accuracy 0.5625, precision [0.0, 1.0, 0.4, 0.5, 0.75, nan, nan, 1.0, nan], recall [nan, 1.0, 0.5, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T17:59:25.741929: step 684, loss 1.65018, accuracy 0.4375, precision [0.0, nan, 0.5, 0.4444444444444444, 1.0, 0.0, nan, nan, nan], recall [nan, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:59:25.899961: step 685, loss 1.49005, accuracy 0.4375, precision [nan, 0.0, 0.5, 0.7142857142857143, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.0, 0.5, 0.5, 0.5, nan, nan, nan, nan]
2019-02-19T17:59:26.056550: step 686, loss 1.33759, accuracy 0.5, precision [1.0, 0.5, 0.0, 0.25, 1.0, 0.0, nan, 0.0, nan], recall [0.6666666666666666, 0.3333333333333333, nan, 0.16666666666666666, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:26.209098: step 687, loss 1.57535, accuracy 0.4375, precision [1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [1.0, 0.6666666666666666, nan, 0.2222222222222222, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T17:59:26.361438: step 688, loss 1.43687, accuracy 0.5625, precision [nan, 0.4, 0.0, 0.8333333333333334, 1.0, nan, 0.0, nan, nan], recall [0.0, 1.0, 0.0, 0.7142857142857143, 0.6666666666666666, nan, 0.0, 0.0, nan]
2019-02-19T17:59:26.522012: step 689, loss 1.48552, accuracy 0.4375, precision [0.0, 1.0, 0.0, 1.0, 0.5, 0.0, nan, 0.0, nan], recall [nan, 1.0, nan, 0.4444444444444444, 0.5, nan, 0.0, 0.0, nan]
2019-02-19T17:59:26.674216: step 690, loss 2.04042, accuracy 0.4375, precision [0.5, 0.0, 0.5, 0.5714285714285714, 1.0, 0.0, nan, nan, 0.0], recall [1.0, 0.0, 1.0, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:26.825029: step 691, loss 1.16999, accuracy 0.625, precision [0.5, 0.2, nan, 0.8333333333333334, 1.0, nan, nan, nan, nan], recall [1.0, 0.5, nan, 0.7142857142857143, 0.75, nan, 0.0, 0.0, nan]
2019-02-19T17:59:26.977706: step 692, loss 1.39408, accuracy 0.5625, precision [nan, 0.0, nan, 0.8888888888888888, 1.0, nan, 0.0, 0.0, nan], recall [0.0, nan, nan, 0.6153846153846154, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:59:27.131515: step 693, loss 1.5162, accuracy 0.4375, precision [0.0, 0.25, 0.0, 0.8, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.0, 0.5, 0.0, 0.4444444444444444, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T17:59:27.281868: step 694, loss 1.68231, accuracy 0.375, precision [nan, 0.0, 0.3333333333333333, 0.75, 0.5, 0.0, 0.0, nan, nan], recall [0.0, nan, 0.5, 0.3, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:59:27.435856: step 695, loss 0.821414, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.75, 1.0, 0.0, 0.0, nan, nan], recall [0.6666666666666666, 0.5, 1.0, 0.6, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:27.594139: step 696, loss 0.773113, accuracy 0.8125, precision [1.0, 0.25, nan, 1.0, 1.0, nan, 1.0, 1.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T17:59:27.749020: step 697, loss 1.29437, accuracy 0.5625, precision [0.5, 0.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, nan, 1.0], recall [0.5, nan, nan, 0.625, 0.6666666666666666, nan, nan, 0.0, 0.5]
2019-02-19T17:59:27.907545: step 698, loss 1.3262, accuracy 0.5, precision [1.0, 0.5, 0.5, 0.6666666666666666, 0.6, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 1.0, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:28.065351: step 699, loss 0.928158, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.875, nan, nan, nan, 0.0, nan], recall [0.5, 0.75, 0.5, 1.0, nan, nan, 0.0, nan, nan]
2019-02-19T17:59:28.218721: step 700, loss 1.77539, accuracy 0.4375, precision [0.0, nan, 0.0, 0.5833333333333334, nan, nan, nan, nan, nan], recall [nan, 0.0, nan, 0.7, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:28.374161: step 701, loss 1.27714, accuracy 0.625, precision [nan, 1.0, 0.0, 0.875, nan, 0.0, nan, 1.0, 0.0], recall [nan, 0.5, nan, 0.7, nan, nan, nan, 0.5, nan]
2019-02-19T17:59:28.526511: step 702, loss 1.31309, accuracy 0.3125, precision [nan, 0.0, 0.0, 0.7142857142857143, nan, nan, nan, 0.0, 0.0], recall [nan, 0.0, 0.0, 0.38461538461538464, 0.0, nan, nan, nan, nan]
2019-02-19T17:59:28.679970: step 703, loss 1.59285, accuracy 0.5, precision [nan, 1.0, 0.25, 0.8333333333333334, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.25, 1.0, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:28.840481: step 704, loss 1.15008, accuracy 0.625, precision [1.0, 0.5, 0.5, 0.7142857142857143, 0.5, nan, 1.0, nan, 0.0], recall [0.3333333333333333, 1.0, 0.3333333333333333, 0.7142857142857143, 1.0, nan, 1.0, nan, nan]
2019-02-19T17:59:28.994701: step 705, loss 0.926659, accuracy 0.625, precision [0.5, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.5, 0.0, 0.75, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:29.149894: step 706, loss 1.26986, accuracy 0.375, precision [0.0, 0.5, 0.0, 0.6, 1.0, 0.0, nan, 0.5, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:59:29.303285: step 707, loss 1.65026, accuracy 0.5, precision [0.6666666666666666, 0.0, 1.0, 0.5, 0.5, 0.5, nan, 0.0, nan], recall [1.0, nan, 0.5, 0.5, 0.5, 0.3333333333333333, nan, nan, 0.0]
2019-02-19T17:59:29.457015: step 708, loss 1.91515, accuracy 0.375, precision [nan, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [nan, 0.5, 0.25, 0.4, 0.6666666666666666, nan, nan, 0.0, 0.0]
2019-02-19T17:59:29.608950: step 709, loss 1.94378, accuracy 0.5625, precision [0.5, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.5, 0.0, 0.5555555555555556, 0.6666666666666666, nan, nan, nan, nan]
2019-02-19T17:59:29.765486: step 710, loss 1.3901, accuracy 0.5, precision [0.0, 0.5, 0.5, 0.5, 0.8, 0.0, nan, 0.0, nan], recall [nan, 1.0, 0.25, 0.2, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:29.917089: step 711, loss 1.94237, accuracy 0.3125, precision [nan, 0.5, 0.0, 0.4, 0.5, nan, 0.0, 0.0, 0.0], recall [nan, 0.5, 0.0, 0.3333333333333333, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T17:59:30.074347: step 712, loss 1.36575, accuracy 0.4375, precision [0.0, 0.6666666666666666, 1.0, 0.5, 0.75, nan, 0.0, 0.0, 0.0], recall [nan, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T17:59:30.227664: step 713, loss 1.53758, accuracy 0.4375, precision [nan, 0.5, 1.0, 0.2, 0.8, nan, nan, 0.0, 0.0], recall [nan, 0.5, 0.25, 0.5, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:30.385070: step 714, loss 1.58818, accuracy 0.5, precision [0.3333333333333333, nan, 0.0, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:30.538495: step 715, loss 1.6264, accuracy 0.625, precision [0.0, nan, 1.0, 0.8333333333333334, 1.0, nan, 0.0, 1.0, 0.0], recall [nan, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:30.693740: step 716, loss 1.04666, accuracy 0.6875, precision [0.0, 1.0, 0.75, 0.6666666666666666, 0.8, 0.0, nan, 1.0, nan], recall [nan, 0.5, 0.75, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:30.854197: step 717, loss 1.93663, accuracy 0.5, precision [0.5, nan, 1.0, 0.5, 0.75, 0.0, nan, nan, 0.0], recall [1.0, nan, 0.5, 0.6, 0.75, nan, 0.0, 0.0, 0.0]
2019-02-19T17:59:31.011525: step 718, loss 0.929357, accuracy 0.6875, precision [0.0, 0.6666666666666666, 0.75, 0.7142857142857143, 1.0, nan, nan, nan, nan], recall [nan, 0.6666666666666666, 0.75, 1.0, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:59:31.161849: step 719, loss 0.895764, accuracy 0.6875, precision [1.0, nan, 0.3333333333333333, 1.0, 0.75, nan, nan, 0.0, nan], recall [1.0, nan, 1.0, 0.375, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:31.318094: step 720, loss 1.57312, accuracy 0.4375, precision [1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, nan], recall [0.8, 0.5, nan, 0.2, 0.5, 0.0, nan, nan, nan]
2019-02-19T17:59:31.476449: step 721, loss 0.991151, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6, nan, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 0.0, nan, nan, 0.0]
2019-02-19T17:59:31.626147: step 722, loss 0.943764, accuracy 0.75, precision [0.5, 1.0, 1.0, 0.8, 0.75, nan, nan, 0.6666666666666666, nan], recall [0.3333333333333333, 0.5, 1.0, 0.8, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:31.790115: step 723, loss 1.68918, accuracy 0.375, precision [nan, 0.0, nan, 0.2222222222222222, 1.0, 1.0, nan, 1.0, 1.0], recall [0.0, 0.0, 0.0, 0.5, 0.3333333333333333, 1.0, nan, 0.5, 1.0]
2019-02-19T17:59:31.946468: step 724, loss 1.17738, accuracy 0.625, precision [0.0, 0.75, 1.0, 0.6, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.6, 1.0, 0.6, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:32.101496: step 725, loss 1.25594, accuracy 0.5, precision [0.0, 0.5, 0.6, 0.3333333333333333, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.2, 0.75, 0.0, nan, 0.0, 0.0]
2019-02-19T17:59:32.257921: step 726, loss 0.782782, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.75, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 0.6, 1.0, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:32.413277: step 727, loss 1.30848, accuracy 0.5, precision [nan, 0.0, 0.5, 0.6, 0.8, nan, 0.0, 0.0, nan], recall [0.0, nan, 1.0, 0.5, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T17:59:32.571855: step 728, loss 2.23386, accuracy 0.4375, precision [nan, 0.5, 0.0, 0.625, 1.0, 0.0, 0.0, 0.0, 0.0], recall [nan, 1.0, 0.0, 0.5555555555555556, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T17:59:32.725845: step 729, loss 1.29747, accuracy 0.5625, precision [nan, 0.3333333333333333, nan, 0.5714285714285714, 0.6666666666666666, nan, 0.5, nan, 1.0], recall [nan, 0.5, nan, 0.6666666666666666, 0.5, 0.0, 1.0, nan, 0.5]
2019-02-19T17:59:32.881565: step 730, loss 0.991289, accuracy 0.625, precision [1.0, 0.5, nan, 0.6, 1.0, nan, 0.0, 1.0, 0.0], recall [1.0, 1.0, 0.0, 0.5, 0.75, nan, nan, 0.5, nan]
2019-02-19T17:59:33.034767: step 731, loss 1.24675, accuracy 0.5, precision [1.0, 0.2, 1.0, 1.0, 0.6666666666666666, nan, 0.0, 0.5, 0.0], recall [0.5, 1.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T17:59:33.188300: step 732, loss 1.39028, accuracy 0.5, precision [0.0, 0.3333333333333333, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, nan, 1.0], recall [nan, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T17:59:33.343195: step 733, loss 1.07301, accuracy 0.5625, precision [nan, 0.3333333333333333, nan, 0.625, 0.75, 0.0, nan, nan, nan], recall [0.0, 1.0, 0.0, 0.8333333333333334, 0.5, 0.0, nan, nan, nan]
2019-02-19T17:59:33.498166: step 734, loss 0.997218, accuracy 0.75, precision [nan, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, nan, 1.0, 0.5, nan], recall [nan, 0.6666666666666666, 1.0, 0.625, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T17:59:33.648066: step 735, loss 1.48964, accuracy 0.4375, precision [0.4, 0.0, nan, 0.8, 0.5, nan, nan, 0.0, 0.0], recall [1.0, 0.0, 0.0, 0.4444444444444444, 0.5, nan, nan, nan, nan]
2019-02-19T17:59:33.802032: step 736, loss 0.84581, accuracy 0.75, precision [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [0.75, 0.0, 1.0, 0.6, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:33.952297: step 737, loss 1.22148, accuracy 0.5625, precision [0.0, 1.0, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.0, 0.6, nan, 0.4, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:59:34.106254: step 738, loss 0.961274, accuracy 0.75, precision [1.0, 0.0, 1.0, 0.7142857142857143, 1.0, nan, 0.0, 1.0, nan], recall [0.5, 0.0, 1.0, 0.8333333333333334, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:34.259672: step 739, loss 1.05985, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.6, 1.0, 0.0, nan, nan, 0.0], recall [nan, 0.25, 0.0, 0.42857142857142855, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:34.422051: step 740, loss 0.913568, accuracy 0.6875, precision [0.5, 1.0, nan, 0.8571428571428571, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.6666666666666666, nan, 0.6, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:34.578242: step 741, loss 1.84444, accuracy 0.375, precision [nan, 0.25, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, nan, 0.5, 0.25, nan, nan, nan, nan]
2019-02-19T17:59:34.731395: step 742, loss 1.24647, accuracy 0.5625, precision [1.0, 0.5, 0.5, 0.6, 0.0, 0.5, 0.0, 1.0, nan], recall [1.0, 0.25, 1.0, 0.5, nan, 1.0, nan, 0.5, nan]
2019-02-19T17:59:34.881460: step 743, loss 1.44989, accuracy 0.625, precision [nan, 0.0, nan, 0.875, 1.0, 0.0, 1.0, 1.0, 0.0], recall [nan, nan, nan, 0.5833333333333334, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T17:59:35.039376: step 744, loss 1.31034, accuracy 0.625, precision [0.0, 0.3333333333333333, nan, 1.0, 0.75, nan, nan, 0.0, nan], recall [0.0, 0.5, nan, 0.6, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:35.193144: step 745, loss 1.39907, accuracy 0.625, precision [0.0, nan, 0.0, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, nan, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:35.342457: step 746, loss 1.76569, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.25, nan, nan, nan], recall [nan, nan, 0.5, 0.4444444444444444, 1.0, 1.0, nan, 0.0, 0.0]
2019-02-19T17:59:35.497001: step 747, loss 0.983122, accuracy 0.6875, precision [nan, 1.0, 0.0, 0.8, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.5, nan, 0.8, 0.8571428571428571, nan, 0.0, nan, nan]
2019-02-19T17:59:35.649548: step 748, loss 1.38545, accuracy 0.5625, precision [0.8, 0.0, 0.0, 0.6666666666666666, 0.5, nan, nan, 0.6666666666666666, nan], recall [0.6666666666666666, nan, nan, 0.2857142857142857, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:35.803962: step 749, loss 0.854135, accuracy 0.75, precision [0.5, nan, 1.0, 0.8, 1.0, 0.5, 0.0, nan, nan], recall [0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, nan, nan, nan]
2019-02-19T17:59:35.964945: step 750, loss 1.45651, accuracy 0.625, precision [0.0, 0.6, nan, 1.0, 1.0, 0.3333333333333333, nan, 0.0, nan], recall [nan, 0.6, nan, 0.4, 1.0, 1.0, 0.0, nan, nan]

Evaluation:
[[ 53  11   0  22   1   1   0   3   0]
 [ 14  70   0  65   4   0   0   7   0]
 [  3   3  25  57   4   1   1   2   0]
 [ 15  14   7 248  10   1   1  17   0]
 [  0   1   1  24 132   0   1   0   0]
 [  5   3   0  39   2   3   0   3   0]
 [  2   0   0  15   4   0  11   1   0]
 [  5   2   0  35   0   1   1  57   0]
 [  1   1   0  11   1   0   0   2   1]]
2019-02-19T17:59:38.396745: step 750, loss 1.30062, accuracy 0.585366, precision [0.5824175824175825, 0.4375, 0.2604166666666667, 0.792332268370607, 0.8301886792452831, 0.05454545454545454, 0.3333333333333333, 0.5643564356435643, 0.058823529411764705], recall [0.5408163265306123, 0.6666666666666666, 0.7575757575757576, 0.4806201550387597, 0.8354430379746836, 0.42857142857142855, 0.7333333333333333, 0.6195652173913043, 1.0]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-750

2019-02-19T17:59:38.700903: step 751, loss 1.30141, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.8, 1.0, 0.0, nan, 0.5, nan], recall [nan, 1.0, nan, 0.4, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T17:59:38.855557: step 752, loss 0.893838, accuracy 0.6875, precision [1.0, 0.4, nan, 1.0, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.5, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:59:39.006171: step 753, loss 1.21683, accuracy 0.625, precision [1.0, 0.25, 1.0, 0.8, 0.6666666666666666, nan, nan, 0.0, nan], recall [1.0, 1.0, 0.6666666666666666, 0.5714285714285714, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:39.159625: step 754, loss 1.27645, accuracy 0.625, precision [1.0, 0.75, 0.5, 0.8, 0.0, nan, 0.0, 0.5, nan], recall [0.5, 1.0, 1.0, 0.5, nan, 0.0, nan, 1.0, nan]
2019-02-19T17:59:39.312938: step 755, loss 2.62058, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.2, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [nan, 0.5, 0.5, 0.25, 0.75, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T17:59:39.466535: step 756, loss 1.15228, accuracy 0.6875, precision [1.0, 1.0, 0.3333333333333333, 0.75, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [1.0, 0.75, 1.0, 0.6, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:39.617661: step 757, loss 1.12337, accuracy 0.5625, precision [1.0, 1.0, 1.0, 0.25, 0.6666666666666666, nan, nan, 0.0, nan], recall [1.0, 0.5, 0.75, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T17:59:39.768811: step 758, loss 1.31031, accuracy 0.4375, precision [1.0, 0.5, 0.25, 0.6, nan, nan, 0.0, 0.0, nan], recall [0.5, 0.5, 1.0, 0.5, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:39.924564: step 759, loss 0.973671, accuracy 0.6875, precision [0.5, 0.6666666666666666, 0.0, 0.8, 1.0, nan, nan, 0.5, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:40.079022: step 760, loss 1.67149, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.75, 1.0, 0.5, nan, 0.25, 0.0], recall [0.0, nan, nan, 0.375, 0.6666666666666666, 0.5, nan, 1.0, nan]
2019-02-19T17:59:40.234445: step 761, loss 1.13403, accuracy 0.5, precision [nan, 0.0, 0.6, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, nan], recall [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.25, nan]
2019-02-19T17:59:40.386434: step 762, loss 1.7014, accuracy 0.375, precision [0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T17:59:40.538098: step 763, loss 1.67229, accuracy 0.4375, precision [0.3333333333333333, 0.75, nan, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.5, 0.375, 0.0, 0.6666666666666666, 0.0, nan, nan, 1.0, nan]
2019-02-19T17:59:40.693913: step 764, loss 0.687579, accuracy 0.6875, precision [1.0, nan, 1.0, 0.25, 1.0, nan, 0.0, 0.6666666666666666, nan], recall [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:59:40.848096: step 765, loss 2.05072, accuracy 0.5, precision [0.3333333333333333, 0.5, nan, 0.4, 1.0, nan, 0.5, 0.0, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, 0.75, nan, 1.0, 0.0, nan]
2019-02-19T17:59:41.005565: step 766, loss 1.2835, accuracy 0.5625, precision [nan, 1.0, 1.0, 0.4444444444444444, 1.0, nan, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, 0.5, 0.8, 0.4, nan, 0.0, nan, nan]
2019-02-19T17:59:41.159842: step 767, loss 1.03214, accuracy 0.6875, precision [nan, 1.0, 0.0, 0.75, 0.75, nan, nan, 1.0, 0.0], recall [nan, 0.5, 0.0, 0.75, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:41.320770: step 768, loss 1.58869, accuracy 0.5, precision [0.5, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.0, nan, 0.3333333333333333, 0.8, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:41.473503: step 769, loss 1.09036, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.7142857142857143, 0.5, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.5, 0.5555555555555556, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:41.630965: step 770, loss 1.75219, accuracy 0.3125, precision [0.0, 0.3333333333333333, 0.0, 0.75, 1.0, 0.0, 0.0, nan, 0.0], recall [0.0, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T17:59:41.782615: step 771, loss 0.858988, accuracy 0.8125, precision [nan, 0.8, 1.0, 0.8, 1.0, 1.0, 0.5, nan, nan], recall [nan, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, nan]
2019-02-19T17:59:41.939186: step 772, loss 1.40664, accuracy 0.5, precision [0.25, 0.0, 0.5, 0.6, 1.0, 1.0, nan, 0.0, nan], recall [0.5, nan, 1.0, 0.375, 1.0, 1.0, 0.0, 0.0, nan]
2019-02-19T17:59:42.091374: step 773, loss 0.930704, accuracy 0.75, precision [nan, 0.75, 0.0, 0.6, 1.0, 1.0, nan, 1.0, nan], recall [nan, 1.0, 0.0, 0.75, 0.75, 1.0, nan, 0.6666666666666666, nan]
2019-02-19T17:59:42.245305: step 774, loss 1.08578, accuracy 0.6875, precision [0.0, 0.5, 1.0, 0.3333333333333333, 0.8333333333333334, nan, nan, 1.0, nan], recall [nan, 0.5, 0.5, 1.0, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T17:59:42.401212: step 775, loss 0.895198, accuracy 0.625, precision [nan, 0.5, 1.0, 0.5, 0.5, 1.0, nan, 1.0, nan], recall [nan, 1.0, 1.0, 0.2, 1.0, 1.0, 0.0, 0.5, nan]
2019-02-19T17:59:42.559888: step 776, loss 1.31391, accuracy 0.625, precision [0.0, 0.5, 1.0, 0.6666666666666666, 0.75, nan, 1.0, 0.0, 0.0], recall [0.0, 0.5, 0.75, 0.4, 1.0, nan, 1.0, nan, nan]
2019-02-19T17:59:42.710366: step 777, loss 1.52575, accuracy 0.5625, precision [0.5, 0.0, 1.0, 1.0, 0.5, 0.0, nan, 0.0, nan], recall [0.5, nan, 1.0, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:42.866219: step 778, loss 0.849222, accuracy 0.8125, precision [1.0, 0.5, 1.0, 0.8, 1.0, 1.0, nan, 0.6666666666666666, nan], recall [1.0, 0.5, 1.0, 0.8, 0.6666666666666666, 1.0, nan, 1.0, nan]
2019-02-19T17:59:43.022520: step 779, loss 1.03852, accuracy 0.75, precision [1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, nan], recall [0.5, 1.0, 1.0, 0.5, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T17:59:43.173558: step 780, loss 2.11135, accuracy 0.375, precision [0.0, nan, nan, 0.8571428571428571, 0.0, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:43.329921: step 781, loss 1.09288, accuracy 0.6875, precision [0.0, 1.0, nan, 0.75, 1.0, 0.5, 0.0, 0.8, nan], recall [nan, 0.3333333333333333, nan, 0.5, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T17:59:43.482453: step 782, loss 1.42933, accuracy 0.5, precision [0.3333333333333333, 0.5, nan, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [1.0, 0.4, nan, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T17:59:43.640093: step 783, loss 1.81293, accuracy 0.4375, precision [0.0, 0.75, 1.0, 0.4, 0.5, nan, 0.0, nan, 0.0], recall [nan, 0.5, 0.5, 0.4, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:59:43.793241: step 784, loss 1.54408, accuracy 0.375, precision [0.3333333333333333, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.0, 0.0, 0.25, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:43.950906: step 785, loss 1.78213, accuracy 0.5625, precision [0.0, 0.0, 0.0, 0.8333333333333334, 1.0, nan, 0.25, 1.0, nan], recall [nan, 0.0, nan, 0.5555555555555556, 0.6666666666666666, nan, 1.0, 0.5, nan]
2019-02-19T17:59:44.105622: step 786, loss 1.34599, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, nan], recall [0.5, 1.0, nan, 0.5714285714285714, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T17:59:44.259919: step 787, loss 1.35242, accuracy 0.5625, precision [0.5, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, nan, 1.0], recall [1.0, 0.6666666666666666, 1.0, 0.4, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T17:59:44.409026: step 788, loss 0.766515, accuracy 0.75, precision [nan, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 1.0, 1.0, 0.75, 0.5, nan, 0.5, 1.0, nan]
2019-02-19T17:59:44.566901: step 789, loss 1.54093, accuracy 0.4375, precision [1.0, 1.0, 0.0, 0.2, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [0.5, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:44.722753: step 790, loss 1.36177, accuracy 0.5625, precision [1.0, 0.5, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.3333333333333333, 0.6666666666666666, 0.0, 0.5714285714285714, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:44.876004: step 791, loss 0.830619, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.2, 1.0, 1.0, nan, 1.0, nan], recall [1.0, 0.6, 1.0, 0.5, 1.0, 0.5, nan, 0.6666666666666666, nan]
2019-02-19T17:59:45.034952: step 792, loss 1.41537, accuracy 0.4375, precision [0.3333333333333333, nan, 1.0, 0.2857142857142857, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.0, 1.0, 0.5, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T17:59:45.191530: step 793, loss 1.53883, accuracy 0.375, precision [1.0, 0.0, 0.0, 0.75, 0.5, 0.0, nan, 1.0, nan], recall [0.5, 0.0, nan, 0.5, 0.5, nan, 0.0, 0.5, nan]
2019-02-19T17:59:45.347536: step 794, loss 1.52912, accuracy 0.4375, precision [0.6666666666666666, nan, 1.0, 0.4, 0.5, 0.0, 0.0, nan, 0.0], recall [1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:45.499826: step 795, loss 1.63366, accuracy 0.4375, precision [0.6666666666666666, 0.5, nan, 0.2857142857142857, 0.6666666666666666, nan, 0.0, nan, nan], recall [0.6666666666666666, 0.5, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:45.655203: step 796, loss 1.73449, accuracy 0.5, precision [1.0, 0.5, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 0.5, nan], recall [0.6666666666666666, 0.6666666666666666, 0.0, 0.4, 0.5, nan, nan, 0.5, nan]
2019-02-19T17:59:45.816032: step 797, loss 1.60055, accuracy 0.5, precision [0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, nan, nan, nan], recall [0.5, 0.3333333333333333, 1.0, 0.42857142857142855, 1.0, nan, 0.0, nan, nan]
2019-02-19T17:59:45.970067: step 798, loss 1.49748, accuracy 0.5, precision [nan, 0.75, 1.0, 0.5, nan, 0.0, nan, 0.25, nan], recall [0.0, 0.75, 0.3333333333333333, 0.6, 0.0, nan, nan, 1.0, nan]
2019-02-19T17:59:46.129073: step 799, loss 1.21379, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, nan, nan], recall [nan, 0.0, 0.0, 0.5714285714285714, 0.75, 0.5, nan, nan, nan]
2019-02-19T17:59:46.280647: step 800, loss 1.17594, accuracy 0.75, precision [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.6666666666666666, 1.0, 1.0, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:46.433342: step 801, loss 1.58457, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan, 0.0], recall [0.0, 0.6666666666666666, 0.5, 0.5714285714285714, 0.0, nan, nan, nan, nan]
2019-02-19T17:59:46.592031: step 802, loss 1.63581, accuracy 0.5, precision [0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, nan, nan, nan]
2019-02-19T17:59:46.747012: step 803, loss 1.96911, accuracy 0.5, precision [nan, 0.6, nan, 0.6666666666666666, 0.0, 0.0, nan, 0.3333333333333333, nan], recall [nan, 1.0, nan, 0.4, nan, 0.0, nan, 0.5, nan]
2019-02-19T17:59:46.903098: step 804, loss 1.72046, accuracy 0.3125, precision [0.0, 0.0, 0.5, 0.0, 0.25, nan, 0.0, 0.75, nan], recall [nan, nan, 0.5, 0.0, 0.5, 0.0, 0.0, 0.75, nan]
2019-02-19T17:59:47.059063: step 805, loss 1.11146, accuracy 0.5, precision [1.0, 0.0, nan, 0.5, 0.5, nan, 1.0, 0.0, nan], recall [0.25, nan, nan, 0.6, 1.0, 0.0, 1.0, 0.0, 0.0]
2019-02-19T17:59:47.212560: step 806, loss 0.895889, accuracy 0.75, precision [1.0, 0.6, 0.0, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.75, nan, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T17:59:47.365413: step 807, loss 1.02841, accuracy 0.75, precision [nan, 0.75, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, nan, nan], recall [nan, 1.0, 0.5, 0.7142857142857143, 1.0, 0.5, nan, nan, nan]
2019-02-19T17:59:47.522074: step 808, loss 1.12641, accuracy 0.625, precision [0.5, 0.0, 0.6666666666666666, 1.0, 1.0, nan, 1.0, 0.5, nan], recall [1.0, nan, 1.0, 0.5714285714285714, 0.5, 0.0, 1.0, 1.0, nan]
2019-02-19T17:59:47.673823: step 809, loss 1.42896, accuracy 0.5, precision [nan, 0.5, 0.0, 0.5, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.4, nan, 0.5, 0.6, nan, nan, 1.0, nan]
2019-02-19T17:59:47.826878: step 810, loss 1.50904, accuracy 0.5625, precision [0.5, 1.0, 0.5, 0.5, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.5, 0.5, 0.5, 0.6666666666666666, 0.75, nan, 0.0, 0.5, nan]
2019-02-19T17:59:47.978810: step 811, loss 1.16516, accuracy 0.5625, precision [0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.8333333333333334, 1.0, nan, nan, 0.0], recall [nan, 0.5, 1.0, 0.25, 0.8333333333333334, 1.0, 0.0, 0.0, nan]
2019-02-19T17:59:48.135948: step 812, loss 1.1933, accuracy 0.5625, precision [0.5, nan, 1.0, 0.5714285714285714, 1.0, 0.0, 0.0, 0.5, nan], recall [0.5, 0.0, 1.0, 0.8, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T17:59:48.292766: step 813, loss 1.60716, accuracy 0.5625, precision [0.5, nan, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T17:59:48.443873: step 814, loss 1.71104, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.0, 0.5, 1.0, nan, 0.0, 0.5, 0.0], recall [0.5, 1.0, 0.0, 0.6666666666666666, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T17:59:48.599866: step 815, loss 0.94511, accuracy 0.75, precision [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 1.0, 0.0], recall [1.0, 0.75, nan, 0.6666666666666666, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T17:59:48.755065: step 816, loss 1.19252, accuracy 0.5625, precision [0.0, 0.5, 0.3333333333333333, 0.75, 1.0, nan, nan, nan, nan], recall [nan, 1.0, 1.0, 0.5, 0.75, 0.0, 0.0, 0.0, nan]
2019-02-19T17:59:48.909568: step 817, loss 0.817287, accuracy 0.75, precision [nan, 1.0, 1.0, 0.7142857142857143, 0.75, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.7142857142857143, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:49.069968: step 818, loss 1.07513, accuracy 0.625, precision [1.0, 0.0, 0.5, 0.8333333333333334, 1.0, 0.0, nan, nan, nan], recall [1.0, nan, 0.3333333333333333, 0.7142857142857143, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:49.222954: step 819, loss 1.42813, accuracy 0.5, precision [nan, 0.0, 0.3333333333333333, 1.0, 0.5, 0.0, nan, 0.0, nan], recall [0.0, 0.0, 1.0, 0.5555555555555556, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:49.374642: step 820, loss 1.2862, accuracy 0.625, precision [1.0, 0.3333333333333333, 0.75, 0.8, 0.0, nan, nan, 0.5, nan], recall [0.5, 0.5, 0.75, 0.6666666666666666, 0.0, nan, nan, 1.0, nan]
2019-02-19T17:59:49.529650: step 821, loss 1.09128, accuracy 0.75, precision [nan, nan, nan, 0.75, 1.0, 0.0, 1.0, nan, 0.0], recall [nan, 0.0, 0.0, 0.8571428571428571, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:49.683713: step 822, loss 1.60694, accuracy 0.4375, precision [0.4, 0.6666666666666666, nan, 0.0, 0.75, nan, 0.0, nan, nan], recall [1.0, 0.5, 0.0, 0.0, 0.6, nan, nan, 0.0, nan]
2019-02-19T17:59:49.839736: step 823, loss 1.6161, accuracy 0.4375, precision [0.0, 0.4, 0.0, 0.5, 1.0, nan, 0.5, nan, nan], recall [nan, 0.5, nan, 0.6, 0.3333333333333333, nan, 1.0, 0.0, nan]
2019-02-19T17:59:49.999651: step 824, loss 1.55641, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, nan, 0.0, nan, 0.5, 0.0], recall [1.0, 0.25, 1.0, 0.3333333333333333, nan, nan, nan, 1.0, nan]
2019-02-19T17:59:50.151436: step 825, loss 1.40779, accuracy 0.375, precision [0.6666666666666666, 0.5, nan, 0.2857142857142857, nan, 0.0, nan, 0.0, nan], recall [0.5, 0.3333333333333333, nan, 0.6666666666666666, 0.0, 0.0, nan, nan, nan]
2019-02-19T17:59:50.304037: step 826, loss 1.89682, accuracy 0.375, precision [0.4, 0.5, nan, 0.5, 0.0, 0.0, nan, 0.0, nan], recall [0.6666666666666666, 0.5, nan, 0.375, 0.0, nan, nan, 0.0, nan]
2019-02-19T17:59:50.460732: step 827, loss 0.771034, accuracy 0.75, precision [1.0, 0.75, 0.5, 0.75, 1.0, nan, 0.0, nan, nan], recall [1.0, 0.6, 1.0, 0.75, 0.75, nan, nan, nan, nan]
2019-02-19T17:59:50.615348: step 828, loss 2.277, accuracy 0.4375, precision [nan, 0.5, 0.5, 0.4, 1.0, 0.0, nan, 0.0, nan], recall [nan, 1.0, 0.3333333333333333, 0.2857142857142857, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T17:59:50.771639: step 829, loss 1.95791, accuracy 0.5, precision [0.0, 0.3333333333333333, 0.6666666666666666, 0.8, 1.0, 0.0, 0.0, nan, nan], recall [nan, 0.2, 0.6666666666666666, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T17:59:50.927891: step 830, loss 1.45248, accuracy 0.625, precision [nan, 0.5, 0.5, 0.7142857142857143, 1.0, nan, 0.0, 1.0, 0.0], recall [0.0, 0.5, 1.0, 0.625, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:51.084433: step 831, loss 1.45322, accuracy 0.625, precision [0.0, 0.5, 1.0, 1.0, 0.5, nan, 1.0, 0.0, nan], recall [nan, 1.0, 1.0, 0.375, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T17:59:51.237104: step 832, loss 1.16469, accuracy 0.75, precision [nan, 0.6666666666666666, 0.75, 0.8, 1.0, 0.5, nan, 1.0, nan], recall [nan, 1.0, 0.75, 0.6666666666666666, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T17:59:51.387483: step 833, loss 1.22435, accuracy 0.5, precision [1.0, 0.5, nan, 0.42857142857142855, 0.5, 1.0, nan, 0.0, nan], recall [1.0, 0.25, 0.0, 0.75, 0.5, 0.5, 0.0, nan, nan]
2019-02-19T17:59:51.539794: step 834, loss 1.50399, accuracy 0.6875, precision [0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, nan, 0.5, nan], recall [0.0, 1.0, 1.0, 0.625, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T17:59:51.696948: step 835, loss 1.29381, accuracy 0.6875, precision [1.0, nan, 1.0, 1.0, 1.0, nan, nan, 0.4, 0.0], recall [0.5, nan, 0.5, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:51.847059: step 836, loss 1.10124, accuracy 0.8125, precision [1.0, 0.0, 1.0, 0.8571428571428571, 1.0, nan, 0.5, 1.0, nan], recall [0.75, nan, 0.5, 0.8571428571428571, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T17:59:52.000617: step 837, loss 1.76371, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.6, 0.75, 0.0, 0.0, 0.5, nan], recall [0.0, 0.0, 1.0, 0.6, 0.75, nan, nan, 1.0, nan]
2019-02-19T17:59:52.155523: step 838, loss 0.519345, accuracy 0.75, precision [nan, 1.0, 1.0, 0.6, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, 0.8333333333333334, 0.6, 0.75, nan, nan, nan, nan]
2019-02-19T17:59:52.309060: step 839, loss 1.82194, accuracy 0.3125, precision [0.3333333333333333, 0.3333333333333333, nan, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.3333333333333333, 0.5, nan, 0.14285714285714285, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T17:59:52.466969: step 840, loss 1.42464, accuracy 0.6875, precision [1.0, 0.6, nan, 0.75, 1.0, nan, 0.0, 0.6666666666666666, nan], recall [0.5, 0.75, nan, 0.6, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:59:52.621102: step 841, loss 0.948674, accuracy 0.625, precision [nan, 0.5, 0.0, 0.8571428571428571, 1.0, 1.0, nan, 0.0, nan], recall [0.0, 0.6666666666666666, nan, 0.6666666666666666, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T17:59:52.771791: step 842, loss 0.99073, accuracy 0.75, precision [1.0, nan, 0.0, 1.0, 1.0, 0.0, 1.0, nan, 0.5], recall [0.6666666666666666, nan, nan, 0.7, 1.0, nan, 1.0, nan, 1.0]
2019-02-19T17:59:52.925942: step 843, loss 0.791048, accuracy 0.75, precision [nan, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, nan, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.5555555555555556, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:53.083639: step 844, loss 2.30725, accuracy 0.3125, precision [0.0, 0.5, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, nan], recall [0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, nan, 1.0, nan]
2019-02-19T17:59:53.234894: step 845, loss 1.60546, accuracy 0.5, precision [0.5, nan, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.0], recall [0.75, 0.0, nan, 0.5714285714285714, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T17:59:53.391297: step 846, loss 1.40323, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6, 0.0, nan], recall [1.0, 1.0, 0.0, 0.0, 0.75, nan, 1.0, nan, nan]
2019-02-19T17:59:53.544877: step 847, loss 1.24114, accuracy 0.625, precision [0.5, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, nan], recall [1.0, 1.0, 0.5, 0.3333333333333333, 0.6666666666666666, nan, 1.0, 1.0, nan]
2019-02-19T17:59:53.694507: step 848, loss 2.77989, accuracy 0.3125, precision [0.0, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, nan, 0.3333333333333333, 0.5, nan, nan, 0.0, 0.25, nan]
2019-02-19T17:59:53.850569: step 849, loss 1.93303, accuracy 0.25, precision [0.0, 0.3333333333333333, nan, 0.25, 0.5, 0.0, nan, 1.0, 0.0], recall [0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.5, nan]
2019-02-19T17:59:54.002437: step 850, loss 1.34094, accuracy 0.5, precision [nan, 0.4, 1.0, 1.0, nan, 0.0, nan, 0.6666666666666666, nan], recall [0.0, 0.5, 1.0, 0.42857142857142855, nan, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:59:54.157625: step 851, loss 1.6827, accuracy 0.5625, precision [1.0, 0.5, 1.0, 1.0, nan, 0.0, 0.0, 0.5, 0.0], recall [0.3333333333333333, 1.0, 0.6666666666666666, 0.5, nan, 0.0, nan, 1.0, nan]
2019-02-19T17:59:54.310150: step 852, loss 1.23274, accuracy 0.4375, precision [0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.3333333333333333, nan, nan, 0.2857142857142857, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T17:59:54.463586: step 853, loss 1.16474, accuracy 0.4375, precision [nan, 0.3333333333333333, 0.5, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.5, nan], recall [0.0, 0.5, 0.5, 0.5, 1.0, nan, nan, 0.2, nan]
2019-02-19T17:59:54.623307: step 854, loss 1.06602, accuracy 0.625, precision [1.0, 0.75, 0.6666666666666666, 0.6666666666666666, 0.5, 0.0, 1.0, nan, nan], recall [1.0, 0.75, 1.0, 0.4, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T17:59:54.777386: step 855, loss 1.31701, accuracy 0.4375, precision [nan, 1.0, 0.3333333333333333, 0.2, 0.5, nan, 1.0, 0.3333333333333333, nan], recall [0.0, 1.0, 1.0, 0.25, 0.5, nan, 1.0, 0.25, nan]
2019-02-19T17:59:54.930049: step 856, loss 1.75343, accuracy 0.5, precision [nan, 0.6666666666666666, 0.0, 0.75, 0.5, 0.0, 1.0, 1.0, 0.0], recall [0.0, 0.5, 0.0, 0.5, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T17:59:55.088982: step 857, loss 1.35245, accuracy 0.625, precision [0.3333333333333333, 1.0, 0.5, 0.6, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T17:59:55.244306: step 858, loss 1.12166, accuracy 0.625, precision [nan, 0.5, nan, 0.6, 1.0, 1.0, 1.0, 0.5, 0.0], recall [0.0, 1.0, 0.0, 0.75, 1.0, 1.0, 1.0, 1.0, nan]
2019-02-19T17:59:55.400577: step 859, loss 1.30497, accuracy 0.6875, precision [1.0, nan, 1.0, 0.6, 0.6, nan, nan, 1.0, 0.0], recall [1.0, 0.0, 0.6666666666666666, 0.75, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T17:59:55.553858: step 860, loss 1.31494, accuracy 0.5625, precision [1.0, 1.0, 0.5, 0.3333333333333333, 0.75, nan, 0.0, 0.0, nan], recall [1.0, 0.75, 1.0, 0.2, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T17:59:55.706289: step 861, loss 1.15208, accuracy 0.625, precision [1.0, 0.75, 1.0, 0.0, 0.75, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.75, 1.0, 0.0, 0.75, nan, nan, 0.5, 0.0]
2019-02-19T17:59:55.864674: step 862, loss 1.11803, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.3333333333333333, 0.75, nan, nan, 0.6666666666666666, nan], recall [nan, 0.5, 0.6666666666666666, 0.2, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T17:59:56.021869: step 863, loss 1.82623, accuracy 0.4375, precision [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0], recall [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.5, 0.0, 0.5, 0.0]
2019-02-19T17:59:56.170469: step 864, loss 1.24571, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.5, nan, nan, nan, 0.5, nan], recall [1.0, 0.8333333333333334, 1.0, 1.0, 0.0, nan, 0.0, 0.5, 0.0]
2019-02-19T17:59:56.333049: step 865, loss 2.27519, accuracy 0.375, precision [0.0, 0.6666666666666666, 0.5, 1.0, 0.25, 0.3333333333333333, 0.0, nan, 0.0], recall [nan, 0.5, 1.0, 0.25, 0.5, 0.5, 0.0, nan, nan]
2019-02-19T17:59:56.484633: step 866, loss 1.2134, accuracy 0.625, precision [0.5, 1.0, 0.5, 0.25, 0.8, nan, nan, 1.0, nan], recall [0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.5, 0.0]
2019-02-19T17:59:56.639729: step 867, loss 1.0539, accuracy 0.5625, precision [0.0, 0.8, nan, 0.6, 1.0, nan, 0.3333333333333333, nan, nan], recall [nan, 0.6666666666666666, 0.0, 0.6, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:56.793549: step 868, loss 0.848768, accuracy 0.6875, precision [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, nan, nan, nan], recall [1.0, 0.4, 1.0, 1.0, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:56.947516: step 869, loss 1.75925, accuracy 0.25, precision [nan, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0], recall [nan, 0.0, 0.6666666666666666, 0.16666666666666666, nan, 1.0, 0.0, 0.0, nan]
2019-02-19T17:59:57.104311: step 870, loss 1.4614, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.4, 1.0, 1.0, nan, 0.3333333333333333, 1.0], recall [nan, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0]
2019-02-19T17:59:57.260182: step 871, loss 1.09111, accuracy 0.6875, precision [1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 0.6666666666666666, 0.5714285714285714, 1.0, nan, nan, nan, nan]
2019-02-19T17:59:57.412074: step 872, loss 1.65644, accuracy 0.4375, precision [0.0, 0.5, 0.5, 0.6666666666666666, nan, 0.0, nan, 1.0, 0.0], recall [nan, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, nan, 1.0, nan]
2019-02-19T17:59:57.565201: step 873, loss 1.21189, accuracy 0.625, precision [nan, 0.6666666666666666, 0.0, 0.5714285714285714, 1.0, 0.0, nan, nan, 1.0], recall [nan, 0.6666666666666666, 0.0, 0.6666666666666666, 0.75, nan, 0.0, nan, 1.0]
2019-02-19T17:59:57.719224: step 874, loss 1.01747, accuracy 0.75, precision [0.0, 1.0, 1.0, 0.8, 1.0, nan, 1.0, 0.0, 0.0], recall [0.0, 1.0, 1.0, 0.8, 0.8333333333333334, nan, 1.0, 0.0, nan]
2019-02-19T17:59:57.873955: step 875, loss 1.24065, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.6, 1.0, 0.5, 1.0, 0.25, nan], recall [nan, 0.0, 0.0, 0.6, 0.5, 1.0, 1.0, 0.5, nan]
2019-02-19T17:59:58.030963: step 876, loss 1.58206, accuracy 0.5, precision [1.0, 1.0, nan, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0], recall [1.0, 0.2, nan, 0.5, 0.5, nan, nan, 0.75, nan]
2019-02-19T17:59:58.186995: step 877, loss 1.31651, accuracy 0.6875, precision [1.0, 1.0, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6, nan, nan, 1.0, nan]
2019-02-19T17:59:58.341531: step 878, loss 1.1035, accuracy 0.625, precision [0.6666666666666666, 0.0, 0.5, 0.6, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 0.6, 1.0, nan, nan, 0.4, nan]
2019-02-19T17:59:58.496461: step 879, loss 1.74208, accuracy 0.4375, precision [1.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.5, 0.0, nan, 0.5, nan], recall [0.5, 1.0, 0.5, 0.3333333333333333, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T17:59:58.656783: step 880, loss 1.5539, accuracy 0.5, precision [0.3333333333333333, 0.0, nan, 0.6666666666666666, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [1.0, nan, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.5, nan]
2019-02-19T17:59:58.807813: step 881, loss 1.30019, accuracy 0.625, precision [0.5, 0.0, 1.0, 0.5, 0.8333333333333334, nan, 0.5, 1.0, nan], recall [0.5, 0.0, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T17:59:58.969670: step 882, loss 1.04163, accuracy 0.6875, precision [nan, nan, nan, 0.7777777777777778, 0.6666666666666666, 0.0, 1.0, 0.0, nan], recall [0.0, 0.0, 0.0, 0.875, 1.0, nan, 1.0, nan, nan]
2019-02-19T17:59:59.124800: step 883, loss 1.86665, accuracy 0.3125, precision [0.3333333333333333, 0.3333333333333333, nan, 0.6666666666666666, nan, nan, 0.0, 0.0, nan], recall [0.5, 1.0, 0.0, 0.2222222222222222, nan, 0.0, nan, nan, 0.0]
2019-02-19T17:59:59.282131: step 884, loss 0.710381, accuracy 0.8125, precision [1.0, 0.3333333333333333, nan, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T17:59:59.433767: step 885, loss 1.47963, accuracy 0.5, precision [0.5, nan, nan, 0.8, 0.6666666666666666, 0.0, 1.0, 0.0, nan], recall [0.5, 0.0, nan, 0.4444444444444444, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T17:59:59.591200: step 886, loss 1.4408, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.2, 0.0, 0.6666666666666666, nan, 1.0, 1.0, nan], recall [0.5, 0.6666666666666666, 1.0, 0.0, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T17:59:59.746433: step 887, loss 1.07361, accuracy 0.5, precision [0.0, 1.0, 0.0, 0.625, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 1.0, nan, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T17:59:59.899306: step 888, loss 1.48694, accuracy 0.625, precision [1.0, 0.0, 0.5, 0.5, 1.0, nan, nan, nan, nan], recall [0.6666666666666666, 0.0, 1.0, 1.0, 0.6, nan, nan, 0.0, nan]
2019-02-19T18:00:00.055173: step 889, loss 1.11632, accuracy 0.5, precision [0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, nan, 0.5, 0.0], recall [1.0, nan, 1.0, 0.36363636363636365, nan, 1.0, 0.0, 1.0, nan]
2019-02-19T18:00:00.210887: step 890, loss 2.09698, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.3333333333333333, nan, 0.6666666666666666, nan], recall [1.0, 1.0, nan, 0.2, 0.6666666666666666, 1.0, 0.0, 0.5, nan]
2019-02-19T18:00:00.366621: step 891, loss 1.58031, accuracy 0.4375, precision [0.5, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, nan, 1.0, nan], recall [0.25, nan, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:00:00.521990: step 892, loss 1.33281, accuracy 0.5, precision [1.0, 0.0, 1.0, 0.6, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [0.3333333333333333, nan, 1.0, 0.5, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:00:00.675651: step 893, loss 1.06824, accuracy 0.5625, precision [1.0, 0.0, 0.75, 0.8, 0.5, 0.0, nan, nan, nan], recall [0.5, nan, 1.0, 0.4444444444444444, 0.5, nan, nan, nan, nan]
2019-02-19T18:00:00.831998: step 894, loss 1.45779, accuracy 0.625, precision [nan, 0.0, 1.0, 0.8333333333333334, 0.75, nan, 0.0, 1.0, nan], recall [nan, nan, 0.25, 0.7142857142857143, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:00.984429: step 895, loss 0.78484, accuracy 0.75, precision [nan, 0.5, 1.0, 0.5714285714285714, 1.0, nan, 1.0, nan, nan], recall [0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, nan, nan]
2019-02-19T18:00:01.138220: step 896, loss 1.95218, accuracy 0.5, precision [0.0, 0.25, 0.0, 1.0, 1.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.0, 0.7142857142857143, 0.25, 0.0, nan, 0.5, nan]
2019-02-19T18:00:01.289080: step 897, loss 1.02815, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.5714285714285714, 1.0, 0.0, nan, nan, nan], recall [0.0, 1.0, 0.2, 1.0, 0.8, nan, nan, nan, nan]
2019-02-19T18:00:01.442349: step 898, loss 2.01639, accuracy 0.5, precision [1.0, 1.0, nan, 0.5714285714285714, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.25, 0.6666666666666666, 0.0, 0.8, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:01.596660: step 899, loss 1.76912, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.0, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.4, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:00:01.751545: step 900, loss 0.709846, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan], recall [1.0, nan, 0.6666666666666666, 0.8, 0.5, 0.0, nan, 0.5, 0.0]
2019-02-19T18:00:01.904632: step 901, loss 1.41769, accuracy 0.5625, precision [0.6, 0.0, 1.0, 0.5, 1.0, nan, nan, 0.5, nan], recall [1.0, 0.0, 0.5, 0.75, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T18:00:02.063809: step 902, loss 0.944691, accuracy 0.5625, precision [1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.5, 0.3333333333333333, nan], recall [0.5, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, nan]
2019-02-19T18:00:02.215236: step 903, loss 1.47197, accuracy 0.3125, precision [0.0, 1.0, 1.0, 0.16666666666666666, nan, 0.0, nan, nan, 0.0], recall [nan, 0.3333333333333333, 0.6666666666666666, 0.2, nan, nan, 0.0, 0.0, nan]
2019-02-19T18:00:02.369875: step 904, loss 1.21841, accuracy 0.5625, precision [0.6666666666666666, nan, 1.0, 0.2857142857142857, 1.0, nan, 0.0, 1.0, nan], recall [0.6666666666666666, 0.0, 0.5, 1.0, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:02.521311: step 905, loss 1.78928, accuracy 0.3125, precision [0.0, 0.0, 0.6666666666666666, 0.4, 1.0, nan, nan, 0.0, 0.0], recall [nan, nan, 0.5, 0.25, 0.5, nan, nan, 0.0, 0.0]
2019-02-19T18:00:02.678191: step 906, loss 1.49757, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.8, 0.5, 0.0, nan, 0.5, nan], recall [nan, 0.25, 0.0, 0.5714285714285714, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:02.832704: step 907, loss 1.09036, accuracy 0.5625, precision [nan, 0.75, nan, 0.6666666666666666, 0.5, nan, nan, 0.25, nan], recall [nan, 0.6, 0.0, 0.5714285714285714, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:02.983087: step 908, loss 0.882513, accuracy 0.75, precision [0.5, 0.5, nan, 1.0, 1.0, nan, 0.5, 1.0, nan], recall [1.0, 1.0, nan, 0.5, 1.0, 0.0, 0.5, 1.0, nan]
2019-02-19T18:00:03.139366: step 909, loss 1.41667, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0, 0.0], recall [0.0, 0.75, nan, 0.5, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:03.294567: step 910, loss 1.29575, accuracy 0.5, precision [0.5, 0.75, 0.0, 0.8, 0.0, 0.0, nan, 0.0, 0.0], recall [0.5, 0.6, nan, 0.4444444444444444, nan, nan, nan, nan, nan]
2019-02-19T18:00:03.453094: step 911, loss 1.02144, accuracy 0.625, precision [0.0, nan, 0.3333333333333333, 0.8571428571428571, 0.6666666666666666, nan, 1.0, nan, nan], recall [nan, 0.0, 1.0, 0.6666666666666666, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:00:03.606312: step 912, loss 1.94749, accuracy 0.625, precision [0.0, 0.6, nan, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.0], recall [nan, 1.0, nan, 0.4444444444444444, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:00:03.759206: step 913, loss 1.708, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan], recall [0.6666666666666666, 0.0, nan, 0.2857142857142857, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:03.910128: step 914, loss 1.42374, accuracy 0.625, precision [1.0, 1.0, 0.6666666666666666, 0.5, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [1.0, 0.75, 0.6666666666666666, 0.4, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:04.064188: step 915, loss 1.49871, accuracy 0.5, precision [0.0, 0.5, 0.0, 1.0, 1.0, nan, nan, 0.4, nan], recall [nan, 1.0, nan, 0.4, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:00:04.213380: step 916, loss 2.38365, accuracy 0.3125, precision [0.3333333333333333, 0.0, nan, 0.5714285714285714, 0.0, 0.0, nan, nan, 0.0], recall [0.3333333333333333, 0.0, nan, 0.6666666666666666, nan, 0.0, 0.0, 0.0, nan]
2019-02-19T18:00:04.366892: step 917, loss 1.53276, accuracy 0.5, precision [0.5, nan, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.5, nan], recall [0.5, 0.0, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:04.516673: step 918, loss 1.75908, accuracy 0.375, precision [nan, 0.0, 0.5, 0.6, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [0.0, 0.0, 1.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:04.672256: step 919, loss 2.03762, accuracy 0.75, precision [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 1.0, nan, 0.7142857142857143, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:00:04.825161: step 920, loss 1.19207, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.5, 1.0, nan, nan, nan, nan], recall [0.5, 0.5, nan, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:04.983033: step 921, loss 1.51281, accuracy 0.5, precision [0.0, 0.5714285714285714, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [nan, 0.8, 1.0, 0.16666666666666666, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:00:05.140617: step 922, loss 1.20823, accuracy 0.5625, precision [0.0, 0.25, 1.0, 0.8333333333333334, 0.3333333333333333, nan, nan, 1.0, nan], recall [0.0, 0.5, 0.5, 0.5555555555555556, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:05.293677: step 923, loss 1.3113, accuracy 0.625, precision [1.0, 0.5, 0.5, 1.0, 1.0, nan, 0.0, 0.6666666666666666, nan], recall [0.5, 1.0, 0.5, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:05.449020: step 924, loss 2.04996, accuracy 0.4375, precision [nan, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.5, 0.3333333333333333, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:00:05.607648: step 925, loss 1.20824, accuracy 0.5625, precision [1.0, 0.6, nan, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan], recall [1.0, 0.75, 0.0, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:05.761597: step 926, loss 1.37017, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [0.6666666666666666, 0.5, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:05.915622: step 927, loss 1.34179, accuracy 0.625, precision [nan, 0.3333333333333333, nan, 0.8333333333333334, 1.0, nan, 1.0, 0.0, nan], recall [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, nan, 1.0, nan, nan]
2019-02-19T18:00:06.067302: step 928, loss 0.87878, accuracy 0.75, precision [0.0, 1.0, 0.5, 0.8, 1.0, nan, 0.0, 1.0, nan], recall [nan, 1.0, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:00:06.221574: step 929, loss 0.896888, accuracy 0.625, precision [1.0, 0.5, 0.0, 0.5, 1.0, nan, nan, nan, nan], recall [0.3333333333333333, 1.0, 0.0, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:06.374606: step 930, loss 1.12851, accuracy 0.625, precision [nan, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [0.0, 0.3333333333333333, 1.0, 0.8, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:06.534201: step 931, loss 1.71441, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.5, 0.5, 0.0, nan, nan, 0.0], recall [0.0, nan, 0.6666666666666666, 0.375, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T18:00:06.683037: step 932, loss 1.20487, accuracy 0.5, precision [0.5, 0.3333333333333333, 0.0, 0.6, 1.0, 0.0, nan, 1.0, 0.0], recall [0.3333333333333333, 0.3333333333333333, 0.0, 0.6, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:06.841114: step 933, loss 1.16748, accuracy 0.6875, precision [0.5, 0.5, 0.0, 0.8, 1.0, nan, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.5714285714285714, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:06.995069: step 934, loss 1.40693, accuracy 0.5, precision [1.0, 0.3333333333333333, nan, 0.6, 0.5, 0.0, nan, 1.0, 0.5], recall [1.0, 0.25, 0.0, 0.6, 1.0, nan, nan, 0.3333333333333333, 1.0]
2019-02-19T18:00:07.150769: step 935, loss 1.21115, accuracy 0.625, precision [nan, 0.5, 1.0, 0.75, 0.6666666666666666, 0.0, nan, 0.6666666666666666, nan], recall [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:00:07.306217: step 936, loss 0.986902, accuracy 0.625, precision [0.6666666666666666, 1.0, nan, 0.375, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.25, 0.0, 0.75, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:07.457620: step 937, loss 1.85799, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.0, 0.75, 0.0, nan, nan, nan], recall [nan, 0.6, 0.3333333333333333, 0.0, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:00:07.611704: step 938, loss 0.757461, accuracy 0.8125, precision [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, nan], recall [0.6666666666666666, 1.0, 1.0, 0.8, 0.6666666666666666, nan, 1.0, 1.0, nan]
2019-02-19T18:00:07.767681: step 939, loss 1.295, accuracy 0.625, precision [nan, 0.3333333333333333, 0.5, 0.75, 0.8, nan, nan, nan, nan], recall [nan, 1.0, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:00:07.921332: step 940, loss 2.12701, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.75, 0.3333333333333333, nan, 1.0, 0.6666666666666666, nan], recall [nan, 0.0, 0.5, 0.75, 0.5, 0.0, 1.0, 0.6666666666666666, nan]
2019-02-19T18:00:08.073527: step 941, loss 1.37382, accuracy 0.5625, precision [1.0, 0.75, 0.0, 0.5, 0.5, nan, nan, 0.6666666666666666, nan], recall [0.5, 0.6, nan, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:08.229255: step 942, loss 1.26074, accuracy 0.5625, precision [0.5, 0.5, 0.0, 0.6666666666666666, 0.8, nan, nan, 0.0, nan], recall [1.0, 0.5, nan, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:08.387891: step 943, loss 1.86529, accuracy 0.5, precision [nan, 0.5, 1.0, 0.5, 0.6666666666666666, nan, 0.0, 1.0, 0.0], recall [0.0, 0.25, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:08.540677: step 944, loss 1.55416, accuracy 0.625, precision [nan, 1.0, 0.5, 0.75, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.8, 0.5, 0.42857142857142855, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:08.695070: step 945, loss 1.74308, accuracy 0.5, precision [0.5, 0.0, 0.0, 0.8333333333333334, 0.5, 0.0, 0.0, 1.0, nan], recall [1.0, 0.0, 0.0, 0.625, 0.3333333333333333, nan, nan, 0.5, nan]
2019-02-19T18:00:08.848561: step 946, loss 1.31901, accuracy 0.625, precision [nan, 0.0, 0.0, 0.8571428571428571, 0.5, 0.5, 0.0, 1.0, nan], recall [nan, 0.0, nan, 0.8571428571428571, 0.3333333333333333, 1.0, nan, 1.0, 0.0]
2019-02-19T18:00:09.007424: step 947, loss 1.30446, accuracy 0.375, precision [0.5, 0.0, 0.4, 0.3333333333333333, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [1.0, 0.0, 1.0, 0.125, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:00:09.164077: step 948, loss 1.55331, accuracy 0.625, precision [nan, 0.0, 0.3333333333333333, 0.8, 1.0, 0.0, nan, 0.5, nan], recall [nan, nan, 1.0, 0.5714285714285714, 1.0, 0.0, nan, 1.0, 0.0]
2019-02-19T18:00:09.313994: step 949, loss 1.06156, accuracy 0.625, precision [0.0, 0.5, 1.0, 0.75, 1.0, 0.5, nan, 0.0, nan], recall [0.0, 0.5, 1.0, 0.75, 0.8, 1.0, 0.0, 0.0, nan]
2019-02-19T18:00:09.469927: step 950, loss 1.49991, accuracy 0.4375, precision [0.0, 0.25, 0.0, 0.0, 1.0, 1.0, nan, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.0, 0.8, 1.0, nan, 0.0, nan]
2019-02-19T18:00:09.624660: step 951, loss 1.31027, accuracy 0.5, precision [0.0, 0.5, nan, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 0.5, nan, 0.5714285714285714, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:00:09.785707: step 952, loss 2.63609, accuracy 0.1875, precision [0.0, 0.0, 0.0, 0.5, 0.25, 0.0, nan, 1.0, 0.0], recall [nan, nan, 0.0, 0.125, 0.5, nan, nan, 0.2, nan]
2019-02-19T18:00:09.946472: step 953, loss 0.792654, accuracy 0.8125, precision [1.0, 1.0, 1.0, 0.75, 1.0, nan, 0.0, nan, nan], recall [1.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:10.102188: step 954, loss 2.23976, accuracy 0.375, precision [nan, 0.2, 0.5, 0.6, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.5, 1.0, 0.42857142857142855, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:00:10.253944: step 955, loss 1.19631, accuracy 0.4375, precision [1.0, 0.0, 0.5, 0.2857142857142857, 1.0, 0.0, nan, 1.0, nan], recall [0.6666666666666666, 0.0, 0.3333333333333333, 0.4, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:10.408718: step 956, loss 1.51079, accuracy 0.6875, precision [nan, 0.6, 0.5, 1.0, 1.0, nan, nan, 0.0, 0.0], recall [nan, 0.75, 1.0, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:10.559203: step 957, loss 1.34415, accuracy 0.625, precision [nan, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, nan, 0.3333333333333333, nan], recall [nan, 0.6666666666666666, 0.25, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:10.716097: step 958, loss 1.2269, accuracy 0.75, precision [0.3333333333333333, 1.0, 1.0, 0.5, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.8, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:00:10.869103: step 959, loss 0.975183, accuracy 0.625, precision [0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:11.023679: step 960, loss 0.841248, accuracy 0.8125, precision [0.6666666666666666, 0.6666666666666666, 1.0, 1.0, nan, 0.0, nan, nan, nan], recall [1.0, 1.0, 0.5, 0.875, nan, nan, nan, nan, nan]
2019-02-19T18:00:11.179316: step 961, loss 1.64391, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.75, 0.25, nan, nan, 0.5, nan], recall [nan, 1.0, 0.75, 0.6, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:11.343048: step 962, loss 1.80357, accuracy 0.5, precision [0.5, 0.75, 0.0, 0.5, 1.0, 0.0, nan, nan, 0.0], recall [1.0, 0.75, nan, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:00:11.493674: step 963, loss 1.46875, accuracy 0.625, precision [nan, 0.3333333333333333, nan, 0.6, 1.0, nan, nan, 0.3333333333333333, nan], recall [nan, 0.3333333333333333, nan, 0.6, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:11.647514: step 964, loss 1.2326, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.875, nan, nan, nan, 0.4, nan], recall [nan, 0.0, nan, 0.7, 0.0, nan, nan, 1.0, nan]
2019-02-19T18:00:11.802900: step 965, loss 1.16224, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.6, 1.0, 0.0, nan, 0.0, 0.0], recall [nan, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:11.956722: step 966, loss 1.90193, accuracy 0.375, precision [nan, 0.6666666666666666, nan, 0.3333333333333333, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.0, 0.2857142857142857, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:00:12.115082: step 967, loss 1.65985, accuracy 0.5625, precision [nan, 0.5, 1.0, 0.5, 0.75, 0.0, nan, 0.5, nan], recall [nan, 1.0, 1.0, 0.2857142857142857, 0.75, nan, 0.0, 1.0, nan]
2019-02-19T18:00:12.269650: step 968, loss 1.61247, accuracy 0.4375, precision [0.5, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, nan, 0.0, 0.5, nan], recall [1.0, 0.2857142857142857, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:12.431836: step 969, loss 1.6417, accuracy 0.375, precision [0.0, nan, 0.5, 0.5, 0.5, 0.0, nan, 0.0, nan], recall [nan, 0.0, 0.5, 0.42857142857142855, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:00:12.588594: step 970, loss 1.80731, accuracy 0.5625, precision [0.5, 1.0, nan, 0.625, nan, nan, 0.0, 1.0, 0.0], recall [1.0, 0.6666666666666666, 0.0, 0.7142857142857143, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:00:12.743455: step 971, loss 1.56459, accuracy 0.625, precision [1.0, 0.6, nan, 0.5, 1.0, 0.0, nan, 0.5, 0.0], recall [0.5, 0.6, nan, 1.0, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:00:12.899339: step 972, loss 1.75534, accuracy 0.5625, precision [0.0, 1.0, nan, 0.8, 0.8, 0.0, 0.0, 0.0, nan], recall [nan, 0.3333333333333333, nan, 0.6666666666666666, 0.8, nan, nan, 0.0, nan]
2019-02-19T18:00:13.057606: step 973, loss 1.08245, accuracy 0.6875, precision [nan, 0.5, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, nan], recall [nan, 0.5, 0.6666666666666666, 0.5, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:13.211014: step 974, loss 1.59685, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.6666666666666666, 0.0, nan, nan, 1.0, 0.0], recall [0.5, 1.0, 1.0, 0.5714285714285714, nan, nan, 0.0, 1.0, nan]
2019-02-19T18:00:13.366647: step 975, loss 1.12334, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.75, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 1.0, 0.5, 0.8571428571428571, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:00:13.516419: step 976, loss 1.27734, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.0, 0.5, 0.5, 0.0, nan, 1.0, nan], recall [0.5, 0.6666666666666666, nan, 0.6, 0.5, 0.0, 0.0, 0.5, nan]
2019-02-19T18:00:13.672925: step 977, loss 1.28335, accuracy 0.5, precision [0.0, 0.0, nan, 0.75, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.0, 0.0, nan, 0.6, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:13.829726: step 978, loss 1.74735, accuracy 0.375, precision [0.5, 0.5, 0.0, 0.5714285714285714, 0.0, nan, 0.0, nan, nan], recall [0.3333333333333333, 0.5, nan, 0.6666666666666666, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:00:13.979924: step 979, loss 1.0383, accuracy 0.5, precision [nan, nan, 1.0, 0.375, 0.6, nan, nan, 0.5, nan], recall [nan, nan, 0.3333333333333333, 1.0, 0.6, 0.0, 0.0, 1.0, nan]
2019-02-19T18:00:14.133677: step 980, loss 1.5065, accuracy 0.3125, precision [0.3333333333333333, 0.75, nan, 0.25, 0.0, nan, 0.0, 0.0, nan], recall [1.0, 0.42857142857142855, 0.0, 0.3333333333333333, nan, nan, nan, 0.0, nan]
2019-02-19T18:00:14.289363: step 981, loss 1.79435, accuracy 0.625, precision [0.5, 0.0, 0.0, 1.0, 0.8, nan, nan, 1.0, 0.0], recall [1.0, 0.0, nan, 0.5714285714285714, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:00:14.446868: step 982, loss 1.45133, accuracy 0.4375, precision [0.0, nan, 0.0, 0.3333333333333333, 1.0, nan, 1.0, 0.0, 1.0], recall [nan, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, nan, 1.0]
2019-02-19T18:00:14.599681: step 983, loss 0.974551, accuracy 0.5, precision [nan, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, nan], recall [nan, 0.4, 0.6666666666666666, 0.2, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:00:14.754174: step 984, loss 1.04431, accuracy 0.5625, precision [1.0, 0.0, 0.0, 0.625, 1.0, nan, 1.0, nan, nan], recall [0.5, 0.0, nan, 0.625, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:00:14.905212: step 985, loss 2.18558, accuracy 0.3125, precision [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, nan, 0.0, nan], recall [0.3333333333333333, nan, 0.0, 0.4, 0.0, nan, nan, 0.0, nan]
2019-02-19T18:00:15.059073: step 986, loss 2.28403, accuracy 0.3125, precision [0.0, 0.0, nan, 0.6, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [0.0, nan, 0.0, 0.3, 0.5, nan, nan, nan, nan]
2019-02-19T18:00:15.215675: step 987, loss 1.56091, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.625, nan, 0.0, nan, nan, 0.0], recall [0.0, 0.6666666666666666, nan, 0.5555555555555556, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:00:15.373605: step 988, loss 1.457, accuracy 0.5625, precision [1.0, 0.25, nan, 0.8, 0.5, nan, nan, 0.5, 0.0], recall [1.0, 0.5, nan, 0.4444444444444444, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:00:15.531774: step 989, loss 2.02432, accuracy 0.5625, precision [nan, 0.6, 0.0, 1.0, nan, 0.0, 0.0, 1.0, nan], recall [nan, 0.75, nan, 0.5555555555555556, 0.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:15.686289: step 990, loss 1.7448, accuracy 0.4375, precision [1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.3333333333333333, nan], recall [1.0, nan, 0.5, 0.2857142857142857, 1.0, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T18:00:15.844217: step 991, loss 1.68249, accuracy 0.625, precision [1.0, 0.0, 0.0, 1.0, 1.0, nan, 0.0, 0.6666666666666666, 0.0], recall [0.5, 0.0, nan, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:16.002414: step 992, loss 1.72379, accuracy 0.625, precision [nan, 0.0, 0.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [0.0, nan, nan, 0.5, 0.8, nan, nan, 0.75, nan]
2019-02-19T18:00:16.157718: step 993, loss 1.40755, accuracy 0.5, precision [0.5, nan, 0.0, 0.8333333333333334, 0.6666666666666666, nan, nan, nan, nan], recall [1.0, nan, 0.0, 0.45454545454545453, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:00:16.310060: step 994, loss 1.61232, accuracy 0.5625, precision [nan, nan, 1.0, 0.7, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.0, 1.0, 0.7, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:00:16.464205: step 995, loss 0.834693, accuracy 0.75, precision [nan, 0.5, 0.5, 1.0, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [nan, 1.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:16.614295: step 996, loss 1.56226, accuracy 0.375, precision [0.0, 0.6666666666666666, 1.0, 0.2, 0.5, 0.0, nan, 0.0, nan], recall [nan, 1.0, 0.6666666666666666, 0.2, 0.25, nan, nan, 0.0, nan]
2019-02-19T18:00:16.772418: step 997, loss 1.52458, accuracy 0.5, precision [0.0, 0.5, 0.3333333333333333, 0.6666666666666666, 1.0, nan, nan, 0.5, nan], recall [nan, 0.5, 1.0, 0.5, 1.0, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:16.924242: step 998, loss 1.14605, accuracy 0.625, precision [0.0, nan, nan, 1.0, 1.0, 0.0, nan, 0.0, 0.0], recall [nan, nan, nan, 0.45454545454545453, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:17.078026: step 999, loss 1.59602, accuracy 0.4375, precision [0.0, 0.3333333333333333, nan, 0.25, 0.6666666666666666, 1.0, 0.0, 1.0, nan], recall [nan, 0.3333333333333333, 0.0, 0.25, 1.0, 1.0, 0.0, 0.5, nan]
2019-02-19T18:00:17.235555: step 1000, loss 1.19952, accuracy 0.5625, precision [0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.5, 0.6666666666666666, nan, 0.0, 0.0, nan]

Evaluation:
[[ 42  14   0  29   1   0   0   4   1]
 [  6  79   5  59   2   0   1   8   0]
 [  0   2  44  43   1   1   0   4   1]
 [  5  19  25 225   7   2   4  26   0]
 [  0   0   5  20 128   2   0   4   0]
 [  1   1   1  38   0  10   1   3   0]
 [  0   0   2  13   1   0  12   4   1]
 [  2   5   3  29   2   1   1  56   2]
 [  1   1   0  11   2   0   0   1   1]]
2019-02-19T18:00:19.657854: step 1000, loss 1.26516, accuracy 0.582439, precision [0.46153846153846156, 0.49375, 0.4583333333333333, 0.7188498402555911, 0.8050314465408805, 0.18181818181818182, 0.36363636363636365, 0.5544554455445545, 0.058823529411764705], recall [0.7368421052631579, 0.6528925619834711, 0.5176470588235295, 0.4817987152034261, 0.8888888888888888, 0.625, 0.631578947368421, 0.509090909090909, 0.16666666666666666]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-1000

2019-02-19T18:00:19.963910: step 1001, loss 1.43028, accuracy 0.5625, precision [0.0, 0.0, 0.6666666666666666, 0.75, 1.0, nan, 0.0, 0.5, nan], recall [0.0, nan, 0.6666666666666666, 0.42857142857142855, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:20.117870: step 1002, loss 1.43471, accuracy 0.625, precision [0.3333333333333333, 1.0, nan, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 0.75, 0.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:20.278976: step 1003, loss 1.35904, accuracy 0.625, precision [0.0, 0.75, 0.0, 0.8, 1.0, nan, nan, 1.0, 0.0], recall [nan, 0.75, nan, 0.5714285714285714, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:00:20.436731: step 1004, loss 1.03214, accuracy 0.5625, precision [0.5, nan, 0.0, 0.75, 0.8, 1.0, 0.0, 0.0, nan], recall [1.0, 0.0, nan, 0.375, 0.8, 1.0, nan, nan, nan]
2019-02-19T18:00:20.590818: step 1005, loss 1.32274, accuracy 0.4375, precision [0.0, 0.5, nan, 0.3333333333333333, 0.5, nan, nan, 1.0, nan], recall [0.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:20.749987: step 1006, loss 1.83956, accuracy 0.375, precision [0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:00:20.905101: step 1007, loss 1.35011, accuracy 0.5625, precision [nan, 0.5, 0.5, 0.5, 0.3333333333333333, nan, 1.0, 1.0, nan], recall [nan, 0.5, 0.3333333333333333, 0.75, 0.5, 0.0, 1.0, 0.6666666666666666, nan]
2019-02-19T18:00:21.062537: step 1008, loss 1.61233, accuracy 0.5625, precision [0.5, 0.3333333333333333, nan, 0.8333333333333334, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.25, 0.0, 0.7142857142857143, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:21.215884: step 1009, loss 0.992731, accuracy 0.6875, precision [0.5, 0.5, 0.0, 0.8, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.5, 0.5, nan, 1.0, 1.0, nan, nan, 0.4, nan]
2019-02-19T18:00:21.366824: step 1010, loss 1.76952, accuracy 0.5625, precision [1.0, nan, 0.0, 0.7, nan, 0.0, 1.0, nan, 0.0], recall [0.5, 0.0, 0.0, 0.7777777777777778, nan, nan, 1.0, 0.0, nan]
2019-02-19T18:00:21.523103: step 1011, loss 0.929657, accuracy 0.4375, precision [0.3333333333333333, 0.0, 1.0, 0.16666666666666666, 1.0, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.0, 0.3333333333333333, 0.25, 1.0, nan, nan, 0.4, nan]
2019-02-19T18:00:21.681882: step 1012, loss 1.23069, accuracy 0.625, precision [nan, 1.0, 0.5, 0.875, 0.0, nan, 0.0, 0.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.6363636363636364, nan, nan, nan, 0.0, nan]
2019-02-19T18:00:21.832683: step 1013, loss 1.57062, accuracy 0.375, precision [0.6666666666666666, 0.25, 0.3333333333333333, 0.5, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.5, 1.0, 0.14285714285714285, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:00:21.986594: step 1014, loss 2.08003, accuracy 0.4375, precision [1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, nan, 0.0, 1.0, 0.0], recall [1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:00:22.136397: step 1015, loss 1.87362, accuracy 0.4375, precision [0.3333333333333333, 0.0, nan, 0.7142857142857143, 0.5, nan, 0.0, nan, nan], recall [1.0, 0.0, nan, 0.7142857142857143, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:00:22.294894: step 1016, loss 0.997884, accuracy 0.6875, precision [1.0, 0.25, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, nan, nan], recall [1.0, 1.0, 1.0, 0.5714285714285714, 0.6666666666666666, nan, 1.0, nan, 0.0]
2019-02-19T18:00:22.449806: step 1017, loss 0.995281, accuracy 0.5625, precision [nan, 0.0, nan, 0.5, 1.0, nan, nan, 0.5, nan], recall [nan, 0.0, 0.0, 1.0, 0.75, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T18:00:22.599857: step 1018, loss 1.43046, accuracy 0.5, precision [1.0, 0.3333333333333333, 1.0, 0.4, 0.5, 0.0, nan, 0.5, nan], recall [0.5, 0.5, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, 0.0]
2019-02-19T18:00:22.755298: step 1019, loss 1.55209, accuracy 0.4375, precision [0.0, 0.0, 0.3333333333333333, 1.0, 0.75, 0.0, nan, 1.0, 0.0], recall [nan, 0.0, 1.0, 0.25, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:22.906984: step 1020, loss 1.06994, accuracy 0.5625, precision [0.0, 0.5, 0.0, 0.8, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [0.0, 1.0, nan, 0.5714285714285714, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:00:23.060989: step 1021, loss 1.41155, accuracy 0.4375, precision [0.3333333333333333, 0.0, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.0, 1.0, 0.2, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:00:23.219883: step 1022, loss 1.25505, accuracy 0.5625, precision [nan, 0.5, 1.0, 0.5, 0.8, 0.0, nan, 0.0, nan], recall [nan, 1.0, 0.5, 0.3333333333333333, 0.8, nan, nan, nan, nan]
2019-02-19T18:00:23.374677: step 1023, loss 1.84156, accuracy 0.5, precision [nan, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, nan], recall [0.0, 0.6666666666666666, 0.0, 0.5, nan, 1.0, nan, nan, nan]
2019-02-19T18:00:23.530132: step 1024, loss 0.919506, accuracy 0.6875, precision [nan, nan, 0.5, 1.0, 0.75, 0.5, 0.0, nan, nan], recall [nan, 0.0, 1.0, 0.5555555555555556, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:00:23.683307: step 1025, loss 0.960319, accuracy 0.5625, precision [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [1.0, 0.0, 0.0, 0.16666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:23.839101: step 1026, loss 1.01643, accuracy 0.6875, precision [0.5, 1.0, nan, 0.8, 1.0, 1.0, nan, 0.3333333333333333, nan], recall [1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:00:23.989689: step 1027, loss 1.74446, accuracy 0.5, precision [nan, 0.3333333333333333, 0.0, 0.8, 1.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 1.0, 0.0, 1.0, 0.5, nan, 0.0, 0.3333333333333333, nan]
2019-02-19T18:00:24.146019: step 1028, loss 0.865944, accuracy 0.75, precision [1.0, 0.6666666666666666, nan, 0.6, 1.0, 1.0, 0.5, 1.0, nan], recall [1.0, 1.0, 0.0, 0.6, 1.0, 0.5, 1.0, 1.0, nan]
2019-02-19T18:00:24.302210: step 1029, loss 1.53748, accuracy 0.625, precision [1.0, 0.0, nan, 0.5555555555555556, 1.0, nan, 1.0, 0.5, nan], recall [1.0, 0.0, nan, 0.8333333333333334, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, nan]
2019-02-19T18:00:24.453012: step 1030, loss 1.67528, accuracy 0.5625, precision [1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.5, nan, 1.0, 0.0, 0.0], recall [0.5, 0.4, 1.0, 0.3333333333333333, 0.6666666666666666, nan, 1.0, nan, nan]
2019-02-19T18:00:24.608816: step 1031, loss 1.14124, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.5, 0.0], recall [0.75, 0.5, nan, 0.25, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:24.760677: step 1032, loss 1.44805, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.0, 0.8, 0.0, nan, 0.5, nan], recall [nan, 0.5, 0.0, 0.0, 0.8, nan, nan, 0.5, 0.0]
2019-02-19T18:00:24.917782: step 1033, loss 1.00528, accuracy 0.5625, precision [0.75, nan, nan, 0.5, 1.0, 0.3333333333333333, nan, 0.0, nan], recall [1.0, 0.0, 0.0, 0.6, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:00:25.069066: step 1034, loss 1.06364, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.5, 0.6666666666666666, nan, nan, nan, nan], recall [0.5, 0.3333333333333333, nan, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:25.224659: step 1035, loss 0.860563, accuracy 0.6875, precision [0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.75, nan, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 0.5, 0.75, nan, nan, 0.75, nan]
2019-02-19T18:00:25.379006: step 1036, loss 1.0578, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5, 1.0], recall [0.6666666666666666, 0.6, 0.5, 1.0, 1.0, nan, nan, 1.0, 0.5]
2019-02-19T18:00:25.535780: step 1037, loss 1.46812, accuracy 0.375, precision [nan, 1.0, 0.5, 0.25, 1.0, 0.0, 0.0, 0.0, nan], recall [nan, 0.6, 0.5, 0.25, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:00:25.695521: step 1038, loss 0.829564, accuracy 0.6875, precision [0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, nan, nan], recall [1.0, 0.5, 1.0, 0.6666666666666666, 0.75, nan, 0.5, nan, nan]
2019-02-19T18:00:25.855605: step 1039, loss 1.16305, accuracy 0.6875, precision [nan, 0.5, 0.5, 0.8, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 1.0, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:26.008711: step 1040, loss 1.08873, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, nan], recall [1.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, nan]
2019-02-19T18:00:26.163040: step 1041, loss 1.97219, accuracy 0.375, precision [1.0, 0.0, nan, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.5, 0.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:26.318708: step 1042, loss 0.992137, accuracy 0.6875, precision [nan, 0.5, 1.0, 0.75, 0.6666666666666666, nan, nan, nan, nan], recall [nan, 1.0, 0.3333333333333333, 0.8571428571428571, 0.6666666666666666, 0.0, nan, nan, nan]
2019-02-19T18:00:26.470171: step 1043, loss 1.05692, accuracy 0.625, precision [0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, nan, nan], recall [1.0, 0.25, 0.75, 0.0, 0.6666666666666666, nan, 1.0, nan, nan]
2019-02-19T18:00:26.621466: step 1044, loss 1.37606, accuracy 0.75, precision [nan, nan, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], recall [nan, nan, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.6666666666666666, 1.0]
2019-02-19T18:00:26.777046: step 1045, loss 1.67384, accuracy 0.5, precision [1.0, 0.75, nan, 0.25, 0.5, 1.0, 1.0, 0.0, 0.0], recall [0.5, 0.75, nan, 0.25, 0.5, 1.0, 0.5, 0.0, nan]
2019-02-19T18:00:26.932411: step 1046, loss 0.70172, accuracy 0.75, precision [1.0, 1.0, 0.8, 0.5, 0.5, nan, nan, 0.0, nan], recall [1.0, 0.6, 0.8, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:27.082068: step 1047, loss 1.36491, accuracy 0.5, precision [0.5, 0.25, 0.0, 0.5, 1.0, nan, nan, nan, nan], recall [1.0, 0.5, nan, 0.5, 0.75, 0.0, nan, 0.0, nan]
2019-02-19T18:00:27.237871: step 1048, loss 1.3135, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.5, 1.0, nan, nan, 0.0, nan], recall [0.5, 1.0, nan, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:27.387938: step 1049, loss 1.74329, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.5, 0.5, nan, 0.0, 0.5, 0.0], recall [0.0, 0.25, 0.6666666666666666, 0.4, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:27.540567: step 1050, loss 0.995273, accuracy 0.75, precision [0.0, 1.0, 0.5, 1.0, 1.0, 1.0, nan, 0.5, 1.0], recall [0.0, 0.3333333333333333, 1.0, 0.8, 1.0, 1.0, nan, 1.0, 1.0]
2019-02-19T18:00:27.694729: step 1051, loss 0.874632, accuracy 0.625, precision [0.0, 0.6666666666666666, nan, 0.6, 0.75, 1.0, nan, 1.0, nan], recall [0.0, 1.0, 0.0, 0.6, 1.0, 0.5, nan, 0.5, nan]
2019-02-19T18:00:27.844985: step 1052, loss 0.438918, accuracy 0.875, precision [1.0, 1.0, 1.0, 0.875, 0.5, nan, nan, 1.0, nan], recall [1.0, 0.5, 1.0, 0.875, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:27.998418: step 1053, loss 1.41407, accuracy 0.5625, precision [nan, 0.0, 0.0, 1.0, 0.75, 0.0, nan, 0.5, nan], recall [nan, 0.0, nan, 0.5, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:28.153204: step 1054, loss 1.25077, accuracy 0.6875, precision [1.0, 0.8333333333333334, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.0, 0.0], recall [1.0, 0.8333333333333334, 1.0, 0.4, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:00:28.308812: step 1055, loss 1.38654, accuracy 0.5625, precision [1.0, 0.0, 0.75, 0.6666666666666666, 1.0, nan, nan, 0.0, nan], recall [0.3333333333333333, 0.0, 1.0, 0.5, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:28.462983: step 1056, loss 1.38753, accuracy 0.5, precision [0.0, 0.25, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.5, nan], recall [0.0, 0.3333333333333333, nan, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:00:28.617062: step 1057, loss 1.01775, accuracy 0.625, precision [0.0, 0.5, nan, 0.6, 1.0, nan, 1.0, 0.5, nan], recall [nan, 0.3333333333333333, 0.0, 0.75, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:00:28.775267: step 1058, loss 0.828493, accuracy 0.8125, precision [1.0, 0.5, 1.0, 1.0, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:28.931196: step 1059, loss 1.27719, accuracy 0.5, precision [1.0, 0.25, 0.6666666666666666, 0.3333333333333333, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.5, 0.6666666666666666, 0.14285714285714285, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:29.083442: step 1060, loss 1.26148, accuracy 0.625, precision [1.0, nan, 0.0, 0.625, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 0.0, nan, 0.7142857142857143, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:00:29.239836: step 1061, loss 1.25473, accuracy 0.5, precision [1.0, 1.0, nan, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [0.5, 0.5, 0.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:29.392032: step 1062, loss 1.87965, accuracy 0.625, precision [1.0, 0.5, 0.0, 0.8, 0.6666666666666666, nan, 0.0, 1.0, nan], recall [1.0, 1.0, 0.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:29.548866: step 1063, loss 1.18415, accuracy 0.4375, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, nan, 1.0, 0.0, 1.0], recall [0.0, 0.0, nan, 0.5, 0.5, nan, 1.0, 0.0, 1.0]
2019-02-19T18:00:29.704832: step 1064, loss 1.74759, accuracy 0.4375, precision [nan, 0.3333333333333333, nan, 0.6, 0.5, nan, 1.0, 0.3333333333333333, 0.0], recall [nan, 0.25, nan, 0.6, 0.3333333333333333, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:00:29.864569: step 1065, loss 1.26635, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, 0.0, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:30.020955: step 1066, loss 1.3751, accuracy 0.625, precision [1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 0.5, 0.0, 0.4, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:30.177697: step 1067, loss 1.19049, accuracy 0.625, precision [0.25, 0.5, 1.0, 0.6, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.5, 0.5, 0.75, 1.0, nan, nan, 0.4, nan]
2019-02-19T18:00:30.326897: step 1068, loss 1.59311, accuracy 0.4375, precision [0.6666666666666666, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, nan, nan, 1.0, 0.0], recall [1.0, 0.3333333333333333, 0.0, 0.4, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:30.478556: step 1069, loss 1.87225, accuracy 0.3125, precision [0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.0, nan, nan, 1.0, 0.0, 0.0]
2019-02-19T18:00:30.633157: step 1070, loss 1.38965, accuracy 0.5, precision [nan, 1.0, 0.5, 0.3333333333333333, 0.3333333333333333, nan, 0.0, 1.0, nan], recall [nan, 0.4, 1.0, 0.5, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:00:30.786825: step 1071, loss 1.50705, accuracy 0.625, precision [0.0, nan, 0.0, 0.8888888888888888, 0.3333333333333333, 0.0, nan, 1.0, nan], recall [nan, 0.0, nan, 0.8, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:00:30.936824: step 1072, loss 0.933512, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.4, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [nan, 0.5, nan, 0.4, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:00:31.089859: step 1073, loss 1.74449, accuracy 0.5, precision [0.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, nan, 0.0], recall [nan, 0.5, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 0.0, nan]
2019-02-19T18:00:31.246957: step 1074, loss 1.52155, accuracy 0.4375, precision [0.0, 0.6, 0.0, 0.75, nan, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 1.0, nan, 0.375, 0.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:00:31.403011: step 1075, loss 1.37484, accuracy 0.5625, precision [1.0, 0.6, 0.0, 0.5, 1.0, nan, nan, 0.5, 0.0], recall [0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:31.552958: step 1076, loss 0.984299, accuracy 0.625, precision [nan, 0.6666666666666666, 0.0, 0.7142857142857143, 0.6666666666666666, nan, nan, 1.0, nan], recall [nan, 1.0, nan, 0.625, 0.6666666666666666, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:00:31.707328: step 1077, loss 1.46011, accuracy 0.4375, precision [0.0, 0.2, nan, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 1.0, nan, 0.2857142857142857, 1.0, nan, nan, 0.25, nan]
2019-02-19T18:00:31.860995: step 1078, loss 1.62379, accuracy 0.5625, precision [0.0, 0.3333333333333333, 0.0, 0.8333333333333334, 0.6666666666666666, nan, nan, 1.0, nan], recall [0.0, 0.5, nan, 0.625, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:00:32.018185: step 1079, loss 1.13052, accuracy 0.6875, precision [0.5, 0.5, 1.0, 1.0, 1.0, nan, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 0.5, 0.8333333333333334, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:00:32.173387: step 1080, loss 1.33051, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.0, 0.5714285714285714, 1.0, 0.0, nan, nan, nan], recall [1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.5, nan, nan, nan, nan]
2019-02-19T18:00:32.329805: step 1081, loss 1.5587, accuracy 0.625, precision [1.0, 0.5, 0.0, 1.0, 0.0, nan, 1.0, 0.25, nan], recall [1.0, 0.5, 0.0, 0.6666666666666666, 0.0, nan, 1.0, 1.0, nan]
2019-02-19T18:00:32.482257: step 1082, loss 1.78609, accuracy 0.5, precision [nan, 0.0, 0.5, 1.0, 1.0, nan, 1.0, 0.0, nan], recall [nan, 0.0, 0.5, 0.5714285714285714, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:00:32.636198: step 1083, loss 0.984888, accuracy 0.6875, precision [0.5, 1.0, 0.0, 0.75, 1.0, nan, nan, 0.0, nan], recall [1.0, 1.0, 0.0, 0.42857142857142855, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:32.793901: step 1084, loss 1.04322, accuracy 0.625, precision [1.0, 0.0, nan, 0.8333333333333334, 0.6666666666666666, 0.0, nan, 1.0, 0.0], recall [1.0, nan, 0.0, 0.625, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:00:32.950110: step 1085, loss 1.20891, accuracy 0.75, precision [0.6666666666666666, 1.0, nan, 0.8, 1.0, 0.5, 0.0, 1.0, nan], recall [0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:00:33.104359: step 1086, loss 1.47059, accuracy 0.5, precision [nan, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 1.0, 0.0, 0.5, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:00:33.254121: step 1087, loss 1.35743, accuracy 0.6875, precision [1.0, 1.0, nan, 0.875, nan, 0.0, 1.0, 0.0, nan], recall [1.0, 1.0, nan, 0.6363636363636364, nan, nan, 1.0, 0.0, nan]
2019-02-19T18:00:33.408892: step 1088, loss 0.972649, accuracy 0.625, precision [1.0, 1.0, 0.5, 0.6, 1.0, nan, nan, 0.0, 0.0], recall [0.5, 0.6666666666666666, 1.0, 0.5, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:00:33.562232: step 1089, loss 1.67801, accuracy 0.375, precision [0.0, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan], recall [nan, 0.5, 0.0, 0.2857142857142857, 0.6666666666666666, nan, nan, nan, 0.0]
2019-02-19T18:00:33.718634: step 1090, loss 0.938779, accuracy 0.6875, precision [1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.5, 0.0, 0.7142857142857143, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:33.874226: step 1091, loss 1.10793, accuracy 0.625, precision [0.0, 1.0, 1.0, 0.375, 1.0, nan, nan, nan, nan], recall [nan, 0.3333333333333333, 0.75, 0.75, 1.0, 0.0, 0.0, nan, nan]
2019-02-19T18:00:34.030013: step 1092, loss 1.30923, accuracy 0.6875, precision [0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, nan, nan, 0.0], recall [nan, 0.3333333333333333, 1.0, 0.6, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:34.188897: step 1093, loss 1.33412, accuracy 0.625, precision [1.0, 0.5, 0.5, 1.0, 0.75, 0.0, nan, 1.0, 0.0], recall [0.5, 1.0, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:00:34.339302: step 1094, loss 2.39949, accuracy 0.25, precision [nan, 0.5, 0.0, 0.4, 0.0, 0.0, nan, 0.3333333333333333, 0.0], recall [0.0, 0.5, nan, 0.2857142857142857, nan, 0.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:34.488692: step 1095, loss 1.50972, accuracy 0.5625, precision [nan, 0.5, 1.0, 0.8, 0.5, 0.0, nan, 0.5, 0.0], recall [nan, 0.5, 1.0, 0.5, 0.6666666666666666, nan, nan, 1.0, 0.0]
2019-02-19T18:00:34.640154: step 1096, loss 1.19605, accuracy 0.5625, precision [0.0, 0.0, 0.0, 1.0, 0.8, nan, nan, 0.0, nan], recall [nan, nan, 0.0, 0.5555555555555556, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:00:34.795066: step 1097, loss 1.61422, accuracy 0.5625, precision [nan, 0.0, 0.0, 0.8333333333333334, 1.0, 0.5, nan, 0.0, nan], recall [0.0, nan, nan, 0.5555555555555556, 0.6666666666666666, 1.0, nan, 0.0, nan]
2019-02-19T18:00:34.950440: step 1098, loss 1.29583, accuracy 0.5625, precision [1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, nan, 0.0, 1.0, nan], recall [1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:35.102647: step 1099, loss 1.12132, accuracy 0.6875, precision [0.0, 0.6666666666666666, nan, 1.0, 1.0, nan, nan, 0.5, 0.5], recall [nan, 1.0, nan, 0.625, 1.0, nan, nan, 0.3333333333333333, 1.0]
2019-02-19T18:00:35.254815: step 1100, loss 1.79374, accuracy 0.5625, precision [1.0, 0.5, 1.0, 0.75, 0.3333333333333333, 0.0, nan, nan, 0.0], recall [1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.0, nan, 0.0, nan]
2019-02-19T18:00:35.404122: step 1101, loss 1.85658, accuracy 0.375, precision [0.0, nan, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 1.0, nan], recall [nan, 0.0, 0.5, 0.2857142857142857, nan, 0.0, nan, 1.0, nan]
2019-02-19T18:00:35.559325: step 1102, loss 0.718652, accuracy 0.75, precision [1.0, 0.5, 1.0, 0.7142857142857143, 1.0, nan, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:35.714516: step 1103, loss 2.10092, accuracy 0.1875, precision [0.0, 0.0, nan, 0.6666666666666666, 0.3333333333333333, 0.0, nan, 0.0, nan], recall [nan, 0.0, nan, 0.16666666666666666, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:35.868553: step 1104, loss 1.37482, accuracy 0.6875, precision [1.0, 0.8333333333333334, 1.0, 0.5, 1.0, nan, 0.0, 0.5, nan], recall [0.6666666666666666, 0.8333333333333334, 0.5, 1.0, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T18:00:36.024888: step 1105, loss 0.999431, accuracy 0.6875, precision [nan, 0.5, 0.5, 1.0, 1.0, 0.5, 0.0, 0.75, nan], recall [nan, 0.5, 1.0, 0.25, 1.0, 1.0, nan, 1.0, 0.0]
2019-02-19T18:00:36.178171: step 1106, loss 0.893668, accuracy 0.6875, precision [0.5, nan, 0.3333333333333333, 0.7142857142857143, 1.0, nan, nan, nan, nan], recall [1.0, 0.0, 1.0, 0.7142857142857143, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:00:36.330838: step 1107, loss 0.788167, accuracy 0.5625, precision [0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, nan, 0.5, nan], recall [0.6666666666666666, 0.5, nan, 0.0, 0.6, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T18:00:36.481236: step 1108, loss 1.4956, accuracy 0.4375, precision [nan, 0.25, 1.0, 0.3333333333333333, 0.5, 0.0, nan, 0.6666666666666666, nan], recall [nan, 0.5, 0.5, 0.16666666666666666, 0.6666666666666666, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:36.637972: step 1109, loss 1.46496, accuracy 0.5, precision [0.0, 0.3333333333333333, 0.5, 0.5, 1.0, nan, 0.5, 0.0, 1.0], recall [0.0, 0.5, 1.0, 0.25, 0.6666666666666666, nan, 1.0, 0.0, 1.0]
2019-02-19T18:00:36.791248: step 1110, loss 0.930536, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.5714285714285714, 1.0, nan, nan, nan, 0.5], recall [0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:00:36.950471: step 1111, loss 1.06124, accuracy 0.75, precision [nan, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 1.0, nan], recall [0.0, 0.3333333333333333, 1.0, 1.0, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:37.105050: step 1112, loss 1.03361, accuracy 0.5625, precision [0.3333333333333333, 0.5, 0.5, 0.6, 0.75, nan, nan, nan, nan], recall [0.5, 1.0, 0.5, 0.6, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:00:37.257116: step 1113, loss 1.22679, accuracy 0.625, precision [0.0, 1.0, 0.0, 0.75, 1.0, 0.0, 0.5, nan, nan], recall [nan, 0.3333333333333333, nan, 0.8571428571428571, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:00:37.414694: step 1114, loss 1.69629, accuracy 0.5625, precision [0.0, 0.75, nan, 1.0, 0.75, 0.0, nan, 0.5, 0.0], recall [nan, 0.75, nan, 0.4, 0.6, nan, 0.0, 1.0, nan]
2019-02-19T18:00:37.567766: step 1115, loss 1.16352, accuracy 0.6875, precision [0.3333333333333333, 1.0, 1.0, 0.8, 1.0, 0.5, nan, 0.5, nan], recall [1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, nan, 1.0, nan]
2019-02-19T18:00:37.725511: step 1116, loss 1.5811, accuracy 0.375, precision [nan, 1.0, 0.0, 0.375, 1.0, 0.0, nan, 0.0, 0.0], recall [nan, 0.3333333333333333, 0.0, 0.42857142857142855, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:00:37.883370: step 1117, loss 1.15974, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.2, 1.0, nan, 1.0, 0.0, 0.0], recall [0.75, 0.0, nan, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, nan]
2019-02-19T18:00:38.041717: step 1118, loss 0.729248, accuracy 0.6875, precision [nan, 0.0, 0.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan], recall [nan, 0.0, nan, 0.5714285714285714, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:38.195279: step 1119, loss 1.20202, accuracy 0.625, precision [1.0, 0.75, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.5, 0.0], recall [0.5, 0.75, nan, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:38.349102: step 1120, loss 1.25602, accuracy 0.625, precision [0.0, 0.75, 0.0, 0.6666666666666666, 0.5, nan, 1.0, 1.0, nan], recall [nan, 0.6, nan, 0.8, 1.0, 0.0, 1.0, 0.5, nan]
2019-02-19T18:00:38.503624: step 1121, loss 1.57248, accuracy 0.4375, precision [0.3333333333333333, 1.0, 0.0, 0.42857142857142855, 0.5, nan, nan, nan, nan], recall [1.0, 0.2, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:38.656417: step 1122, loss 0.997585, accuracy 0.75, precision [nan, 0.5, 1.0, 0.75, 1.0, nan, 1.0, 0.5, nan], recall [0.0, 1.0, 1.0, 0.75, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:00:38.813989: step 1123, loss 1.552, accuracy 0.375, precision [0.0, 0.3333333333333333, nan, 0.2857142857142857, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 0.0, 0.5, 0.75, nan, nan, 0.0, 0.0]
2019-02-19T18:00:38.968207: step 1124, loss 1.38661, accuracy 0.3125, precision [0.0, 0.6666666666666666, nan, 0.2857142857142857, nan, 0.0, 0.0, 0.5, nan], recall [nan, 0.4, nan, 0.5, 0.0, nan, 0.0, 0.25, nan]
2019-02-19T18:00:39.129991: step 1125, loss 1.20743, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.5, 0.8, nan, nan, 0.5, nan], recall [0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:39.288140: step 1126, loss 1.54002, accuracy 0.5, precision [0.75, 0.0, nan, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], recall [0.6, nan, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:00:39.445091: step 1127, loss 1.72215, accuracy 0.5625, precision [0.5, 1.0, 0.0, 0.75, 0.75, 0.0, 1.0, nan, 0.0], recall [0.5, 0.5, nan, 0.5, 0.75, nan, 1.0, nan, 0.0]
2019-02-19T18:00:39.607867: step 1128, loss 1.13085, accuracy 0.6875, precision [1.0, 0.3333333333333333, nan, 1.0, 0.8, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, nan, 0.5714285714285714, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:39.767780: step 1129, loss 1.5001, accuracy 0.5625, precision [1.0, nan, 0.0, 1.0, 0.75, nan, 0.0, 1.0, 0.0], recall [1.0, 0.0, nan, 0.5, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:00:39.925024: step 1130, loss 0.685166, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan]
2019-02-19T18:00:40.079443: step 1131, loss 1.49006, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.75, 0.8, 0.5, nan, 0.0, nan], recall [nan, 0.0, 0.0, 0.42857142857142855, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:00:40.234622: step 1132, loss 0.971791, accuracy 0.8125, precision [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [0.0, nan, 1.0, 0.875, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:40.387455: step 1133, loss 0.864289, accuracy 0.75, precision [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, nan, nan, 0.7272727272727273, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:00:40.540219: step 1134, loss 0.989667, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 0.0, nan, nan, nan], recall [1.0, 1.0, 1.0, 0.5, 0.3333333333333333, nan, nan, 0.0, nan]
2019-02-19T18:00:40.701284: step 1135, loss 1.73342, accuracy 0.4375, precision [0.25, 0.0, 1.0, 0.75, 1.0, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.5, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:40.857263: step 1136, loss 1.1217, accuracy 0.625, precision [nan, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, nan, 0.0, 1.0, 0.0], recall [nan, 1.0, 1.0, 0.4, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:00:41.007645: step 1137, loss 1.75166, accuracy 0.4375, precision [0.0, 0.6, nan, 0.5, 1.0, 0.0, nan, 0.5, nan], recall [0.0, 0.75, 0.0, 0.5, 0.5, 0.0, nan, 0.5, nan]
2019-02-19T18:00:41.161866: step 1138, loss 1.46852, accuracy 0.6875, precision [nan, 1.0, 1.0, 1.0, 1.0, 0.0, nan, 0.5, 0.0], recall [0.0, 1.0, 0.5, 0.8333333333333334, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:00:41.313265: step 1139, loss 1.70508, accuracy 0.4375, precision [0.3333333333333333, 0.6, 1.0, 0.5, 0.5, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 1.0, 0.16666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:41.466188: step 1140, loss 1.42992, accuracy 0.6875, precision [0.0, 0.5, 1.0, 0.8333333333333334, 1.0, 0.0, 0.5, 1.0, nan], recall [nan, 1.0, 0.5, 0.5555555555555556, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:00:41.615960: step 1141, loss 1.08494, accuracy 0.6875, precision [0.0, 0.5, 0.0, 0.875, 1.0, nan, 1.0, 0.5, nan], recall [nan, 0.5, 0.0, 0.7777777777777778, 1.0, nan, 1.0, 1.0, 0.0]
2019-02-19T18:00:41.768056: step 1142, loss 2.09526, accuracy 0.4375, precision [nan, 1.0, 0.5, 0.5, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.6666666666666666, 1.0, 0.25, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:41.919598: step 1143, loss 1.12816, accuracy 0.625, precision [1.0, 1.0, 0.3333333333333333, 0.6, 1.0, 0.0, nan, 0.5, nan], recall [0.5, 0.6, 0.5, 0.6, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:42.071083: step 1144, loss 1.18098, accuracy 0.6875, precision [0.0, 1.0, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 1.0, 0.5, 1.0, nan, 0.0, 0.5, nan]
2019-02-19T18:00:42.222129: step 1145, loss 1.33983, accuracy 0.5625, precision [nan, 1.0, 0.6666666666666666, 0.7142857142857143, 1.0, 0.0, nan, nan, 0.0], recall [nan, 0.5, 0.6666666666666666, 0.8333333333333334, 1.0, 0.0, 0.0, 0.0, nan]
2019-02-19T18:00:42.375166: step 1146, loss 2.05641, accuracy 0.5625, precision [nan, 0.5, 0.0, 0.8, 0.5, nan, 0.3333333333333333, 1.0, 0.0], recall [nan, 0.3333333333333333, nan, 0.6666666666666666, 0.5, nan, 1.0, 0.5, nan]
2019-02-19T18:00:42.527526: step 1147, loss 1.21681, accuracy 0.625, precision [0.5, nan, 0.5, 0.5, 1.0, nan, nan, 1.0, 1.0], recall [1.0, 0.0, 0.5, 0.6, 1.0, nan, nan, 0.6666666666666666, 1.0]
2019-02-19T18:00:42.676720: step 1148, loss 1.28121, accuracy 0.5625, precision [0.5, 0.6666666666666666, 0.0, 0.4, 1.0, 0.5, nan, 1.0, nan], recall [1.0, 0.5, nan, 0.5, 0.5, 1.0, nan, 0.5, nan]
2019-02-19T18:00:42.829831: step 1149, loss 0.844156, accuracy 0.75, precision [0.0, nan, nan, 0.875, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 0.0, nan, 0.875, 1.0, nan, 0.5, 0.6666666666666666, nan]
2019-02-19T18:00:42.988460: step 1150, loss 1.29325, accuracy 0.625, precision [0.0, 0.25, 0.0, 1.0, 1.0, nan, 1.0, 0.5, nan], recall [0.0, 1.0, nan, 0.5555555555555556, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T18:00:43.142693: step 1151, loss 1.02458, accuracy 0.625, precision [0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, nan, 1.0, 1.0], recall [0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0]
2019-02-19T18:00:43.302630: step 1152, loss 1.15194, accuracy 0.625, precision [0.6666666666666666, nan, 0.5, 0.8333333333333334, 0.5, 0.0, nan, 0.5, nan], recall [1.0, 0.0, 1.0, 0.7142857142857143, 1.0, nan, 0.0, 0.5, 0.0]
2019-02-19T18:00:43.457912: step 1153, loss 1.56314, accuracy 0.6875, precision [0.0, 1.0, 0.0, 0.8, nan, nan, nan, 1.0, nan], recall [nan, 1.0, nan, 0.5714285714285714, nan, 0.0, nan, 0.8333333333333334, nan]
2019-02-19T18:00:43.573979: step 1154, loss 2.09419, accuracy 0.4, precision [0.0, 0.5, nan, 0.3333333333333333, 0.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, nan, 0.25, nan, 0.0, nan, 0.5, nan]
2019-02-19T18:00:43.728610: step 1155, loss 1.10051, accuracy 0.5, precision [1.0, nan, 0.0, 0.6, 0.6666666666666666, 0.0, 0.0, 0.0, nan], recall [1.0, 0.0, nan, 0.5, 0.6666666666666666, 0.0, nan, nan, 0.0]
2019-02-19T18:00:43.882765: step 1156, loss 0.886682, accuracy 0.75, precision [0.6666666666666666, 1.0, nan, 0.8333333333333334, 1.0, 0.5, 0.0, 1.0, nan], recall [0.6666666666666666, 0.5, nan, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, nan]
2019-02-19T18:00:44.039572: step 1157, loss 1.89661, accuracy 0.4375, precision [0.0, 0.5, 0.0, 0.8, 0.6666666666666666, nan, nan, nan, 0.0], recall [0.0, 1.0, nan, 0.5714285714285714, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:00:44.196774: step 1158, loss 1.07747, accuracy 0.625, precision [0.0, 0.0, nan, 1.0, 0.75, nan, 1.0, 0.6666666666666666, nan], recall [nan, nan, nan, 0.5714285714285714, 0.75, 0.0, 0.5, 1.0, nan]
2019-02-19T18:00:44.348778: step 1159, loss 0.882315, accuracy 0.5625, precision [0.3333333333333333, 0.0, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.0, nan], recall [0.5, 0.0, 1.0, 0.625, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:44.500305: step 1160, loss 1.22347, accuracy 0.5, precision [0.3333333333333333, 0.5, nan, 1.0, 0.4, nan, nan, 0.0, nan], recall [0.5, 1.0, nan, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:44.654578: step 1161, loss 1.0623, accuracy 0.625, precision [0.5, 0.6666666666666666, 0.0, 0.75, 0.6666666666666666, 0.0, 1.0, 1.0, nan], recall [0.5, 1.0, 0.0, 0.6, 1.0, 0.0, 1.0, 0.5, nan]
2019-02-19T18:00:44.808913: step 1162, loss 1.2784, accuracy 0.4375, precision [0.0, 0.0, 0.0, 0.75, 0.75, 0.0, 0.5, nan, nan], recall [nan, 0.0, nan, 0.375, 0.75, nan, 1.0, 0.0, nan]
2019-02-19T18:00:44.966475: step 1163, loss 1.22993, accuracy 0.5625, precision [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.25, nan], recall [nan, 0.3333333333333333, 0.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:45.121801: step 1164, loss 0.91423, accuracy 0.6875, precision [0.0, 0.5, nan, 0.7142857142857143, 1.0, 0.0, nan, 1.0, nan], recall [nan, 1.0, 0.0, 0.625, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:45.276801: step 1165, loss 1.15066, accuracy 0.625, precision [0.6666666666666666, 0.6666666666666666, 0.5, 0.6, 1.0, nan, nan, 0.0, 1.0], recall [1.0, 1.0, 1.0, 0.6, 1.0, nan, nan, 0.0, 0.5]
2019-02-19T18:00:45.435493: step 1166, loss 1.15989, accuracy 0.5, precision [0.5, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, nan], recall [1.0, 0.0, 1.0, 0.2857142857142857, 0.6666666666666666, nan, nan, 1.0, 0.0]
2019-02-19T18:00:45.590130: step 1167, loss 1.248, accuracy 0.5, precision [1.0, 0.0, nan, 0.5, 0.5, nan, nan, 0.0, 0.0], recall [0.6, 0.0, nan, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:45.746658: step 1168, loss 1.3757, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, nan, 0.0, nan], recall [nan, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0]
2019-02-19T18:00:45.902815: step 1169, loss 0.892314, accuracy 0.75, precision [1.0, 0.5, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.5, 1.0], recall [0.5, 1.0, 1.0, 0.8, 1.0, nan, nan, 0.3333333333333333, 1.0]
2019-02-19T18:00:46.053656: step 1170, loss 1.1609, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.5, 0.3333333333333333, 0.75, 1.0, nan, 0.5, nan], recall [0.5, 0.5, 0.5, 0.2, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:00:46.205334: step 1171, loss 1.05213, accuracy 0.625, precision [0.0, 1.0, nan, 0.875, 0.0, 1.0, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.7777777777777778, 0.0, 1.0, nan, nan, 0.0]
2019-02-19T18:00:46.361303: step 1172, loss 1.24889, accuracy 0.625, precision [0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, nan, 0.6666666666666666, 1.0], recall [0.0, 1.0, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.6666666666666666, 1.0]
2019-02-19T18:00:46.514418: step 1173, loss 1.22109, accuracy 0.5, precision [1.0, 0.3333333333333333, 0.3333333333333333, 0.4, 0.6666666666666666, nan, nan, nan, nan], recall [0.5, 1.0, 0.5, 0.4, 0.5, nan, nan, nan, nan]
2019-02-19T18:00:46.667570: step 1174, loss 1.15822, accuracy 0.75, precision [1.0, 0.75, nan, 0.8333333333333334, 1.0, 0.5, nan, 1.0, 0.0], recall [1.0, 1.0, 0.0, 0.7142857142857143, 0.5, 1.0, nan, 1.0, nan]
2019-02-19T18:00:46.822074: step 1175, loss 0.807448, accuracy 0.8125, precision [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, nan, 0.0, 0.0], recall [0.75, nan, 0.6666666666666666, 0.75, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:00:46.977787: step 1176, loss 1.04424, accuracy 0.625, precision [nan, 0.0, 0.6666666666666666, 0.6666666666666666, 0.8, nan, nan, nan, 0.0], recall [0.0, nan, 1.0, 0.5714285714285714, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:47.132485: step 1177, loss 1.0176, accuracy 0.5625, precision [1.0, 0.0, nan, 0.6, 1.0, 0.5, 0.0, 0.3333333333333333, nan], recall [0.5, 0.0, 0.0, 0.5, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:00:47.286018: step 1178, loss 1.27741, accuracy 0.5, precision [0.75, 0.6666666666666666, 0.6666666666666666, 0.0, nan, 0.3333333333333333, 0.0, 0.0, nan], recall [0.6, 1.0, 1.0, 0.0, nan, 0.5, 0.0, 0.0, nan]
2019-02-19T18:00:47.442453: step 1179, loss 0.967841, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.625, 1.0, nan, nan, 0.3333333333333333, nan], recall [0.5, 0.5, 1.0, 1.0, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:00:47.594540: step 1180, loss 1.07436, accuracy 0.75, precision [nan, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.5], recall [nan, 0.4, 1.0, 1.0, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:00:47.748835: step 1181, loss 0.81269, accuracy 0.75, precision [1.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.7142857142857143, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:00:47.901841: step 1182, loss 0.959379, accuracy 0.625, precision [nan, 0.3333333333333333, 0.5, 0.8571428571428571, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:48.056547: step 1183, loss 1.41847, accuracy 0.75, precision [1.0, nan, 0.0, 1.0, 1.0, 0.0, nan, nan, nan], recall [0.5, nan, nan, 0.8181818181818182, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:48.211658: step 1184, loss 1.0874, accuracy 0.6875, precision [1.0, 0.0, 0.5, 1.0, 0.5, nan, nan, 0.5, 1.0], recall [0.5, nan, 1.0, 0.7142857142857143, 0.5, nan, nan, 0.5, 1.0]
2019-02-19T18:00:48.364076: step 1185, loss 1.33693, accuracy 0.6875, precision [nan, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, nan, 0.0], recall [0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, nan, nan, nan]
2019-02-19T18:00:48.517392: step 1186, loss 0.969778, accuracy 0.625, precision [1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, nan, 1.0, nan], recall [1.0, nan, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5, nan, 1.0, nan]
2019-02-19T18:00:48.675822: step 1187, loss 0.497236, accuracy 0.875, precision [0.5, 1.0, nan, 1.0, 0.8333333333333334, nan, nan, nan, nan], recall [1.0, 0.5, nan, 0.875, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:48.830882: step 1188, loss 0.762385, accuracy 0.6875, precision [0.0, 0.5, 1.0, 0.6, 0.75, nan, 1.0, 1.0, nan], recall [0.0, 1.0, 0.5, 0.75, 0.6, nan, 1.0, 1.0, nan]
2019-02-19T18:00:48.991623: step 1189, loss 1.14834, accuracy 0.5, precision [0.0, 0.5, 0.4, 0.75, 1.0, 0.0, nan, nan, 0.0], recall [nan, 1.0, 0.6666666666666666, 0.3, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:49.146726: step 1190, loss 1.391, accuracy 0.5, precision [0.0, 1.0, 0.5, 0.6666666666666666, 0.75, 0.0, 0.0, 0.0, nan], recall [0.0, 0.6666666666666666, 0.5, 0.2857142857142857, 1.0, nan, nan, nan, nan]
2019-02-19T18:00:49.303873: step 1191, loss 1.30627, accuracy 0.5, precision [nan, 0.5, 0.0, 1.0, 0.6, 0.0, nan, nan, 0.0], recall [nan, 0.5, nan, 0.4, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:00:49.457093: step 1192, loss 1.07681, accuracy 0.5625, precision [0.0, 0.75, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.5, nan], recall [nan, 0.6, 0.5, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:49.613043: step 1193, loss 0.935511, accuracy 0.6875, precision [nan, 0.5, 0.0, 1.0, 1.0, nan, nan, 0.0, nan], recall [0.0, 1.0, nan, 0.6666666666666666, 0.75, nan, nan, nan, nan]
2019-02-19T18:00:49.766973: step 1194, loss 0.998715, accuracy 0.625, precision [nan, 0.25, nan, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, nan, nan], recall [nan, 0.5, 0.0, 0.5555555555555556, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:00:49.918008: step 1195, loss 1.20321, accuracy 0.5625, precision [0.0, 0.4, 1.0, 0.8, 1.0, nan, nan, 1.0, nan], recall [nan, 0.6666666666666666, 0.5, 0.5, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:00:50.069863: step 1196, loss 1.37184, accuracy 0.4375, precision [1.0, 0.3333333333333333, 1.0, 0.25, 0.0, 0.5, nan, 0.5, 0.0], recall [1.0, 0.5, 1.0, 0.25, 0.0, 0.5, 0.0, 0.3333333333333333, nan]
2019-02-19T18:00:50.224245: step 1197, loss 0.998801, accuracy 0.6875, precision [1.0, 0.6666666666666666, 0.5, 0.75, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 1.0, 0.6666666666666666, 0.6, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:00:50.376193: step 1198, loss 1.00791, accuracy 0.6875, precision [1.0, 0.6666666666666666, nan, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:00:50.532501: step 1199, loss 1.15392, accuracy 0.625, precision [0.5, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, nan, 1.0, nan], recall [1.0, 0.3333333333333333, nan, 0.75, 0.75, 0.3333333333333333, nan, 1.0, nan]
2019-02-19T18:00:50.683133: step 1200, loss 0.875774, accuracy 0.6875, precision [nan, 0.6666666666666666, 0.5, 0.75, 0.6666666666666666, nan, 1.0, 1.0, 0.0], recall [nan, 0.6666666666666666, 0.5, 0.75, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T18:00:50.837485: step 1201, loss 1.13545, accuracy 0.6875, precision [0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, nan, 0.0, nan], recall [1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:00:50.991578: step 1202, loss 0.878429, accuracy 0.6875, precision [nan, 0.5, nan, 0.5714285714285714, 1.0, nan, 1.0, 0.5, nan], recall [0.0, 0.5, nan, 0.8, 0.75, 0.0, 1.0, 1.0, nan]
2019-02-19T18:00:51.141782: step 1203, loss 0.939607, accuracy 0.75, precision [0.75, 1.0, 0.5, 0.8333333333333334, 1.0, 1.0, nan, 0.0, nan], recall [1.0, 1.0, 1.0, 0.625, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:00:51.298367: step 1204, loss 1.0116, accuracy 0.625, precision [1.0, 1.0, 1.0, 0.5555555555555556, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.5, 0.5, 0.7142857142857143, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:00:51.451375: step 1205, loss 1.06909, accuracy 0.75, precision [0.0, 1.0, nan, 0.6, 1.0, 0.0, 1.0, nan, nan], recall [nan, 0.8333333333333334, 0.0, 0.6, 1.0, nan, 1.0, nan, nan]
2019-02-19T18:00:51.601213: step 1206, loss 1.40007, accuracy 0.625, precision [0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [nan, 0.5, 0.6666666666666666, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:51.761231: step 1207, loss 1.0775, accuracy 0.6875, precision [0.75, nan, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, nan], recall [1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 1.0, nan]
2019-02-19T18:00:51.919293: step 1208, loss 1.83372, accuracy 0.625, precision [nan, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, nan, 0.0, 0.6666666666666666, nan], recall [0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:52.073172: step 1209, loss 1.16451, accuracy 0.625, precision [nan, 1.0, 1.0, 0.0, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [0.0, 0.3333333333333333, 1.0, 0.0, 0.8333333333333334, 0.0, nan, 1.0, nan]
2019-02-19T18:00:52.225830: step 1210, loss 0.855286, accuracy 0.625, precision [nan, 0.5, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, nan, nan], recall [nan, 1.0, 0.6666666666666666, 0.4, 1.0, nan, 0.3333333333333333, nan, nan]
2019-02-19T18:00:52.377564: step 1211, loss 0.492095, accuracy 0.875, precision [0.75, 1.0, 1.0, 1.0, 1.0, nan, 1.0, 0.5, nan], recall [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:00:52.536434: step 1212, loss 1.01676, accuracy 0.5, precision [nan, 1.0, 0.3333333333333333, 0.4, 1.0, 0.0, nan, 0.0, nan], recall [nan, 0.5, 0.5, 0.2857142857142857, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:52.689217: step 1213, loss 1.22837, accuracy 0.625, precision [0.5, nan, 1.0, 0.8333333333333334, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.0, 0.5, 0.8333333333333334, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:00:52.845957: step 1214, loss 1.64038, accuracy 0.625, precision [nan, 0.6666666666666666, 1.0, 0.8, 1.0, nan, 0.0, 0.0, nan], recall [0.0, 0.5, 1.0, 0.6666666666666666, 1.0, nan, nan, nan, 0.0]
2019-02-19T18:00:53.003947: step 1215, loss 0.811775, accuracy 0.625, precision [1.0, 0.6666666666666666, 0.0, 0.6, 1.0, nan, nan, nan, 0.5], recall [1.0, 0.5, nan, 0.6, 1.0, 0.0, nan, 0.0, 1.0]
2019-02-19T18:00:53.159724: step 1216, loss 0.948657, accuracy 0.6875, precision [1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 1.0, 0.5, 0.8333333333333334, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:00:53.310253: step 1217, loss 1.1104, accuracy 0.8125, precision [1.0, 1.0, 1.0, 0.75, 1.0, nan, nan, 0.0, 0.5], recall [1.0, 0.6666666666666666, 0.75, 1.0, 0.6666666666666666, nan, nan, nan, 1.0]
2019-02-19T18:00:53.467800: step 1218, loss 0.704213, accuracy 0.75, precision [0.5, nan, 1.0, 0.8333333333333334, 0.75, nan, nan, nan, 0.5], recall [1.0, 0.0, 0.6666666666666666, 0.8333333333333334, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:00:53.625979: step 1219, loss 0.778841, accuracy 0.6875, precision [0.5, 0.5, 1.0, 0.7142857142857143, 1.0, 1.0, nan, 0.5, nan], recall [0.5, 0.3333333333333333, 0.5, 0.8333333333333334, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:00:53.780694: step 1220, loss 1.12748, accuracy 0.4375, precision [0.0, 0.5, nan, 0.4444444444444444, 1.0, nan, 0.0, nan, nan], recall [nan, 0.3333333333333333, 0.0, 0.8, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:00:53.932964: step 1221, loss 0.568517, accuracy 0.875, precision [1.0, 1.0, nan, 0.8333333333333334, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, 0.0, 1.0, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:00:54.086811: step 1222, loss 1.47352, accuracy 0.5625, precision [0.3333333333333333, 0.5, nan, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0], recall [0.5, 0.5, nan, 0.5714285714285714, 1.0, nan, 1.0, 0.5, 0.0]
2019-02-19T18:00:54.243996: step 1223, loss 0.872128, accuracy 0.625, precision [nan, 0.5, nan, 0.5, 1.0, nan, 1.0, 0.5, nan], recall [nan, 1.0, nan, 0.4, 0.75, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:00:54.401425: step 1224, loss 0.878326, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.8333333333333334, 0.5, 0.3333333333333333, 0.0, 1.0, nan], recall [nan, 0.0, 1.0, 0.5555555555555556, 1.0, 1.0, 0.0, 0.5, nan]
2019-02-19T18:00:54.556439: step 1225, loss 1.06982, accuracy 0.6875, precision [0.0, 0.5, nan, 1.0, 0.6666666666666666, nan, nan, 0.5, 0.0], recall [0.0, 1.0, nan, 0.875, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:00:54.714187: step 1226, loss 0.627049, accuracy 0.75, precision [0.75, 1.0, nan, 0.8, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:00:54.865569: step 1227, loss 1.00274, accuracy 0.625, precision [nan, 0.0, 0.0, 0.875, 1.0, 1.0, 0.0, 1.0, nan], recall [0.0, 0.0, 0.0, 0.7777777777777778, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T18:00:55.021310: step 1228, loss 1.482, accuracy 0.4375, precision [nan, 1.0, 0.0, 0.3333333333333333, 0.5, nan, 0.5, 1.0, nan], recall [nan, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.5, 0.3333333333333333, nan]
2019-02-19T18:00:55.177607: step 1229, loss 1.32403, accuracy 0.5, precision [0.6666666666666666, 0.25, 0.0, 0.5, 1.0, 0.0, nan, nan, nan], recall [0.5, 1.0, nan, 0.4, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:55.333739: step 1230, loss 0.372988, accuracy 0.875, precision [nan, 1.0, 1.0, 0.75, 1.0, nan, nan, 1.0, nan], recall [nan, 1.0, 0.5, 1.0, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:00:55.495080: step 1231, loss 0.642637, accuracy 0.75, precision [0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:00:55.649192: step 1232, loss 1.0401, accuracy 0.625, precision [1.0, 0.4, 1.0, 0.5, 0.5, 0.0, nan, 1.0, nan], recall [0.75, 1.0, 1.0, 0.2, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:00:55.807785: step 1233, loss 0.993712, accuracy 0.6875, precision [0.5, 1.0, 1.0, 0.6666666666666666, nan, nan, nan, 0.6, nan], recall [1.0, 0.5, 1.0, 0.5714285714285714, nan, nan, 0.0, 1.0, nan]
2019-02-19T18:00:55.963622: step 1234, loss 1.41853, accuracy 0.5, precision [nan, 0.0, 0.5, 1.0, 0.6666666666666666, nan, nan, 0.5, 0.0], recall [nan, nan, 1.0, 0.4444444444444444, 1.0, nan, 0.0, 0.5, 0.0]
2019-02-19T18:00:56.121920: step 1235, loss 1.19576, accuracy 0.5, precision [0.0, 0.25, 1.0, 0.6666666666666666, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.5, 0.5, 0.6666666666666666, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:00:56.281195: step 1236, loss 1.14078, accuracy 0.5625, precision [1.0, 0.0, 0.5, 0.8333333333333334, 0.0, nan, 0.0, 1.0, nan], recall [1.0, 0.0, 1.0, 0.5555555555555556, nan, nan, nan, 0.6666666666666666, 0.0]
2019-02-19T18:00:56.433985: step 1237, loss 0.864181, accuracy 0.6875, precision [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 1.0, nan], recall [0.5, nan, nan, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:00:56.592613: step 1238, loss 1.55376, accuracy 0.375, precision [0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.75, 0.0, nan, 1.0, nan], recall [nan, nan, 0.5, 0.16666666666666666, 1.0, nan, nan, 0.2, nan]
2019-02-19T18:00:56.744376: step 1239, loss 0.727266, accuracy 0.8125, precision [nan, nan, 0.0, 1.0, 0.8, 1.0, nan, 1.0, nan], recall [nan, 0.0, nan, 0.7777777777777778, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:00:56.899724: step 1240, loss 1.24094, accuracy 0.625, precision [1.0, nan, 0.5, 0.5, 0.6, 0.0, nan, 1.0, 1.0], recall [1.0, nan, 1.0, 0.4, 1.0, 0.0, nan, 0.6666666666666666, 0.5]
2019-02-19T18:00:57.049653: step 1241, loss 1.36888, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [nan, 0.0, nan, 0.5454545454545454, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:00:57.209798: step 1242, loss 1.11811, accuracy 0.6875, precision [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.75, 0.0, 0.0, nan, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:00:57.363141: step 1243, loss 1.21137, accuracy 0.625, precision [1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, nan, 0.5, nan], recall [1.0, 1.0, 0.75, 0.2, 1.0, 1.0, nan, 0.5, nan]
2019-02-19T18:00:57.517787: step 1244, loss 1.27745, accuracy 0.5, precision [nan, nan, 0.25, 0.8333333333333334, 0.5, 1.0, nan, 0.0, 0.0], recall [nan, 0.0, 1.0, 0.45454545454545453, 0.5, 1.0, nan, nan, nan]
2019-02-19T18:00:57.669756: step 1245, loss 1.53445, accuracy 0.5625, precision [0.3333333333333333, 0.5, 0.0, 0.5, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 0.25, nan, 0.5, 0.8, nan, nan, 0.5, nan]
2019-02-19T18:00:57.820368: step 1246, loss 1.40972, accuracy 0.625, precision [1.0, 0.0, 0.0, 0.7142857142857143, 0.6666666666666666, nan, nan, 0.6666666666666666, nan], recall [1.0, 0.0, 0.0, 0.8333333333333334, 0.6666666666666666, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:00:57.973204: step 1247, loss 0.820468, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.75, 1.0, 0.0, 1.0, 1.0, 0.0], recall [1.0, 0.6666666666666666, 1.0, 0.75, 1.0, nan, 0.5, 0.5, nan]
2019-02-19T18:00:58.126750: step 1248, loss 1.41838, accuracy 0.5625, precision [0.5, 0.0, 0.5, 0.7142857142857143, nan, nan, 0.0, 1.0, nan], recall [1.0, nan, 0.3333333333333333, 0.625, nan, nan, nan, 0.5, 0.0]
2019-02-19T18:00:58.277960: step 1249, loss 0.620114, accuracy 0.6875, precision [1.0, 1.0, 0.0, 0.25, 1.0, nan, 1.0, 0.75, nan], recall [0.6666666666666666, 0.3333333333333333, 0.0, 0.5, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:00:58.432422: step 1250, loss 1.27091, accuracy 0.6875, precision [1.0, 0.75, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, nan], recall [1.0, 0.75, 0.5, 0.625, nan, nan, 1.0, nan, nan]

Evaluation:
[[ 53  12   0  15   3   1   0   6   1]
 [ 13  85   3  44   3   1   0  11   0]
 [  0   6  44  34   5   0   0   7   0]
 [ 12  18  25 205  15   3   3  32   0]
 [  1   0   5  13 135   2   0   3   0]
 [  1   2   1  34   2  12   0   3   0]
 [  2   1   2   7   5   0  15   1   0]
 [  5   3   0  22   4   0   0  65   2]
 [  1   1   1   9   2   0   0   2   1]]
2019-02-19T18:01:00.861813: step 1250, loss 1.23072, accuracy 0.6, precision [0.5824175824175825, 0.53125, 0.4583333333333333, 0.6549520766773163, 0.8490566037735849, 0.21818181818181817, 0.45454545454545453, 0.6435643564356436, 0.058823529411764705], recall [0.6022727272727273, 0.6640625, 0.5432098765432098, 0.5352480417754569, 0.7758620689655172, 0.631578947368421, 0.8333333333333334, 0.5, 0.25]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-1250

2019-02-19T18:01:01.168176: step 1251, loss 0.813554, accuracy 0.8125, precision [1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, 1.0, nan, 1.0, 0.8, nan, nan, 1.0, nan]
2019-02-19T18:01:01.322391: step 1252, loss 2.12471, accuracy 0.375, precision [0.0, 0.0, nan, 0.4, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, nan], recall [0.0, nan, 0.0, 0.4, 0.3333333333333333, 1.0, nan, 0.5, 0.0]
2019-02-19T18:01:01.481001: step 1253, loss 1.6779, accuracy 0.4375, precision [0.5, 0.6666666666666666, 0.0, 0.75, 0.5, nan, nan, 0.0, 0.0], recall [0.5, 0.6666666666666666, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:01.634970: step 1254, loss 1.64488, accuracy 0.4375, precision [0.25, 0.0, nan, 0.8, 1.0, nan, 0.5, 0.0, nan], recall [0.5, nan, nan, 0.5714285714285714, 0.3333333333333333, nan, 1.0, 0.0, nan]
2019-02-19T18:01:01.788520: step 1255, loss 0.500859, accuracy 0.8125, precision [0.5, 0.0, 1.0, 0.5, 1.0, 1.0, nan, 1.0, nan], recall [1.0, 0.0, 1.0, 0.5, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:01:01.945357: step 1256, loss 2.02375, accuracy 0.375, precision [0.0, 0.0, 0.5, 0.25, 1.0, nan, nan, nan, nan], recall [nan, nan, 0.5, 0.16666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:02.098218: step 1257, loss 1.34759, accuracy 0.5, precision [nan, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.3333333333333333, 0.0], recall [0.0, 0.5, 1.0, 0.5714285714285714, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:01:02.256567: step 1258, loss 0.873041, accuracy 0.5625, precision [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 0.0, 0.3333333333333333, nan, 0.5, 1.0, nan]
2019-02-19T18:01:02.409926: step 1259, loss 1.03398, accuracy 0.6875, precision [nan, 1.0, 0.5, 0.625, 0.5, nan, 1.0, nan, nan], recall [nan, 0.6, 1.0, 0.7142857142857143, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:02.564319: step 1260, loss 0.914192, accuracy 0.625, precision [1.0, 1.0, 0.5, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [1.0, 0.3333333333333333, 1.0, 0.5, 0.8, nan, nan, 0.0, nan]
2019-02-19T18:01:02.721058: step 1261, loss 1.04666, accuracy 0.5625, precision [nan, 1.0, 0.0, 0.625, 1.0, nan, 0.0, 0.0, 0.0], recall [nan, 0.6, 0.0, 0.625, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:02.874143: step 1262, loss 1.32368, accuracy 0.625, precision [0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:01:03.031636: step 1263, loss 1.00886, accuracy 0.5625, precision [1.0, 0.5, 0.6666666666666666, 0.5, 0.5, nan, nan, 0.0, nan], recall [0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:03.187934: step 1264, loss 1.12803, accuracy 0.5625, precision [nan, 0.5, 1.0, 0.75, 0.0, 0.3333333333333333, 1.0, nan, nan], recall [nan, 1.0, 0.5, 0.6, 0.0, 1.0, 1.0, 0.0, nan]
2019-02-19T18:01:03.342332: step 1265, loss 0.996438, accuracy 0.75, precision [1.0, 0.75, 0.0, 0.8333333333333334, 1.0, 0.0, nan, 1.0, nan], recall [0.5, 1.0, nan, 0.625, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:03.502628: step 1266, loss 0.97379, accuracy 0.625, precision [0.6666666666666666, 1.0, 0.0, 0.75, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 0.4, nan, 0.6, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:01:03.657295: step 1267, loss 1.14535, accuracy 0.6875, precision [0.6666666666666666, 0.5, nan, 1.0, 0.3333333333333333, 0.0, 1.0, nan, nan], recall [0.6666666666666666, 1.0, nan, 0.6666666666666666, 1.0, 0.0, 1.0, nan, nan]
2019-02-19T18:01:03.814579: step 1268, loss 1.14645, accuracy 0.5625, precision [0.3333333333333333, 0.4, nan, 1.0, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [1.0, 1.0, nan, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:03.971283: step 1269, loss 1.24158, accuracy 0.4375, precision [0.25, 0.5, 0.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan], recall [0.3333333333333333, 0.25, 0.0, 0.6, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:04.124107: step 1270, loss 1.11468, accuracy 0.6875, precision [nan, 0.0, 1.0, 0.8333333333333334, 0.6666666666666666, 0.5, nan, 0.5, nan], recall [0.0, nan, 0.6666666666666666, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, 1.0, nan]
2019-02-19T18:01:04.279791: step 1271, loss 1.28599, accuracy 0.5, precision [1.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, nan], recall [0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:04.435309: step 1272, loss 1.26131, accuracy 0.5, precision [1.0, 0.42857142857142855, 0.0, 1.0, 0.5, 0.5, nan, nan, nan], recall [0.5, 1.0, 0.0, 0.25, 1.0, 1.0, nan, nan, nan]
2019-02-19T18:01:04.590048: step 1273, loss 1.10755, accuracy 0.625, precision [0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [1.0, nan, 0.5, 0.4, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:01:04.746695: step 1274, loss 1.51667, accuracy 0.5, precision [1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.3333333333333333, nan], recall [0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:04.898423: step 1275, loss 0.974391, accuracy 0.5625, precision [0.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.0, nan, nan], recall [nan, 0.0, 0.6666666666666666, 0.75, 1.0, 0.5, nan, nan, 0.0]
2019-02-19T18:01:05.053810: step 1276, loss 0.730302, accuracy 0.875, precision [1.0, 0.6666666666666666, 1.0, 0.75, 1.0, nan, nan, nan, nan], recall [1.0, 0.6666666666666666, 1.0, 0.75, 1.0, nan, nan, nan, nan]
2019-02-19T18:01:05.212884: step 1277, loss 1.77577, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0], recall [1.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5, nan, nan]
2019-02-19T18:01:05.370012: step 1278, loss 1.04057, accuracy 0.625, precision [nan, 0.75, 0.6666666666666666, 0.0, 0.8, nan, nan, 0.3333333333333333, nan], recall [0.0, 1.0, 1.0, 0.0, 0.8, nan, nan, 1.0, nan]
2019-02-19T18:01:05.522597: step 1279, loss 1.53692, accuracy 0.5, precision [0.0, 0.0, 0.4, 0.5, 1.0, nan, 0.5, nan, nan], recall [0.0, 0.0, 1.0, 0.3333333333333333, 0.6, nan, 1.0, nan, nan]
2019-02-19T18:01:05.673061: step 1280, loss 1.09111, accuracy 0.625, precision [0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 1.0, nan, 0.0, 0.0, nan], recall [0.5, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:05.828583: step 1281, loss 0.97349, accuracy 0.6875, precision [1.0, 0.0, nan, 0.6666666666666666, 1.0, nan, 1.0, 1.0, nan], recall [0.5, 0.0, 0.0, 0.8, 0.6666666666666666, nan, 1.0, 1.0, nan]
2019-02-19T18:01:05.985376: step 1282, loss 0.840601, accuracy 0.625, precision [0.0, 0.6666666666666666, 0.0, 0.8, 1.0, nan, nan, nan, nan], recall [0.0, 0.5, nan, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:06.138085: step 1283, loss 1.08927, accuracy 0.625, precision [1.0, 0.0, 0.6666666666666666, 0.2, 1.0, nan, nan, 1.0, nan], recall [0.5, nan, 0.6666666666666666, 0.5, 0.8, nan, 0.0, 1.0, 0.0]
2019-02-19T18:01:06.298625: step 1284, loss 0.797656, accuracy 0.625, precision [0.0, 1.0, nan, 0.25, 1.0, 0.0, nan, nan, nan], recall [0.0, 0.6666666666666666, nan, 0.3333333333333333, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:06.450999: step 1285, loss 0.760456, accuracy 0.75, precision [1.0, 1.0, 1.0, 0.5, 1.0, nan, 0.5, 0.6666666666666666, nan], recall [1.0, 1.0, 0.75, 0.6666666666666666, 0.5, nan, 0.5, 1.0, nan]
2019-02-19T18:01:06.605917: step 1286, loss 0.815263, accuracy 0.6875, precision [0.5, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 1.0, 0.6666666666666666, 0.5, 0.8, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:06.759239: step 1287, loss 1.44846, accuracy 0.625, precision [0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 0.0, nan, nan], recall [1.0, 0.6666666666666666, 0.5, 1.0, 0.8333333333333334, nan, 0.0, 0.0, nan]
2019-02-19T18:01:06.918780: step 1288, loss 1.18695, accuracy 0.625, precision [0.3333333333333333, nan, 0.3333333333333333, 0.8333333333333334, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 0.0, 0.5, 0.625, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:07.069261: step 1289, loss 1.46076, accuracy 0.625, precision [1.0, 0.6666666666666666, 1.0, 0.8333333333333334, nan, nan, 0.5, 0.0, 0.0], recall [0.5, 0.6666666666666666, 1.0, 0.7142857142857143, 0.0, nan, 1.0, nan, nan]
2019-02-19T18:01:07.221801: step 1290, loss 1.5369, accuracy 0.75, precision [0.0, 1.0, 0.0, 0.875, 0.75, nan, nan, 1.0, nan], recall [nan, 0.5, nan, 0.875, 0.6, nan, nan, 1.0, nan]
2019-02-19T18:01:07.373526: step 1291, loss 0.934782, accuracy 0.6875, precision [nan, 0.6666666666666666, nan, 1.0, 1.0, 0.0, 0.0, 0.5, nan], recall [nan, 0.6666666666666666, nan, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:07.532119: step 1292, loss 0.546118, accuracy 0.8125, precision [1.0, 0.5, 1.0, 0.8333333333333334, 0.75, nan, 1.0, 1.0, nan], recall [0.5, 0.5, 1.0, 0.8333333333333334, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:01:07.689048: step 1293, loss 0.949348, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.6666666666666666, nan, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 0.5, 0.6666666666666666, 0.0, nan, nan, 0.5, nan]
2019-02-19T18:01:07.847737: step 1294, loss 0.983858, accuracy 0.625, precision [0.5, 0.75, 1.0, 0.8, 0.0, nan, nan, 0.5, 0.0], recall [1.0, 0.75, 0.3333333333333333, 0.6666666666666666, nan, nan, nan, 0.5, nan]
2019-02-19T18:01:08.006462: step 1295, loss 1.18136, accuracy 0.6875, precision [0.0, 0.0, 0.3333333333333333, 0.8333333333333334, 1.0, nan, nan, 1.0, nan], recall [nan, 0.0, 0.5, 0.8333333333333334, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:01:08.165866: step 1296, loss 0.99697, accuracy 0.5625, precision [nan, 0.8333333333333334, 1.0, 0.0, 0.6666666666666666, 0.0, nan, 1.0, nan], recall [nan, 0.7142857142857143, 0.3333333333333333, 0.0, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:01:08.316980: step 1297, loss 1.57102, accuracy 0.5, precision [nan, 0.8, 0.0, 0.5, 0.5, nan, 0.0, 1.0, 0.0], recall [nan, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:08.473605: step 1298, loss 1.59067, accuracy 0.625, precision [0.5, 0.5, 0.5, 0.75, 1.0, nan, nan, 0.5, 0.0], recall [0.5, 1.0, 1.0, 0.75, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:01:08.632343: step 1299, loss 1.22088, accuracy 0.6875, precision [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, nan], recall [0.5, 1.0, 1.0, 0.5, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:01:08.786484: step 1300, loss 1.20987, accuracy 0.75, precision [1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, nan], recall [0.5, nan, 1.0, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:01:08.943212: step 1301, loss 0.622395, accuracy 0.875, precision [1.0, 1.0, 1.0, 0.6, 1.0, 1.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, nan]
2019-02-19T18:01:09.097321: step 1302, loss 0.927576, accuracy 0.6875, precision [0.0, 0.75, 0.5, 0.6, 1.0, 1.0, nan, nan, nan], recall [0.0, 1.0, 1.0, 0.6, 0.75, 1.0, 0.0, nan, nan]
2019-02-19T18:01:09.251957: step 1303, loss 1.8178, accuracy 0.4375, precision [nan, 0.0, 0.4, 1.0, 0.0, 0.0, nan, 0.0, nan], recall [0.0, nan, 1.0, 0.5, 0.0, nan, 0.0, nan, nan]
2019-02-19T18:01:09.406271: step 1304, loss 1.28657, accuracy 0.5625, precision [nan, nan, nan, 0.7777777777777778, 0.5, 0.5, nan, 0.0, 0.0], recall [0.0, 0.0, 0.0, 0.7777777777777778, 1.0, 1.0, 0.0, nan, nan]
2019-02-19T18:01:09.561562: step 1305, loss 1.76265, accuracy 0.4375, precision [0.0, 0.5, 0.75, 0.4, 0.3333333333333333, nan, 0.0, nan, nan], recall [nan, 0.3333333333333333, 0.75, 0.4, 0.5, 0.0, 0.0, nan, nan]
2019-02-19T18:01:09.719616: step 1306, loss 1.71563, accuracy 0.5625, precision [0.0, 0.5, 1.0, 1.0, 0.6666666666666666, nan, nan, 0.0, nan], recall [nan, 0.5, 0.75, 0.25, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:01:09.873457: step 1307, loss 1.15399, accuracy 0.5625, precision [0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0], recall [0.0, 1.0, 1.0, 0.4, nan, 1.0, 0.5, 0.3333333333333333, nan]
2019-02-19T18:01:10.034037: step 1308, loss 0.586337, accuracy 0.75, precision [nan, nan, 0.5, 0.875, 0.75, 0.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.7777777777777778, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:10.192188: step 1309, loss 0.968499, accuracy 0.625, precision [0.5, 0.0, nan, 0.8, 1.0, nan, 1.0, 0.6, 0.0], recall [1.0, 0.0, nan, 0.5714285714285714, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T18:01:10.348956: step 1310, loss 1.32801, accuracy 0.5625, precision [1.0, 0.75, nan, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0], recall [0.5, 1.0, 0.0, 0.4, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:01:10.503580: step 1311, loss 1.20325, accuracy 0.625, precision [nan, 0.0, nan, 0.8571428571428571, 0.5, 1.0, nan, 0.3333333333333333, nan], recall [0.0, nan, 0.0, 0.75, 0.6666666666666666, 1.0, nan, 1.0, nan]
2019-02-19T18:01:10.653093: step 1312, loss 1.90209, accuracy 0.4375, precision [0.0, 0.5, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0], recall [nan, 0.5, 0.25, 0.4, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:10.803932: step 1313, loss 1.33114, accuracy 0.6875, precision [1.0, 1.0, nan, 0.75, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 0.75, nan, 0.6, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:01:10.957026: step 1314, loss 0.973067, accuracy 0.6875, precision [0.5, nan, 0.3333333333333333, 0.8333333333333334, 1.0, 0.0, nan, nan, 1.0], recall [0.5, nan, 0.5, 0.7142857142857143, 1.0, nan, nan, 0.0, 1.0]
2019-02-19T18:01:11.117978: step 1315, loss 1.14927, accuracy 0.75, precision [0.5, 1.0, 0.6666666666666666, 0.75, 1.0, nan, 1.0, 1.0, 0.0], recall [1.0, 1.0, 1.0, 0.75, 0.6666666666666666, 0.0, 1.0, 0.5, nan]
2019-02-19T18:01:11.275386: step 1316, loss 0.897594, accuracy 0.875, precision [1.0, 0.5, 1.0, 1.0, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:11.433351: step 1317, loss 0.832935, accuracy 0.8125, precision [0.5, nan, nan, 0.8, 1.0, 0.5, 1.0, 1.0, nan], recall [1.0, 0.0, nan, 0.8, 0.8, 1.0, 1.0, 1.0, nan]
2019-02-19T18:01:11.590988: step 1318, loss 0.930339, accuracy 0.6875, precision [nan, 1.0, 0.25, 1.0, 0.8, nan, 1.0, nan, 0.0], recall [nan, 1.0, 1.0, 0.5, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:01:11.745082: step 1319, loss 0.822393, accuracy 0.875, precision [nan, 1.0, 0.5, 1.0, 1.0, nan, nan, 0.6666666666666666, nan], recall [nan, 1.0, 1.0, 0.8333333333333334, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:11.902570: step 1320, loss 0.749934, accuracy 0.8125, precision [nan, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, nan, 1.0, 0.0], recall [nan, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, nan, 1.0, nan]
2019-02-19T18:01:12.054938: step 1321, loss 1.45944, accuracy 0.4375, precision [0.0, 1.0, 0.5, 0.25, 1.0, 0.3333333333333333, 0.0, nan, nan], recall [nan, 0.3333333333333333, 0.6666666666666666, 0.25, 0.4, 1.0, nan, nan, nan]
2019-02-19T18:01:12.208477: step 1322, loss 0.850253, accuracy 0.625, precision [1.0, 0.75, 0.0, 1.0, 0.5, 1.0, nan, 0.3333333333333333, nan], recall [1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.5, nan, 1.0, nan]
2019-02-19T18:01:12.360368: step 1323, loss 1.14795, accuracy 0.625, precision [0.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, nan], recall [nan, 1.0, 0.3333333333333333, 0.4, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:12.512510: step 1324, loss 0.924101, accuracy 0.6875, precision [1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, nan, 0.0, nan], recall [1.0, 0.5, 1.0, 0.4, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:01:12.665246: step 1325, loss 0.939748, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.3333333333333333, 1.0, nan, nan, 0.5, nan], recall [1.0, nan, 0.5, 0.6666666666666666, 0.5714285714285714, nan, nan, 1.0, nan]
2019-02-19T18:01:12.819678: step 1326, loss 1.79816, accuracy 0.375, precision [nan, 0.3333333333333333, 0.25, 0.75, nan, 0.0, nan, 0.0, nan], recall [nan, 0.6666666666666666, 0.5, 0.3333333333333333, 0.0, 0.0, nan, nan, nan]
2019-02-19T18:01:12.979576: step 1327, loss 1.0189, accuracy 0.6875, precision [1.0, 0.0, 1.0, 0.75, 1.0, 0.0, nan, 1.0, nan], recall [1.0, nan, 1.0, 0.5, 1.0, 0.0, nan, 0.6666666666666666, nan]
2019-02-19T18:01:13.135925: step 1328, loss 0.894136, accuracy 0.6875, precision [1.0, nan, 1.0, 0.5714285714285714, 0.6666666666666666, nan, nan, 1.0, 0.0], recall [1.0, 0.0, 1.0, 0.8, 0.5, nan, nan, 1.0, 0.0]
2019-02-19T18:01:13.290606: step 1329, loss 1.49023, accuracy 0.625, precision [nan, 0.6666666666666666, nan, 0.75, 0.5, nan, 0.6666666666666666, 0.5, nan], recall [0.0, 0.5, nan, 0.75, 1.0, nan, 0.6666666666666666, 0.6666666666666666, nan]
2019-02-19T18:01:13.448792: step 1330, loss 1.16779, accuracy 0.625, precision [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 1.0], recall [1.0, nan, nan, 0.5714285714285714, 1.0, 0.0, 0.5, 1.0, 1.0]
2019-02-19T18:01:13.605489: step 1331, loss 1.58082, accuracy 0.3125, precision [1.0, 0.0, nan, 0.2857142857142857, 1.0, nan, 0.0, 0.0, 0.0], recall [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, 0.0]
2019-02-19T18:01:13.766683: step 1332, loss 1.21363, accuracy 0.625, precision [1.0, 0.3333333333333333, nan, 0.5, 1.0, 0.0, nan, nan, nan], recall [1.0, 1.0, 0.0, 0.75, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:01:13.925678: step 1333, loss 1.24716, accuracy 0.6875, precision [0.3333333333333333, 0.75, 1.0, 0.5, 1.0, 0.0, nan, 1.0, nan], recall [0.3333333333333333, 1.0, 0.5, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:14.077092: step 1334, loss 0.904486, accuracy 0.75, precision [0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, nan], recall [nan, 1.0, 0.5, 0.75, 1.0, nan, 0.5, 1.0, nan]
2019-02-19T18:01:14.233008: step 1335, loss 1.47273, accuracy 0.5, precision [0.0, 0.5, 0.0, 0.5, 1.0, nan, nan, 1.0, 0.0], recall [0.0, 0.6666666666666666, nan, 0.5, 0.6666666666666666, nan, nan, 0.4, nan]
2019-02-19T18:01:14.383769: step 1336, loss 1.01081, accuracy 0.6875, precision [nan, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.75, 0.0], recall [nan, 1.0, 0.6666666666666666, 0.5, 0.5, nan, 1.0, 1.0, nan]
2019-02-19T18:01:14.537098: step 1337, loss 0.946636, accuracy 0.75, precision [1.0, 0.5, nan, 1.0, 1.0, nan, 0.0, nan, 0.0], recall [1.0, 1.0, 0.0, 0.6666666666666666, 0.8333333333333334, nan, nan, nan, nan]
2019-02-19T18:01:14.690326: step 1338, loss 1.02228, accuracy 0.75, precision [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, nan, 1.0, 0.0, nan], recall [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, nan]
2019-02-19T18:01:14.845396: step 1339, loss 1.12848, accuracy 0.5625, precision [0.0, 0.5, 0.6666666666666666, 0.6, 1.0, 0.0, 0.0, nan, nan], recall [nan, 1.0, 0.6666666666666666, 0.6, 1.0, nan, 0.0, 0.0, 0.0]
2019-02-19T18:01:14.999844: step 1340, loss 1.12346, accuracy 0.5, precision [0.0, 0.75, 0.0, 0.42857142857142855, 1.0, nan, nan, 0.5, nan], recall [nan, 0.6, nan, 0.6, 0.3333333333333333, 0.0, nan, 0.5, nan]
2019-02-19T18:01:15.151962: step 1341, loss 1.0073, accuracy 0.625, precision [1.0, 0.5, 0.6666666666666666, 0.6, 1.0, nan, 0.0, 0.5, nan], recall [0.6666666666666666, 0.5, 0.6666666666666666, 0.75, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:01:15.309459: step 1342, loss 0.529711, accuracy 0.875, precision [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:15.467437: step 1343, loss 1.32616, accuracy 0.4375, precision [0.5, 0.0, 0.5, 1.0, 0.0, nan, nan, 0.0, 0.0], recall [1.0, 0.0, 0.75, 0.3, nan, nan, nan, nan, nan]
2019-02-19T18:01:15.623679: step 1344, loss 0.727197, accuracy 0.75, precision [1.0, 1.0, nan, 0.8333333333333334, 0.75, 0.0, nan, 1.0, nan], recall [1.0, 1.0, 0.0, 0.7142857142857143, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:01:15.784528: step 1345, loss 1.45111, accuracy 0.5625, precision [0.5, 0.5, 0.3333333333333333, 0.0, 1.0, nan, 1.0, 0.0, 0.0], recall [0.3333333333333333, 0.5, 1.0, 0.0, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:15.940460: step 1346, loss 1.0485, accuracy 0.5625, precision [nan, 0.8, 0.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan], recall [0.0, 0.8, nan, 0.6666666666666666, 0.5, 0.0, nan, nan, nan]
2019-02-19T18:01:16.102279: step 1347, loss 1.0231, accuracy 0.6875, precision [1.0, 0.3333333333333333, 0.0, 1.0, nan, 0.6666666666666666, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.5, nan, 1.0, 0.0, 1.0, 0.0]
2019-02-19T18:01:16.259587: step 1348, loss 1.2105, accuracy 0.625, precision [0.5, 0.75, 1.0, 0.25, 1.0, nan, 1.0, 0.5, nan], recall [1.0, 0.6, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.3333333333333333, nan]
2019-02-19T18:01:16.409794: step 1349, loss 1.05128, accuracy 0.75, precision [0.6666666666666666, nan, nan, 0.875, 1.0, 0.0, nan, 1.0, 0.0], recall [1.0, nan, 0.0, 0.7777777777777778, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:01:16.563860: step 1350, loss 1.07996, accuracy 0.6875, precision [1.0, 0.5, 1.0, 0.6, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [0.75, 1.0, 0.5, 0.5, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:16.721267: step 1351, loss 0.784688, accuracy 0.6875, precision [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, nan, 0.0, 0.5, nan], recall [1.0, 0.8, 1.0, 0.4, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:16.876013: step 1352, loss 0.918566, accuracy 0.5625, precision [0.0, 0.6666666666666666, 1.0, 0.5714285714285714, 0.5, 0.0, nan, 1.0, nan], recall [0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:17.028920: step 1353, loss 0.717171, accuracy 0.8125, precision [0.5, 1.0, nan, 0.8, 0.75, nan, nan, 1.0, nan], recall [1.0, 1.0, nan, 0.6666666666666666, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:01:17.185467: step 1354, loss 1.06118, accuracy 0.8125, precision [0.0, 1.0, nan, 1.0, 1.0, nan, 1.0, 1.0, nan], recall [nan, 0.6666666666666666, nan, 0.8333333333333334, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:01:17.334634: step 1355, loss 0.876112, accuracy 0.75, precision [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 1.0, nan, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:17.490995: step 1356, loss 0.652945, accuracy 0.75, precision [0.5, 1.0, 0.0, 0.8, 1.0, nan, nan, 0.5, nan], recall [1.0, 1.0, 0.0, 0.6666666666666666, 0.8333333333333334, nan, nan, 1.0, nan]
2019-02-19T18:01:17.640418: step 1357, loss 1.24825, accuracy 0.5625, precision [nan, 0.5, nan, 0.8333333333333334, 0.6666666666666666, 0.0, nan, 0.25, nan], recall [nan, 0.5, 0.0, 0.625, 0.6666666666666666, nan, nan, 0.5, nan]
2019-02-19T18:01:17.793685: step 1358, loss 0.865501, accuracy 0.6875, precision [1.0, 1.0, 0.75, 0.75, 1.0, 0.0, nan, 0.5, nan], recall [1.0, 0.5, 1.0, 0.5, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:17.949786: step 1359, loss 1.3194, accuracy 0.5625, precision [1.0, 0.3333333333333333, 0.5, 0.6, 0.6666666666666666, 0.5, nan, nan, nan], recall [0.3333333333333333, 0.5, 0.5, 0.6, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:01:18.105872: step 1360, loss 1.28442, accuracy 0.5625, precision [1.0, 0.6, nan, 0.6666666666666666, 0.0, 1.0, nan, 0.0, 0.5], recall [0.3333333333333333, 0.6, 0.0, 0.5, nan, 1.0, nan, nan, 1.0]
2019-02-19T18:01:18.261898: step 1361, loss 0.557385, accuracy 0.8125, precision [nan, nan, nan, 0.7777777777777778, 1.0, nan, 1.0, 0.5, nan], recall [nan, 0.0, nan, 0.875, 1.0, nan, 1.0, 0.5, nan]
2019-02-19T18:01:18.419801: step 1362, loss 1.09656, accuracy 0.5, precision [0.0, 0.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 1.0, nan], recall [nan, nan, 0.0, 0.25, 1.0, nan, nan, 0.6, nan]
2019-02-19T18:01:18.576703: step 1363, loss 1.03013, accuracy 0.75, precision [nan, 0.4, 1.0, 1.0, 1.0, nan, nan, nan, 0.0], recall [nan, 1.0, 1.0, 0.8, 0.8333333333333334, nan, 0.0, 0.0, nan]
2019-02-19T18:01:18.729870: step 1364, loss 1.10799, accuracy 0.5625, precision [0.5, 0.0, 0.5, 0.6, 1.0, 1.0, nan, nan, nan], recall [0.5, 0.0, 0.5, 0.6, 1.0, 1.0, nan, 0.0, nan]
2019-02-19T18:01:18.881987: step 1365, loss 0.945296, accuracy 0.75, precision [1.0, nan, 1.0, 1.0, 1.0, nan, nan, 0.25, 0.0], recall [0.5, nan, 1.0, 0.5, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:01:19.036145: step 1366, loss 1.49646, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.6666666666666666, nan, nan, 0.0, 0.0, nan], recall [1.0, 0.25, nan, 0.75, 0.0, nan, nan, nan, nan]
2019-02-19T18:01:19.195994: step 1367, loss 1.23613, accuracy 0.5, precision [0.0, 0.0, 1.0, 0.8, 1.0, 0.0, nan, 1.0, nan], recall [nan, 0.0, 1.0, 0.5, 0.6666666666666666, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:19.350261: step 1368, loss 1.03038, accuracy 0.6875, precision [1.0, 1.0, nan, 0.6, 1.0, nan, nan, 1.0, 0.0], recall [0.3333333333333333, 1.0, nan, 1.0, 0.5, nan, nan, 0.5, nan]
2019-02-19T18:01:19.504109: step 1369, loss 1.07147, accuracy 0.625, precision [nan, 0.5, nan, 0.6666666666666666, 1.0, 0.25, 1.0, 0.5, nan], recall [0.0, 0.5, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, nan]
2019-02-19T18:01:19.664123: step 1370, loss 1.47712, accuracy 0.625, precision [0.0, 0.6666666666666666, nan, 0.6666666666666666, 0.8, nan, nan, nan, nan], recall [nan, 0.4, nan, 0.8, 1.0, nan, nan, 0.0, 0.0]
2019-02-19T18:01:19.820741: step 1371, loss 1.39902, accuracy 0.625, precision [0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, nan, 0.0], recall [nan, 0.6666666666666666, 1.0, 0.5714285714285714, 0.75, nan, nan, 0.0, nan]
2019-02-19T18:01:19.972935: step 1372, loss 1.45501, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, nan, 1.0, nan], recall [nan, 0.6666666666666666, 1.0, 0.5714285714285714, 0.5, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:20.122941: step 1373, loss 1.00501, accuracy 0.6875, precision [0.0, 0.0, 1.0, 1.0, 1.0, nan, 0.0, 0.0, nan], recall [0.0, nan, 0.5, 0.75, 1.0, nan, nan, nan, nan]
2019-02-19T18:01:20.277003: step 1374, loss 1.73952, accuracy 0.5625, precision [0.0, 1.0, 0.0, 0.8333333333333334, 0.5, nan, 0.0, 0.3333333333333333, nan], recall [0.0, 1.0, 0.0, 0.7142857142857143, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:01:20.432444: step 1375, loss 2.09587, accuracy 0.3125, precision [0.0, 0.0, nan, 0.8, 0.0, 0.0, 0.0, 0.3333333333333333, nan], recall [0.0, 0.0, nan, 0.5, nan, 0.0, nan, 1.0, 0.0]
2019-02-19T18:01:20.589357: step 1376, loss 0.989663, accuracy 0.625, precision [0.0, 0.5, 0.75, 0.75, 1.0, nan, nan, 0.5, nan], recall [nan, 0.5, 1.0, 0.5, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:01:20.742769: step 1377, loss 1.13026, accuracy 0.6875, precision [0.0, nan, 0.5, 0.8571428571428571, 0.5, 0.0, 1.0, 1.0, nan], recall [nan, 0.0, 1.0, 0.75, 0.3333333333333333, nan, 1.0, 1.0, nan]
2019-02-19T18:01:20.901724: step 1378, loss 1.83641, accuracy 0.5, precision [0.0, 0.5, 0.5, 0.8333333333333334, nan, 0.0, nan, nan, nan], recall [0.0, 0.6666666666666666, 1.0, 0.625, nan, nan, nan, 0.0, nan]
2019-02-19T18:01:21.050677: step 1379, loss 1.47014, accuracy 0.625, precision [0.0, 1.0, 0.3333333333333333, 0.8, 0.5, nan, nan, 1.0, 0.0], recall [nan, 0.3333333333333333, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:01:21.209964: step 1380, loss 1.23315, accuracy 0.6875, precision [0.5, 1.0, 0.5, 0.8, 0.0, 0.0, nan, 1.0, nan], recall [1.0, 0.6, 0.5, 0.8, nan, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:21.364394: step 1381, loss 0.889188, accuracy 0.6875, precision [0.0, 0.5, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 1.0, nan], recall [0.0, 1.0, 0.5, 0.3333333333333333, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:01:21.518963: step 1382, loss 1.30664, accuracy 0.6875, precision [1.0, 0.75, 0.0, 0.75, 0.5, nan, nan, 1.0, 0.5], recall [1.0, 0.75, nan, 0.5, 1.0, nan, nan, 0.5, 1.0]
2019-02-19T18:01:21.674218: step 1383, loss 1.12657, accuracy 0.625, precision [0.5, 1.0, 0.3333333333333333, 1.0, 0.5, 0.0, nan, nan, nan], recall [0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:01:21.832485: step 1384, loss 1.36795, accuracy 0.5, precision [0.5, 0.25, 0.6666666666666666, 0.5, 1.0, nan, 0.0, 1.0, nan], recall [1.0, 1.0, 1.0, 0.14285714285714285, 0.5, 0.0, nan, 1.0, nan]
2019-02-19T18:01:21.992901: step 1385, loss 1.16554, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.8, 0.3333333333333333, 0.0, nan, nan, nan], recall [1.0, 0.5, 0.0, 0.5714285714285714, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:01:22.151179: step 1386, loss 1.38392, accuracy 0.375, precision [0.0, 0.0, 1.0, 0.6, 1.0, 0.5, 0.0, 0.0, nan], recall [0.0, nan, 1.0, 0.375, 1.0, 1.0, nan, 0.0, 0.0]
2019-02-19T18:01:22.303922: step 1387, loss 1.55514, accuracy 0.6875, precision [0.5, 0.75, 1.0, 0.3333333333333333, 1.0, nan, 0.5, 1.0, 1.0], recall [1.0, 0.75, 0.5, 0.5, 0.6666666666666666, nan, 1.0, 0.5, 1.0]
2019-02-19T18:01:22.458831: step 1388, loss 1.17229, accuracy 0.625, precision [1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.0, 0.5, 0.0], recall [1.0, nan, 0.5, 0.625, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:01:22.615654: step 1389, loss 1.03683, accuracy 0.6875, precision [1.0, 0.0, 1.0, 0.75, 1.0, nan, nan, nan, 0.0], recall [0.75, nan, 1.0, 0.75, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:01:22.766369: step 1390, loss 1.73917, accuracy 0.5, precision [0.0, 0.2857142857142857, nan, 1.0, 1.0, 0.0, 0.0, nan, nan], recall [0.0, 1.0, nan, 0.6666666666666666, 0.5, 0.0, nan, 0.0, nan]
2019-02-19T18:01:22.923884: step 1391, loss 0.811059, accuracy 0.8125, precision [1.0, 0.75, nan, 1.0, 1.0, 0.0, nan, 0.75, nan], recall [0.5, 1.0, nan, 1.0, 1.0, nan, nan, 0.75, nan]
2019-02-19T18:01:23.075556: step 1392, loss 1.63069, accuracy 0.4375, precision [1.0, 0.25, nan, 0.75, 0.6666666666666666, 0.0, nan, 0.0, 0.0], recall [0.3333333333333333, 1.0, nan, 0.6, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:01:23.230647: step 1393, loss 1.23855, accuracy 0.5625, precision [0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 0.75, nan, nan, 1.0, 1.0], recall [0.5, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.0, nan, 0.5, 1.0]
2019-02-19T18:01:23.383777: step 1394, loss 0.970064, accuracy 0.5625, precision [1.0, 0.5, 0.0, 0.8, 0.6666666666666666, nan, nan, 0.0, nan], recall [0.5, 1.0, 0.0, 0.6666666666666666, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:01:23.537097: step 1395, loss 1.33688, accuracy 0.375, precision [0.0, 0.0, nan, 0.6, 0.3333333333333333, nan, nan, 0.5, nan], recall [0.0, 0.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:23.694531: step 1396, loss 1.02009, accuracy 0.6875, precision [0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 0.6666666666666666, 0.0], recall [1.0, 0.5, 1.0, 0.3333333333333333, 1.0, nan, 1.0, 1.0, nan]
2019-02-19T18:01:23.848861: step 1397, loss 1.39893, accuracy 0.5, precision [nan, 1.0, 0.5, 0.7142857142857143, 1.0, 0.0, nan, 0.0, nan], recall [0.0, 0.3333333333333333, 0.5, 0.8333333333333334, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:23.999044: step 1398, loss 1.00844, accuracy 0.625, precision [nan, 0.75, 1.0, 0.75, 1.0, 0.0, 0.0, 0.0, nan], recall [0.0, 0.6, 1.0, 0.5, 1.0, nan, nan, nan, nan]
2019-02-19T18:01:24.156974: step 1399, loss 1.40458, accuracy 0.5625, precision [0.5, 1.0, 0.5, 0.3333333333333333, 0.5, nan, 1.0, 1.0, nan], recall [0.5, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, nan]
2019-02-19T18:01:24.310739: step 1400, loss 1.30168, accuracy 0.5, precision [nan, 0.5, 0.3333333333333333, 0.5, 1.0, 0.0, 0.0, 0.5, nan], recall [nan, 0.3333333333333333, 0.3333333333333333, 0.4, 1.0, nan, 0.0, 1.0, nan]
2019-02-19T18:01:24.472212: step 1401, loss 0.630392, accuracy 0.75, precision [1.0, nan, 0.6666666666666666, 0.8, 0.6666666666666666, nan, nan, nan, nan], recall [1.0, 0.0, 1.0, 1.0, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:24.627501: step 1402, loss 1.02249, accuracy 0.625, precision [nan, nan, 1.0, 0.5714285714285714, 0.5, nan, nan, 0.3333333333333333, nan], recall [nan, 0.0, 0.8, 0.8, 1.0, nan, nan, 0.5, 0.0]
2019-02-19T18:01:24.776125: step 1403, loss 1.13159, accuracy 0.625, precision [1.0, 1.0, 0.5, 0.5, 0.6666666666666666, 1.0, nan, 0.0, nan], recall [0.5, 0.5, 1.0, 0.4, 1.0, 0.5, nan, nan, nan]
2019-02-19T18:01:24.935825: step 1404, loss 1.59765, accuracy 0.5, precision [0.0, 0.0, 0.5, 0.7142857142857143, 1.0, 0.0, nan, 0.5, nan], recall [nan, 0.0, 0.5, 0.5555555555555556, 1.0, nan, nan, 0.5, nan]
2019-02-19T18:01:25.089251: step 1405, loss 0.992046, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, nan], recall [0.5, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, nan]
2019-02-19T18:01:25.244898: step 1406, loss 1.60447, accuracy 0.4375, precision [0.5, 0.0, 1.0, 0.4, 0.5, nan, 0.0, nan, nan], recall [1.0, nan, 0.6666666666666666, 0.2857142857142857, 1.0, nan, 0.0, 0.0, nan]
2019-02-19T18:01:25.396442: step 1407, loss 1.32109, accuracy 0.625, precision [1.0, 1.0, nan, 0.5, 1.0, 0.0, nan, 0.6666666666666666, nan], recall [1.0, 0.5, 0.0, 0.75, 0.75, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:01:25.551084: step 1408, loss 0.64816, accuracy 0.625, precision [1.0, 0.5, 0.0, 0.6, 0.75, 0.5, nan, nan, nan], recall [1.0, 0.5, nan, 0.6, 0.6, 0.5, nan, nan, nan]
2019-02-19T18:01:25.707470: step 1409, loss 1.19536, accuracy 0.625, precision [1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, nan], recall [1.0, 1.0, 0.5, 0.2857142857142857, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:25.859112: step 1410, loss 1.01209, accuracy 0.6875, precision [nan, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6, nan, nan, nan, nan], recall [nan, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 1.0, nan, nan, nan, nan]
2019-02-19T18:01:26.011902: step 1411, loss 1.2627, accuracy 0.625, precision [1.0, 1.0, 0.0, 0.25, nan, 0.3333333333333333, nan, 1.0, 1.0], recall [1.0, 0.6666666666666666, 0.0, 0.25, nan, 0.5, nan, 1.0, 1.0]
2019-02-19T18:01:26.168357: step 1412, loss 1.46126, accuracy 0.5625, precision [0.5, 0.6, 0.0, 0.0, 1.0, 1.0, nan, 0.5, nan], recall [1.0, 0.75, 0.0, 0.0, 1.0, 1.0, nan, 1.0, 0.0]
2019-02-19T18:01:26.324812: step 1413, loss 0.557714, accuracy 0.875, precision [0.75, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, nan, nan], recall [0.75, 1.0, 1.0, 1.0, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:26.479772: step 1414, loss 1.51051, accuracy 0.4375, precision [nan, nan, 1.0, 0.2, 0.75, 0.0, nan, 1.0, 0.0], recall [nan, 0.0, 0.6666666666666666, 0.5, 0.6, nan, nan, 0.25, 0.0]
2019-02-19T18:01:26.634835: step 1415, loss 1.16337, accuracy 0.5625, precision [0.5, 1.0, 0.0, 0.5714285714285714, 1.0, nan, nan, 0.6666666666666666, 0.0], recall [1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:26.792728: step 1416, loss 1.12558, accuracy 0.6875, precision [nan, 0.3333333333333333, 0.0, 0.8333333333333334, 1.0, nan, nan, 0.6666666666666666, nan], recall [0.0, 1.0, nan, 0.8333333333333334, 0.6, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:26.947935: step 1417, loss 1.48474, accuracy 0.5, precision [0.5, 0.0, 1.0, 0.75, 0.6666666666666666, nan, 0.0, 0.0, nan], recall [1.0, 0.0, 0.5, 0.5, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:27.101878: step 1418, loss 2.00574, accuracy 0.5625, precision [nan, 0.6666666666666666, 0.3333333333333333, 0.8, 0.6666666666666666, nan, nan, 0.0, 0.0], recall [0.0, 1.0, 0.5, 0.5, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:27.256145: step 1419, loss 0.999073, accuracy 0.6875, precision [nan, 0.0, 0.5, 1.0, 1.0, nan, nan, 0.6, 0.0], recall [0.0, nan, 1.0, 0.6666666666666666, 1.0, nan, nan, 1.0, 0.0]
2019-02-19T18:01:27.416328: step 1420, loss 1.38254, accuracy 0.625, precision [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, nan, nan], recall [0.6666666666666666, 1.0, 1.0, 0.5714285714285714, 1.0, nan, nan, 0.0, nan]
2019-02-19T18:01:27.575155: step 1421, loss 0.890242, accuracy 0.625, precision [0.5, 0.5, 1.0, 0.8, 0.5, 0.0, nan, 1.0, nan], recall [1.0, 0.5, 1.0, 0.4444444444444444, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:27.733358: step 1422, loss 1.38397, accuracy 0.5625, precision [1.0, 1.0, nan, 0.42857142857142855, 0.5, 1.0, nan, 0.0, 0.0], recall [1.0, 0.6, 0.0, 1.0, 0.3333333333333333, 1.0, nan, 0.0, 0.0]
2019-02-19T18:01:27.889226: step 1423, loss 1.12816, accuracy 0.5625, precision [0.5, 0.8, 0.3333333333333333, 0.6666666666666666, 0.5, nan, 0.0, nan, nan], recall [1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:01:28.048321: step 1424, loss 1.49339, accuracy 0.3125, precision [nan, 0.25, 0.0, 0.5, 0.5, nan, nan, 0.0, nan], recall [0.0, 1.0, 0.0, 0.42857142857142855, 0.5, 0.0, nan, 0.0, 0.0]
2019-02-19T18:01:28.199526: step 1425, loss 0.801544, accuracy 0.75, precision [0.5, 1.0, nan, 0.875, 0.5, 0.0, nan, 1.0, nan], recall [1.0, 0.5, nan, 1.0, 1.0, 0.0, nan, 0.5, nan]
2019-02-19T18:01:28.358489: step 1426, loss 1.00255, accuracy 0.6875, precision [1.0, 1.0, 0.5, 0.8333333333333334, 0.75, nan, 0.0, nan, 0.0], recall [1.0, 0.5, 1.0, 0.625, 0.75, nan, nan, nan, nan]
2019-02-19T18:01:28.514411: step 1427, loss 0.699597, accuracy 0.625, precision [nan, 1.0, 0.0, 0.6, 1.0, 0.0, nan, 0.3333333333333333, nan], recall [nan, 1.0, 0.0, 0.42857142857142855, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:28.670985: step 1428, loss 0.817692, accuracy 0.6875, precision [0.3333333333333333, 0.5, 0.0, 1.0, 1.0, nan, nan, nan, nan], recall [1.0, 1.0, 0.0, 0.5714285714285714, 0.8333333333333334, nan, nan, nan, nan]
2019-02-19T18:01:28.830449: step 1429, loss 0.890376, accuracy 0.6875, precision [0.0, 0.25, 0.75, 1.0, 1.0, nan, nan, nan, nan], recall [nan, 1.0, 1.0, 0.6, 0.5, nan, nan, nan, nan]
2019-02-19T18:01:28.985239: step 1430, loss 1.45608, accuracy 0.5, precision [1.0, 0.6666666666666666, 0.3333333333333333, 0.6, 0.5, 0.0, 0.0, nan, nan], recall [0.5, 0.6666666666666666, 1.0, 0.42857142857142855, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:01:29.141452: step 1431, loss 1.58855, accuracy 0.5, precision [0.0, 0.5, 0.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, nan], recall [nan, 0.25, nan, 0.4444444444444444, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:29.298579: step 1432, loss 0.708766, accuracy 0.6875, precision [1.0, 0.75, nan, 0.7142857142857143, 0.5, 0.0, 1.0, nan, nan], recall [1.0, 0.75, 0.0, 0.8333333333333334, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:01:29.452553: step 1433, loss 1.34859, accuracy 0.5625, precision [0.5, 0.0, nan, 0.6666666666666666, 1.0, 0.3333333333333333, nan, 0.8, 0.0], recall [1.0, nan, 0.0, 0.2857142857142857, 1.0, 1.0, nan, 0.8, nan]
2019-02-19T18:01:29.607554: step 1434, loss 1.49288, accuracy 0.625, precision [0.0, 0.5, 1.0, 0.6666666666666666, 0.8, nan, nan, 1.0, nan], recall [nan, 0.5, 1.0, 0.5, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:01:29.763109: step 1435, loss 1.72129, accuracy 0.4375, precision [0.5, 0.5, 1.0, 0.5, 0.4, 0.0, nan, nan, 0.0], recall [0.5, 1.0, 1.0, 0.2857142857142857, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:01:29.921263: step 1436, loss 0.44075, accuracy 0.875, precision [0.0, nan, 1.0, 1.0, 1.0, 1.0, nan, 0.8, nan], recall [nan, 0.0, 1.0, 1.0, 0.75, 1.0, nan, 1.0, nan]
2019-02-19T18:01:30.080567: step 1437, loss 1.30357, accuracy 0.625, precision [nan, 0.5, nan, 0.6, 1.0, 0.5, 0.5, 0.75, nan], recall [nan, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.75, nan]
2019-02-19T18:01:30.241354: step 1438, loss 1.21343, accuracy 0.5625, precision [0.0, 0.6, 0.0, nan, 1.0, 0.0, nan, 0.5, nan], recall [nan, 0.75, nan, 0.0, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:30.400989: step 1439, loss 1.3279, accuracy 0.6875, precision [1.0, 0.7142857142857143, nan, 0.6666666666666666, 0.5, 0.5, nan, 1.0, nan], recall [1.0, 0.8333333333333334, nan, 0.5, 1.0, 1.0, nan, 0.3333333333333333, nan]
2019-02-19T18:01:30.561064: step 1440, loss 0.854813, accuracy 0.625, precision [1.0, 0.5, 1.0, 0.3333333333333333, 0.8, nan, nan, nan, nan], recall [0.5, 0.5, 0.6666666666666666, 1.0, 0.8, nan, nan, 0.0, nan]
2019-02-19T18:01:30.713092: step 1441, loss 1.16966, accuracy 0.5625, precision [0.4, 1.0, nan, 0.0, 0.75, 1.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.0, 0.0, 1.0, 0.5, nan, 0.6666666666666666, nan]
2019-02-19T18:01:30.867488: step 1442, loss 1.48874, accuracy 0.5625, precision [nan, 0.6666666666666666, 0.5, 0.5, nan, 0.0, nan, 1.0, 0.0], recall [nan, 0.8, 0.5, 0.25, 0.0, nan, nan, 0.75, nan]
2019-02-19T18:01:31.026123: step 1443, loss 1.67641, accuracy 0.5, precision [nan, 0.75, 0.0, 0.5555555555555556, nan, nan, nan, nan, 0.0], recall [nan, 0.6, 0.0, 0.625, nan, 0.0, nan, nan, nan]
2019-02-19T18:01:31.182217: step 1444, loss 1.20641, accuracy 0.5625, precision [1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, nan, nan], recall [0.25, 1.0, 0.0, 0.5, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:31.339839: step 1445, loss 0.806998, accuracy 0.6875, precision [1.0, 0.75, nan, 0.5, 0.6666666666666666, nan, nan, 1.0, nan], recall [1.0, 0.75, 0.0, 0.75, 0.6666666666666666, 0.0, nan, 1.0, nan]
2019-02-19T18:01:31.497735: step 1446, loss 1.42621, accuracy 0.5, precision [0.5, 0.5, nan, 0.5714285714285714, 1.0, nan, 0.0, 0.3333333333333333, nan], recall [1.0, 0.2, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 1.0, nan]
2019-02-19T18:01:31.649012: step 1447, loss 1.32181, accuracy 0.5, precision [1.0, 0.0, 0.5, 1.0, 0.3333333333333333, nan, 1.0, 0.25, nan], recall [1.0, 0.0, 0.5, 0.25, 1.0, nan, 1.0, 0.3333333333333333, 0.0]
2019-02-19T18:01:31.797893: step 1448, loss 0.879865, accuracy 0.6875, precision [0.5, 0.6666666666666666, 0.5, 1.0, 1.0, nan, nan, 0.3333333333333333, nan], recall [1.0, 0.4, 1.0, 0.7142857142857143, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:31.949341: step 1449, loss 1.2416, accuracy 0.6875, precision [0.75, 1.0, nan, 0.8333333333333334, 1.0, 0.0, 0.0, 1.0, 0.0], recall [1.0, 0.3333333333333333, 0.0, 0.8333333333333334, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:01:32.099990: step 1450, loss 1.26762, accuracy 0.5625, precision [0.5, 0.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.3333333333333333, nan], recall [0.5, nan, 1.0, 0.4444444444444444, 0.5, 1.0, nan, 1.0, nan]
2019-02-19T18:01:32.256117: step 1451, loss 1.2168, accuracy 0.5625, precision [0.0, 0.0, nan, 1.0, 1.0, 0.0, 0.0, 1.0, nan], recall [0.0, nan, nan, 0.5454545454545454, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:01:32.410484: step 1452, loss 0.992329, accuracy 0.75, precision [0.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.0, nan, 1.0, nan], recall [0.0, 1.0, 1.0, 0.7142857142857143, 0.6666666666666666, nan, nan, 1.0, nan]
2019-02-19T18:01:32.566599: step 1453, loss 1.6993, accuracy 0.4375, precision [0.5, 1.0, 0.0, 0.5, 0.5, 0.0, 0.0, nan, nan], recall [1.0, 0.6, 0.0, 0.2857142857142857, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:32.725901: step 1454, loss 1.21184, accuracy 0.4375, precision [1.0, 0.0, 0.0, 0.375, 1.0, 0.0, nan, 0.0, nan], recall [0.4, 0.0, 0.0, 0.6, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:01:32.885263: step 1455, loss 2.02901, accuracy 0.5, precision [0.5, 0.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, nan], recall [0.5, 0.0, nan, 0.625, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:33.036830: step 1456, loss 1.05897, accuracy 0.5, precision [nan, nan, 0.0, 0.6666666666666666, 0.6, 0.0, nan, 0.5, nan], recall [nan, 0.0, 0.0, 0.4444444444444444, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:33.195624: step 1457, loss 1.42051, accuracy 0.75, precision [nan, 1.0, 0.25, 0.8, 1.0, nan, 1.0, 1.0, nan], recall [nan, 1.0, 1.0, 0.8, 1.0, nan, 0.5, 0.3333333333333333, nan]
2019-02-19T18:01:33.355265: step 1458, loss 1.72665, accuracy 0.5, precision [0.5, 1.0, 0.0, 0.8, 0.25, 0.0, 1.0, 0.0, nan], recall [0.3333333333333333, 0.3333333333333333, nan, 0.5714285714285714, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:33.508304: step 1459, loss 1.31121, accuracy 0.5625, precision [1.0, 0.5, 0.0, 1.0, 0.5, 0.0, nan, 0.3333333333333333, nan], recall [1.0, 1.0, 0.0, 0.625, 0.5, nan, 0.0, 1.0, nan]
2019-02-19T18:01:33.666891: step 1460, loss 0.941421, accuracy 0.75, precision [0.3333333333333333, nan, nan, 0.8333333333333334, 1.0, nan, 1.0, 1.0, 0.0], recall [1.0, 0.0, nan, 0.8333333333333334, 0.6666666666666666, nan, 1.0, 0.75, nan]
2019-02-19T18:01:33.817067: step 1461, loss 0.992146, accuracy 0.625, precision [0.6666666666666666, 1.0, nan, 0.75, 0.3333333333333333, nan, nan, 0.0, nan], recall [1.0, 1.0, nan, 0.6, 0.5, nan, 0.0, nan, nan]
2019-02-19T18:01:33.973798: step 1462, loss 0.866343, accuracy 0.6875, precision [nan, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 0.0, 1.0, nan], recall [nan, 0.0, nan, 0.6, 1.0, 1.0, nan, 1.0, nan]
2019-02-19T18:01:34.127556: step 1463, loss 0.923577, accuracy 0.625, precision [1.0, 0.25, 0.0, 0.75, 1.0, nan, nan, nan, nan], recall [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.5, nan, nan, 0.0, nan]
2019-02-19T18:01:34.280943: step 1464, loss 2.70142, accuracy 0.3125, precision [1.0, 0.5, 0.0, 0.5, 0.2, nan, 0.0, 0.5, 0.0], recall [0.5, 0.5, 0.0, 0.16666666666666666, 0.5, nan, nan, 0.5, 0.0]
2019-02-19T18:01:34.434591: step 1465, loss 1.35969, accuracy 0.625, precision [1.0, 0.5, 0.0, 1.0, 1.0, nan, 0.0, nan, 0.0], recall [1.0, 1.0, nan, 0.3333333333333333, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:01:34.592893: step 1466, loss 0.991412, accuracy 0.6875, precision [1.0, 0.5, 0.0, 0.8333333333333334, 0.6666666666666666, nan, 1.0, 0.0, nan], recall [1.0, 1.0, 0.0, 0.7142857142857143, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:01:34.747339: step 1467, loss 0.696546, accuracy 0.6875, precision [1.0, 0.5, 1.0, 1.0, 0.6666666666666666, nan, nan, 0.3333333333333333, nan], recall [1.0, 1.0, 1.0, 0.2857142857142857, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:34.898241: step 1468, loss 0.847453, accuracy 0.625, precision [nan, 1.0, 0.25, 1.0, 1.0, 0.0, nan, 0.5, 0.0], recall [0.0, 1.0, 1.0, 0.6, 0.5, nan, nan, 1.0, nan]
2019-02-19T18:01:35.052682: step 1469, loss 1.09607, accuracy 0.5, precision [0.5, 0.5, 0.0, 0.8, 0.6666666666666666, 0.0, 0.0, nan, nan], recall [1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, nan, 0.0, nan]
2019-02-19T18:01:35.348433: step 1470, loss 1.06613, accuracy 0.625, precision [0.3333333333333333, 0.5, 0.0, 1.0, 1.0, nan, nan, 1.0, nan], recall [1.0, 0.75, nan, 0.5, 0.75, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:35.505171: step 1471, loss 1.58346, accuracy 0.5, precision [0.5, 0.25, 0.0, 0.75, 0.5, nan, nan, 0.5, 1.0], recall [0.3333333333333333, 1.0, 0.0, 0.42857142857142855, 0.5, nan, nan, 1.0, 1.0]
2019-02-19T18:01:35.663243: step 1472, loss 0.814885, accuracy 0.75, precision [nan, 0.5, nan, 0.8571428571428571, 1.0, 0.0, 1.0, nan, nan], recall [0.0, 1.0, nan, 0.75, 0.75, nan, 1.0, nan, nan]
2019-02-19T18:01:35.816636: step 1473, loss 1.61231, accuracy 0.625, precision [0.5, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 1.0, 0.0], recall [1.0, 0.75, nan, 0.3333333333333333, 0.5, nan, nan, 0.75, nan]
2019-02-19T18:01:35.971866: step 1474, loss 1.13697, accuracy 0.625, precision [nan, 0.0, 0.0, 0.8333333333333334, 0.75, 0.5, 0.5, nan, nan], recall [nan, 0.0, nan, 0.625, 1.0, 1.0, 1.0, 0.0, nan]
2019-02-19T18:01:36.131477: step 1475, loss 1.35153, accuracy 0.5, precision [1.0, 0.5714285714285714, 0.3333333333333333, 0.0, 1.0, nan, nan, 0.5, nan], recall [0.25, 1.0, 1.0, 0.0, 0.3333333333333333, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:36.292515: step 1476, loss 1.18687, accuracy 0.75, precision [0.5, 1.0, 0.0, 0.8, 1.0, 0.0, nan, 1.0, nan], recall [1.0, 0.6666666666666666, nan, 1.0, 0.8, nan, 0.0, 0.5, nan]
2019-02-19T18:01:36.448841: step 1477, loss 1.41923, accuracy 0.5625, precision [1.0, 0.5, 0.5, 0.6, 0.5, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 1.0, 0.42857142857142855, 1.0, nan, 0.0, 0.6666666666666666, nan]
2019-02-19T18:01:36.602821: step 1478, loss 1.45084, accuracy 0.625, precision [0.5, 1.0, 1.0, 0.6666666666666666, 1.0, nan, nan, 0.25, 0.0], recall [0.3333333333333333, 0.6666666666666666, 1.0, 0.5, 0.75, nan, nan, 1.0, nan]
2019-02-19T18:01:36.757933: step 1479, loss 1.51213, accuracy 0.5, precision [0.5, 1.0, 0.0, 0.5, 1.0, 0.0, nan, 0.0, nan], recall [0.3333333333333333, 1.0, 0.0, 0.5, 0.6666666666666666, nan, nan, 0.0, nan]
2019-02-19T18:01:36.912246: step 1480, loss 1.20266, accuracy 0.5625, precision [1.0, 0.75, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, nan, nan, 0.6666666666666666, nan]
2019-02-19T18:01:37.065702: step 1481, loss 1.70618, accuracy 0.375, precision [0.4, nan, 0.0, 1.0, 0.0, 0.0, nan, 1.0, nan], recall [1.0, 0.0, nan, 0.2727272727272727, nan, nan, nan, 1.0, nan]
2019-02-19T18:01:37.218981: step 1482, loss 1.03103, accuracy 0.625, precision [nan, 0.8, nan, 0.4, 1.0, 1.0, 0.0, nan, 0.0], recall [0.0, 1.0, 0.0, 0.5, 1.0, 1.0, nan, 0.0, 0.0]
2019-02-19T18:01:37.375804: step 1483, loss 0.801829, accuracy 0.6875, precision [1.0, 0.75, 1.0, 0.75, 0.5, 0.0, 1.0, nan, nan], recall [1.0, 0.75, 0.5, 0.6, 1.0, nan, 1.0, nan, 0.0]
2019-02-19T18:01:37.530836: step 1484, loss 0.947763, accuracy 0.6875, precision [1.0, 0.5, 0.6666666666666666, 0.75, 1.0, 0.0, 0.0, 1.0, nan], recall [1.0, 1.0, 1.0, 0.5, 1.0, nan, nan, 0.3333333333333333, nan]
2019-02-19T18:01:37.687803: step 1485, loss 1.61556, accuracy 0.375, precision [0.0, 0.6666666666666666, nan, 0.2, 1.0, 0.0, 0.0, 1.0, 0.0], recall [nan, 0.4, nan, 0.25, 1.0, nan, nan, 0.4, 0.0]
2019-02-19T18:01:37.845874: step 1486, loss 1.10285, accuracy 0.5, precision [nan, 0.3333333333333333, 0.4, 1.0, nan, nan, 1.0, 0.25, nan], recall [nan, 1.0, 1.0, 0.3, 0.0, nan, 1.0, 1.0, nan]
2019-02-19T18:01:37.995807: step 1487, loss 1.51281, accuracy 0.5625, precision [0.5, 0.3333333333333333, 0.0, 0.5, 1.0, nan, 1.0, 1.0, nan], recall [1.0, 0.5, nan, 0.6, 1.0, nan, 0.5, 0.25, nan]
2019-02-19T18:01:38.151976: step 1488, loss 1.3285, accuracy 0.625, precision [nan, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0], recall [nan, 0.75, 0.6666666666666666, 0.25, 1.0, nan, 1.0, 0.0, nan]
2019-02-19T18:01:38.304153: step 1489, loss 1.36565, accuracy 0.5, precision [1.0, 0.0, 0.6666666666666666, 0.5714285714285714, 0.0, nan, nan, 0.0, nan], recall [1.0, 0.0, 1.0, 0.5714285714285714, 0.0, 0.0, nan, 0.0, nan]
2019-02-19T18:01:38.461249: step 1490, loss 1.06855, accuracy 0.5625, precision [0.0, 1.0, 1.0, 0.2857142857142857, 0.5, 1.0, 1.0, nan, nan], recall [nan, 0.4, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, nan, nan]
2019-02-19T18:01:38.615354: step 1491, loss 1.51, accuracy 0.5, precision [0.6666666666666666, 1.0, nan, 0.6666666666666666, 0.25, 0.0, 0.0, 1.0, nan], recall [1.0, 0.5, 0.0, 1.0, 0.3333333333333333, nan, 0.0, 0.5, 0.0]
2019-02-19T18:01:38.769849: step 1492, loss 1.27856, accuracy 0.5625, precision [1.0, 0.0, 0.0, 0.8, 0.75, 0.0, 0.0, 0.5, nan], recall [0.5, nan, 0.0, 0.6666666666666666, 1.0, nan, nan, 1.0, nan]
2019-02-19T18:01:38.923865: step 1493, loss 1.61447, accuracy 0.5, precision [nan, 0.5, nan, 0.7142857142857143, 0.0, 0.5, nan, 0.0, nan], recall [nan, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, nan, nan]
2019-02-19T18:01:39.076209: step 1494, loss 1.23887, accuracy 0.5625, precision [0.75, nan, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, nan], recall [1.0, 0.0, 1.0, 0.4, 0.75, nan, 0.0, nan, nan]
2019-02-19T18:01:39.231166: step 1495, loss 0.731859, accuracy 0.8125, precision [nan, 0.6666666666666666, 1.0, 0.875, 1.0, nan, nan, 0.0, nan], recall [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, nan, nan, nan]
2019-02-19T18:01:39.385540: step 1496, loss 1.03817, accuracy 0.5, precision [1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, nan, nan], recall [0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, nan, 0.0, nan]
2019-02-19T18:01:39.541534: step 1497, loss 0.953197, accuracy 0.6875, precision [1.0, 1.0, nan, 0.5714285714285714, 0.6, nan, 1.0, nan, nan], recall [0.6666666666666666, 1.0, 0.0, 0.8, 1.0, nan, 0.5, 0.0, nan]
2019-02-19T18:01:39.694242: step 1498, loss 1.3518, accuracy 0.5, precision [nan, 0.0, 0.25, 0.8333333333333334, 1.0, 0.0, 1.0, nan, 0.0], recall [nan, nan, 0.3333333333333333, 0.5555555555555556, 0.5, nan, 1.0, 0.0, nan]
2019-02-19T18:01:39.851260: step 1499, loss 1.21104, accuracy 0.625, precision [1.0, 0.25, 1.0, 0.75, 0.75, nan, nan, 0.0, nan], recall [0.5, 0.5, 0.6666666666666666, 0.6, 1.0, nan, 0.0, nan, nan]
2019-02-19T18:01:40.008852: step 1500, loss 1.2518, accuracy 0.6875, precision [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, nan, 0.0, 0.0], recall [1.0, 0.5, nan, 0.6666666666666666, 1.0, nan, nan, 0.0, nan]

Evaluation:
[[ 55  10   1  22   0   1   0   2   0]
 [  8  74   1  72   2   0   0   3   0]
 [  0   1  44  47   3   0   0   1   0]
 [  8  16  22 246   8   3   2   8   0]
 [  0   0   7  20 130   0   2   0   0]
 [  1   2   1  37   0  11   2   1   0]
 [  0   0   2  16   3   0  11   1   0]
 [  3   7   3  42   0   0   0  46   0]
 [  1   1   1  10   1   0   0   2   1]]
2019-02-19T18:01:42.434838: step 1500, loss 1.23267, accuracy 0.602927, precision [0.6043956043956044, 0.4625, 0.4583333333333333, 0.7859424920127795, 0.8176100628930818, 0.2, 0.3333333333333333, 0.45544554455445546, 0.058823529411764705], recall [0.7236842105263158, 0.6666666666666666, 0.5365853658536586, 0.48046875, 0.8843537414965986, 0.7333333333333333, 0.6470588235294118, 0.71875, 1.0]

Saved model checkpoint to /home/ubuntu/Project/runs/1550599006/checkpoints/model-1500

